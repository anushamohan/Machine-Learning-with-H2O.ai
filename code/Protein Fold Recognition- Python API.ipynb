{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h2o\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Classifier models using H2O + Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
    "from h2o.estimators.glm import H2OGeneralizedLinearEstimator\n",
    "from h2o.estimators import H2ORandomForestEstimator\n",
    "from h2o.estimators import H2ODeepLearningEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anusha/anaconda2/lib/python2.7/site-packages/h2o/connection.py:82: DeprecationWarning: `max_mem_size_GB` is deprecated. Use `max_mem_size` instead.\n",
      "  warnings.warn(\"`max_mem_size_GB` is deprecated. Use `max_mem_size` instead.\", category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "No instance found at ip and port: localhost:54321. Trying to start local jar...\n",
      "\n",
      "\n",
      "JVM stdout: /tmp/tmpdrqfG1/h2o_anusha_started_from_python.out\n",
      "JVM stderr: /tmp/tmpqJzQH2/h2o_anusha_started_from_python.err\n",
      "Using ice_root: /tmp/tmpbGDCcZ\n",
      "\n",
      "\n",
      "Java Version: Picked up JAVA_TOOL_OPTIONS: -javaagent:/usr/share/java/jayatanaag.jar \n",
      "java version \"1.8.0_91\"\n",
      "Java(TM) SE Runtime Environment (build 1.8.0_91-b14)\n",
      "Java HotSpot(TM) 64-Bit Server VM (build 25.91-b14, mixed mode)\n",
      "\n",
      "\n",
      "Starting H2O JVM and connecting: ............... Connection successful!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anusha/anaconda2/lib/python2.7/site-packages/IPython/core/formatters.py:92: DeprecationWarning: DisplayFormatter._ipython_display_formatter_default is deprecated: use @default decorator instead.\n",
      "  def _ipython_display_formatter_default(self):\n",
      "/home/anusha/anaconda2/lib/python2.7/site-packages/IPython/core/formatters.py:98: DeprecationWarning: DisplayFormatter._formatters_default is deprecated: use @default decorator instead.\n",
      "  def _formatters_default(self):\n",
      "/home/anusha/anaconda2/lib/python2.7/site-packages/IPython/core/formatters.py:677: DeprecationWarning: PlainTextFormatter._deferred_printers_default is deprecated: use @default decorator instead.\n",
      "  def _deferred_printers_default(self):\n",
      "/home/anusha/anaconda2/lib/python2.7/site-packages/IPython/core/formatters.py:669: DeprecationWarning: PlainTextFormatter._singleton_printers_default is deprecated: use @default decorator instead.\n",
      "  def _singleton_printers_default(self):\n",
      "/home/anusha/anaconda2/lib/python2.7/site-packages/IPython/core/formatters.py:672: DeprecationWarning: PlainTextFormatter._type_printers_default is deprecated: use @default decorator instead.\n",
      "  def _type_printers_default(self):\n",
      "/home/anusha/anaconda2/lib/python2.7/site-packages/IPython/core/formatters.py:669: DeprecationWarning: PlainTextFormatter._singleton_printers_default is deprecated: use @default decorator instead.\n",
      "  def _singleton_printers_default(self):\n",
      "/home/anusha/anaconda2/lib/python2.7/site-packages/IPython/core/formatters.py:672: DeprecationWarning: PlainTextFormatter._type_printers_default is deprecated: use @default decorator instead.\n",
      "  def _type_printers_default(self):\n",
      "/home/anusha/anaconda2/lib/python2.7/site-packages/IPython/core/formatters.py:677: DeprecationWarning: PlainTextFormatter._deferred_printers_default is deprecated: use @default decorator instead.\n",
      "  def _deferred_printers_default(self):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime: </td>\n",
       "<td>1 seconds 633 milliseconds </td></tr>\n",
       "<tr><td>H2O cluster version: </td>\n",
       "<td>3.8.2.3</td></tr>\n",
       "<tr><td>H2O cluster name: </td>\n",
       "<td>H2O_started_from_python_anusha_rmi162</td></tr>\n",
       "<tr><td>H2O cluster total nodes: </td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster total free memory: </td>\n",
       "<td>28.44 GB</td></tr>\n",
       "<tr><td>H2O cluster total cores: </td>\n",
       "<td>32</td></tr>\n",
       "<tr><td>H2O cluster allowed cores: </td>\n",
       "<td>32</td></tr>\n",
       "<tr><td>H2O cluster healthy: </td>\n",
       "<td>True</td></tr>\n",
       "<tr><td>H2O Connection ip: </td>\n",
       "<td>127.0.0.1</td></tr>\n",
       "<tr><td>H2O Connection port: </td>\n",
       "<td>54321</td></tr>\n",
       "<tr><td>H2O Connection proxy: </td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>Python Version: </td>\n",
       "<td>2.7.11</td></tr></table></div>"
      ],
      "text/plain": [
       "------------------------------  -------------------------------------\n",
       "H2O cluster uptime:             1 seconds 633 milliseconds\n",
       "H2O cluster version:            3.8.2.3\n",
       "H2O cluster name:               H2O_started_from_python_anusha_rmi162\n",
       "H2O cluster total nodes:        1\n",
       "H2O cluster total free memory:  28.44 GB\n",
       "H2O cluster total cores:        32\n",
       "H2O cluster allowed cores:      32\n",
       "H2O cluster healthy:            True\n",
       "H2O Connection ip:              127.0.0.1\n",
       "H2O Connection port:            54321\n",
       "H2O Connection proxy:\n",
       "Python Version:                 2.7.11\n",
       "------------------------------  -------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init(nthreads = -1 , max_mem_size_GB = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parse Progress: [##################################################] 100%\n"
     ]
    }
   ],
   "source": [
    " foldpro_df = h2o.import_file(\"/home/anusha/cscie-63/project/foldpro_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:951,600 Cols:85\n",
      "\n",
      "Chunk compression summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>chunk_type</b></td>\n",
       "<td><b>chunk_name</b></td>\n",
       "<td><b>count</b></td>\n",
       "<td><b>count_percentage</b></td>\n",
       "<td><b>size</b></td>\n",
       "<td><b>size_percentage</b></td></tr>\n",
       "<tr><td>CX0</td>\n",
       "<td>Zero Sparse Bits</td>\n",
       "<td>128</td>\n",
       "<td>1.1764706</td>\n",
       "<td>   23.8 KB</td>\n",
       "<td>0.0045702</td></tr>\n",
       "<tr><td>C1S</td>\n",
       "<td>1-Byte Fractions</td>\n",
       "<td>826</td>\n",
       "<td>7.5919113</td>\n",
       "<td>    5.9 MB</td>\n",
       "<td>1.1662543</td></tr>\n",
       "<tr><td>C2S</td>\n",
       "<td>2-Byte Fractions</td>\n",
       "<td>198</td>\n",
       "<td>1.819853</td>\n",
       "<td>    2.8 MB</td>\n",
       "<td>0.5545419</td></tr>\n",
       "<tr><td>CXD</td>\n",
       "<td>Zero Sparse Reals</td>\n",
       "<td>9</td>\n",
       "<td>0.0827206</td>\n",
       "<td>   45.2 KB</td>\n",
       "<td>0.0086955</td></tr>\n",
       "<tr><td>CUD</td>\n",
       "<td>Unique Reals</td>\n",
       "<td>1257</td>\n",
       "<td>11.553309</td>\n",
       "<td>   18.8 MB</td>\n",
       "<td>3.698888</td></tr>\n",
       "<tr><td>C8D</td>\n",
       "<td>64-bit Reals</td>\n",
       "<td>8462</td>\n",
       "<td>77.775734</td>\n",
       "<td>  480.5 MB</td>\n",
       "<td>94.567055</td></tr></table></div>"
      ],
      "text/plain": [
       "chunk_type    chunk_name         count    count_percentage    size      size_percentage\n",
       "------------  -----------------  -------  ------------------  --------  -----------------\n",
       "CX0           Zero Sparse Bits   128      1.17647             23.8 KB   0.00457018\n",
       "C1S           1-Byte Fractions   826      7.59191             5.9 MB    1.16625\n",
       "C2S           2-Byte Fractions   198      1.81985             2.8 MB    0.554542\n",
       "CXD           Zero Sparse Reals  9        0.0827206           45.2 KB   0.0086955\n",
       "CUD           Unique Reals       1257     11.5533             18.8 MB   3.69889\n",
       "C8D           64-bit Reals       8462     77.7757             480.5 MB  94.5671"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frame distribution summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>size</b></td>\n",
       "<td><b>number_of_rows</b></td>\n",
       "<td><b>number_of_chunks_per_column</b></td>\n",
       "<td><b>number_of_chunks</b></td></tr>\n",
       "<tr><td>127.0.0.1:54321</td>\n",
       "<td>  508.1 MB</td>\n",
       "<td>951600.0</td>\n",
       "<td>128.0</td>\n",
       "<td>10880.0</td></tr>\n",
       "<tr><td>mean</td>\n",
       "<td>  508.1 MB</td>\n",
       "<td>951600.0</td>\n",
       "<td>128.0</td>\n",
       "<td>10880.0</td></tr>\n",
       "<tr><td>min</td>\n",
       "<td>  508.1 MB</td>\n",
       "<td>951600.0</td>\n",
       "<td>128.0</td>\n",
       "<td>10880.0</td></tr>\n",
       "<tr><td>max</td>\n",
       "<td>  508.1 MB</td>\n",
       "<td>951600.0</td>\n",
       "<td>128.0</td>\n",
       "<td>10880.0</td></tr>\n",
       "<tr><td>stddev</td>\n",
       "<td>      0  B</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>total</td>\n",
       "<td>  508.1 MB</td>\n",
       "<td>951600.0</td>\n",
       "<td>128.0</td>\n",
       "<td>10880.0</td></tr></table></div>"
      ],
      "text/plain": [
       "                 size      number_of_rows    number_of_chunks_per_column    number_of_chunks\n",
       "---------------  --------  ----------------  -----------------------------  ------------------\n",
       "127.0.0.1:54321  508.1 MB  951600            128                            10880\n",
       "mean             508.1 MB  951600            128                            10880\n",
       "min              508.1 MB  951600            128                            10880\n",
       "max              508.1 MB  951600            128                            10880\n",
       "stddev           0  B      0                 0                              0\n",
       "total            508.1 MB  951600            128                            10880"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>       </th><th>LABEL           </th><th>QUERY_LENGTH  </th><th>TARGET_LENGTH  </th><th>COSINE_COMP_MONOMER_QUERY_TEMPLATE_SEQ  </th><th>CORRELATION_COMP_MONOMER_QUERY_TEMPLATE_SEQ  </th><th>GAUSSIAN_FUNCTION_COMP_MONOMER_QUERY_TEMPLATE_SEQ  </th><th>COSINE_COMP_DIMER_QUERY_TEMPLATE_SEQ  </th><th>CORRELATION_COMP_DIMER_QUERY_TEMPLATE_SEQ  </th><th>GAUSSIAN_FUNCTION_COMP_DIMER_QUERY_TEMPLATE_SEQ  </th><th>COSINE_COMP_MONOMER_QUERY_TEMPLATE_FAMILIES  </th><th>CORRELATION_COMP_MONOMER_QUERY_TEMPLATE_FAMILIES  </th><th>GAUSSIAN_FUNCTION_COMP_MONOMER_QUERY_TEMPLATE_FAMILIES  </th><th>COSINE_COMP_DIMER_QUERY_TEMPLATE_FAMILIES  </th><th>CORRELATION_COMP_DIMER_QUERY_TEMPLATE_FAMILIES  </th><th>GAUSSIAN_FUNCTION_COMP_DIMER_QUERY_TEMPLATE_FAMILIES  </th><th>PALIGN_SEQ_ALIGNMENT_SCORE_1  </th><th>PALIGN_SEQ_ALIGNMENT_SCORE_2  </th><th>CLUSTALW_SEQ_ALIGNMENT_SCORE  </th><th>CLUSTALW_PROFILE_PROFILE_ALIGNMENT_SCORE  </th><th>LOBSTER_PROFILE_PROFILE_ALIGNMENT_SCORE  </th><th>PSIBLAST_PROFILE_SEQ_ALIGNMENT_SCORE  </th><th>PSIBLAST_ALIGNMENT_EVALUE  </th><th>PSIBLAST_NORMALIZED_ALIGNMENT_LENGTH  </th><th>PSIBLAST_IDENTITY_RATE_ALIGNMENT  </th><th>PSIBLAST_POSITIVE_RATE_ALIGNMENT  </th><th>PFAM_ALIGNMENT_SCORE  </th><th>PFAM_ALIGNMENT_EVALUE  </th><th>SEARCH_ALIGNMENT_SCORE  </th><th>SEARCH_ALIGNMENT_EVALUE  </th><th>IMPALA_SEQ_PROFILE_ALIGNMENT_SCORE  </th><th>IMPLALA_ALIGNMENT_EVALUE  </th><th>IMPALA_NORMALIZED_ALIGNMENT_LENGTH  </th><th>IMPALA_ALIGNMENT_IDENTITY_RATE  </th><th>IMPALA_ALIGNMENT_POSITIVE_RATE  </th><th>RPSBLAST_SEQ_PROFILE_ALIGNMENT_SCORE  </th><th>RPSBLAST_ALIGNMENT_EVALUE  </th><th>RPSBLAST_ALIGNMENT_NORMALIZED_LENGTH  </th><th>RPSBLAST_ALIGNMENT_IDENTITY_RATE  </th><th>RPSBLAST_ALIGNMENT_POSITIVE_RATE  </th><th>SECONDARY_STRUCTURE_MATCH_RATIO  </th><th>RELATIVE_SOLVENT_ACCESSIBILITY_MATCH_RATIO  </th><th>AVG_CONTACT_PROBABILITY_cm_8Angstrom  </th><th>COSINE_RESIDUE_CONTACT_NUM_cm_8Angstrom  </th><th>CORRELATION_RESIDUE_CONTACT_NUM_cm_8Angstrom  </th><th>COSINE_RESIDUE_CONTACT_ORDER_cm_8Angstrom  </th><th>CORRELATION_RESIDUE_CONTACT_ORDER_cm_8Angstrom  </th><th>AVG_CONTACT_PROBABILITY_bm_8Angstrom  </th><th>COSINE_RESIDUE_CONTACT_NUM_bm_8Angstrom  </th><th>CORRELATION_RESIDUE_CONTACT_NUM_bm_8Angstrom  </th><th>COSINE_RESIDUE_CONTACT_ORDER_bm_8Angstrom  </th><th>CORRELATION_RESIDUE_CONTACT_ORDER_bm_8Angstrom  </th><th>AVG_CONTACT_PROBABILITY_cm_12Angstrom  </th><th>COSINE_RESIDUE_CONTACT_NUM_cm_12Angstrom  </th><th>CORRELATION_RESIDUE_CONTACT_NUM_cm_12Angstrom  </th><th>COSINE_RESIDUE_CONTACT_ORDER_cm_12Angstrom  </th><th>CORRELATION_RESIDUE_CONTACT_ORDER_cm_12Angstrom  </th><th>AVG_CONTACT_PROBABILITY_bm_12Angstrom  </th><th>COSINE_RESIDUE_CONTACT_NUM_bm_12Angstrom  </th><th>CORRELATION_RESIDUE_CONTACT_NUM_bm_12Angstrom  </th><th>COSINE_RESIDUE_CONTACT_ORDER_bm_12Angstrom  </th><th>CORRELATION_RESIDUE_CONTACT_ORDER_bm_12Angstrom  </th><th>BETA_RESIDUE_BETA_SHEET_PAIRING_PROBABILITY  </th><th>PERCENTAGE_HELIX_QUERY  </th><th>PERCENTAGE_BETA_STRAND_QUERY  </th><th>PERCENTAGE_COIL_QUERY  </th><th>PERCENTAGE_EXPOSED_RESIDUE_QUERY  </th><th>PERCENTAGE_BURIED_RESIDUE_QUERY  </th><th>PERCENTAGE_HELIX_TEMPLATE  </th><th>PERCENTAGE_BETA_STRAND_TEMPLATE  </th><th>PERCENTAGE_COIL_TEMPLATE  </th><th>PERCENTAGE_EXPOSED_RESIDUE_TEMPLATE  </th><th>PERCENTAGE_BURIED_RESIDUE_TEMPLATE  </th><th>COSINE_SS_SA_COMP  </th><th>CORRELATION_SS_SA_COMP  </th><th>GAUSSIAN_FUNC_SS_SA_COMP  </th><th>DOT_PRODUCT_SS_SA_COMP  </th><th>HMMER_PRCHMMM_COEMIS_SCORE  </th><th>HMMER_PRCHMMM_SIMPLE_SCORE  </th><th>HMMER_PRCHMMM_REVERSE_SCORE  </th><th>CHK_PRCHMMM_COEMIS_SCORE  </th><th>CHK_PRCHMMM_SIMPLE_SCORE  </th><th>CHK_PRCHMMM_REVERSE_SCORE  </th><th>HHSEARCH_PROFILE_PROFILE_ALIGNMENT_SCORE  </th><th>COMPASS_ALIGNMENT_SCORE  </th><th>COMPASS_EVALUE  </th></tr>\n",
       "<tr><td>type   </td><td>enum            </td><td>real          </td><td>real           </td><td>real                                    </td><td>real                                         </td><td>real                                               </td><td>real                                  </td><td>real                                       </td><td>real                                             </td><td>real                                         </td><td>real                                              </td><td>real                                                    </td><td>real                                       </td><td>real                                            </td><td>real                                                  </td><td>real                          </td><td>real                          </td><td>real                          </td><td>real                                      </td><td>real                                     </td><td>real                                  </td><td>real                       </td><td>real                                  </td><td>real                              </td><td>real                              </td><td>real                  </td><td>real                   </td><td>real                    </td><td>real                     </td><td>real                                </td><td>real                      </td><td>real                                </td><td>real                            </td><td>real                            </td><td>real                                  </td><td>real                       </td><td>real                                  </td><td>real                              </td><td>real                              </td><td>real                             </td><td>real                                        </td><td>real                                  </td><td>real                                     </td><td>real                                          </td><td>real                                       </td><td>real                                            </td><td>real                                  </td><td>real                                     </td><td>real                                          </td><td>real                                       </td><td>real                                            </td><td>real                                   </td><td>real                                      </td><td>real                                           </td><td>real                                        </td><td>real                                             </td><td>real                                   </td><td>real                                      </td><td>real                                           </td><td>real                                        </td><td>real                                             </td><td>real                                         </td><td>real                    </td><td>real                          </td><td>real                   </td><td>real                              </td><td>real                             </td><td>real                       </td><td>real                             </td><td>real                      </td><td>real                                 </td><td>real                                </td><td>real               </td><td>real                    </td><td>real                      </td><td>real                    </td><td>real                        </td><td>real                        </td><td>real                         </td><td>real                      </td><td>real                      </td><td>real                       </td><td>real                                      </td><td>real                     </td><td>real            </td></tr>\n",
       "<tr><td>mins   </td><td>0.0             </td><td>0.24          </td><td>0.24           </td><td>0.0802732994595                         </td><td>-0.617960242113                              </td><td>0.475818755904                                     </td><td>0.0                                   </td><td>-0.175794812739                            </td><td>0.579735191451                                   </td><td>0.0811458609574                              </td><td>-0.582715535982                                   </td><td>0.475818755904                                          </td><td>0.0                                        </td><td>-0.215942425016                                 </td><td>0.579735191451                                        </td><td>-0.302585092994               </td><td>-2.71012698297                </td><td>0.0                           </td><td>0.108140947752                            </td><td>-30.375                                  </td><td>0.0                                   </td><td>-159.0                     </td><td>0.0                                   </td><td>0.0                               </td><td>0.0                               </td><td>-32.8291666667        </td><td>-546.580167607         </td><td>-1.55833333333          </td><td>-546.580167607           </td><td>0.0                                 </td><td>-151.0                    </td><td>0.0                                 </td><td>0.0                             </td><td>0.0                             </td><td>0.0                                   </td><td>-152.0                     </td><td>0.0                                   </td><td>0.0                               </td><td>0.0                               </td><td>0.0                              </td><td>0.0                                         </td><td>0.0                                   </td><td>0.0                                      </td><td>-0.42889613617                                </td><td>0.0                                        </td><td>-0.491570803304                                 </td><td>0.0                                   </td><td>0.0                                      </td><td>-0.460563118403                               </td><td>0.0                                        </td><td>-0.48217356837                                  </td><td>0.0                                    </td><td>0.0                                       </td><td>-0.498656485876                                </td><td>0.0                                         </td><td>-0.534660767923                                  </td><td>0.0                                    </td><td>0.0                                       </td><td>-0.520090902212                                </td><td>0.0                                         </td><td>-0.556323464661                                  </td><td>0.0                                          </td><td>0.0                     </td><td>0.0                           </td><td>0.0350877192982        </td><td>0.149805447471                    </td><td>0.027027027027                   </td><td>0.0                        </td><td>0.0                              </td><td>0.0350877192982           </td><td>0.338003502627                       </td><td>0.0                                 </td><td>0.198018796757     </td><td>-0.857533107517         </td><td>0.207790229847            </td><td>0.291506169615          </td><td>0.0143377885784             </td><td>0.00631834750911            </td><td>-0.258333333333              </td><td>0.0154313487242           </td><td>0.00680437424058          </td><td>-0.153571428571            </td><td>-0.0578947368421                          </td><td>0.0138121546961          </td><td>-318.248583911  </td></tr>\n",
       "<tr><td>mean   </td><td>0.00781630937369</td><td>1.55911885246 </td><td>1.55911885246  </td><td>0.798262829546                          </td><td>0.381405020138                               </td><td>0.844322940449                                     </td><td>0.280580533121                        </td><td>0.0993516849171                            </td><td>0.865424927114                                   </td><td>0.847424287929                               </td><td>0.476928760688                                    </td><td>0.869765486756                                          </td><td>0.499634126486                             </td><td>0.241089173529                                  </td><td>0.909759660883                                        </td><td>0.581750093338                </td><td>0.632120208686                </td><td>0.0941935222684               </td><td>2.48483833772                             </td><td>-1.03429426541                           </td><td>0.0776281736845                       </td><td>2.13189391015              </td><td>0.0934026061612                       </td><td>0.24528685372                     </td><td>0.370061254729                    </td><td>-1.40657702187        </td><td>-0.464908502226        </td><td>-0.810800424751         </td><td>-0.464908506639          </td><td>0.137989136123                      </td><td>-0.730318551138           </td><td>0.144084169963                      </td><td>0.340592150063                  </td><td>0.521719966372                  </td><td>0.088940325449                        </td><td>1.0303680713               </td><td>0.101686652436                        </td><td>0.268155390921                    </td><td>0.406072456915                    </td><td>0.219838970024                   </td><td>0.410004203016                              </td><td>0.0515390551739                       </td><td>0.517881823064                           </td><td>0.255783899472                                </td><td>0.50242856244                              </td><td>0.318258251671                                  </td><td>0.0357534050039                       </td><td>0.485623660773                           </td><td>0.220798008953                                </td><td>0.487496947216                             </td><td>0.299979164246                                  </td><td>0.262499534571                         </td><td>0.778097440321                            </td><td>0.488569297178                                 </td><td>0.732038084739                              </td><td>0.535154300897                                   </td><td>0.236929141411                         </td><td>0.764854501914                            </td><td>0.451720239363                                 </td><td>0.721389156823                              </td><td>0.511969643896                                   </td><td>0.0156247027781                              </td><td>0.326395979424          </td><td>0.201667751196                </td><td>0.471936269381         </td><td>0.495098414247                    </td><td>0.504901585753                   </td><td>0.333427998289             </td><td>0.221573505688                   </td><td>0.444998496024            </td><td>0.606221754676                       </td><td>0.393778245324                      </td><td>0.87431465259      </td><td>0.398552683477          </td><td>0.641296348879            </td><td>0.862382578799          </td><td>0.118464144991              </td><td>0.0834211751593             </td><td>0.00348005954914             </td><td>0.16196091862             </td><td>0.118789330019            </td><td>0.00196259065693           </td><td>0.0525409866168                           </td><td>0.271858299261           </td><td>-0.0561824032942</td></tr>\n",
       "<tr><td>maxs   </td><td>1.0             </td><td>8.23          </td><td>8.23           </td><td>0.989624550771                          </td><td>0.971537067837                               </td><td>0.96575768038                                      </td><td>0.917662935482                        </td><td>0.911534939344                             </td><td>0.948889360008                                   </td><td>0.999942703723                               </td><td>0.999786667157                                    </td><td>0.997222019314                                          </td><td>0.99947276284                              </td><td>0.998850137632                                  </td><td>0.99779627477                                         </td><td>2.51386698882                 </td><td>6.99004706959                 </td><td>2.7027027027                  </td><td>17.6774193548                             </td><td>1.7293814433                             </td><td>1.63855421687                         </td><td>6.90775527898              </td><td>1.45161290323                         </td><td>1.0                               </td><td>1.0                               </td><td>2.51134751773         </td><td>0.0                    </td><td>2.55317460317           </td><td>0.0                      </td><td>1.54296875                          </td><td>2.99573227355             </td><td>1.30188679245                       </td><td>1.0                             </td><td>1.0                             </td><td>1.54296875                            </td><td>3.91202300543              </td><td>1.45283018868                         </td><td>1.0                               </td><td>1.0                               </td><td>0.967741935484                   </td><td>1.0                                         </td><td>0.924303                              </td><td>0.974268384883                           </td><td>0.973036578483                                </td><td>0.979181999493                             </td><td>0.974439646594                                  </td><td>0.994142                              </td><td>0.978076923158                           </td><td>0.974219966409                                </td><td>0.981908787616                             </td><td>0.979784062696                                  </td><td>0.988413                               </td><td>0.993527697866                            </td><td>0.988948779353                                 </td><td>0.994590145383                              </td><td>0.992714380887                                   </td><td>0.992794                               </td><td>0.999314983893                            </td><td>0.996898003594                                 </td><td>0.997024614854                              </td><td>0.992056368073                                   </td><td>0.999511                                     </td><td>0.964912280702          </td><td>0.59595959596                 </td><td>0.97619047619          </td><td>0.972972972973                    </td><td>0.850194552529                   </td><td>0.964912280702             </td><td>0.826086956522                   </td><td>0.906976744186            </td><td>1.0                                  </td><td>0.661996497373                      </td><td>0.999996711954     </td><td>0.999987684474          </td><td>0.99750853858             </td><td>1.83528811831           </td><td>1.63356643357               </td><td>1.63356643357               </td><td>1.54195804196                </td><td>6.25                      </td><td>6.15                      </td><td>0.951773049645             </td><td>3.58095238095                             </td><td>7.10996563574            </td><td>3.82616089595   </td></tr>\n",
       "<tr><td>sigma  </td><td>0.0880637429998 </td><td>1.07368229598 </td><td>1.07368229598  </td><td>0.10977762883                           </td><td>0.251039369496                               </td><td>0.0479192788752                                    </td><td>0.113341085037                        </td><td>0.0910612296786                            </td><td>0.0343246420661                                  </td><td>0.109944524679                               </td><td>0.279710967211                                    </td><td>0.0523106639329                                         </td><td>0.190531995177                             </td><td>0.182818271794                                  </td><td>0.0411607145814                                       </td><td>0.226842350062                </td><td>0.510597635358                </td><td>0.104075353145                </td><td>1.36659316416                             </td><td>1.52858045404                            </td><td>0.0762703176305                       </td><td>3.46489739315              </td><td>0.123962581874                        </td><td>0.219774475043                    </td><td>0.281338762801                    </td><td>1.86800265716         </td><td>3.22348829895          </td><td>0.239838997857          </td><td>3.22348828351            </td><td>0.0913751203836                     </td><td>1.53835234971             </td><td>0.124762158094                      </td><td>0.183761177176                  </td><td>0.183985866931                  </td><td>0.0799691812228                       </td><td>2.34425982986              </td><td>0.124783151017                        </td><td>0.217903457178                    </td><td>0.270820369233                    </td><td>0.132739937398                   </td><td>0.181334756836                              </td><td>0.0462752806948                       </td><td>0.179003002251                           </td><td>0.197289241966                                </td><td>0.192264043838                             </td><td>0.22515215717                                   </td><td>0.0419631521264                       </td><td>0.177815887017                           </td><td>0.195105238926                                </td><td>0.194314792192                             </td><td>0.22709062476                                   </td><td>0.0974080586347                        </td><td>0.0958743258532                           </td><td>0.191964302179                                 </td><td>0.133888874763                              </td><td>0.224979511387                                   </td><td>0.113745769311                         </td><td>0.0995905400044                           </td><td>0.195510232682                                 </td><td>0.134385199381                              </td><td>0.224858701604                                   </td><td>0.0577946022168                              </td><td>0.223592802392          </td><td>0.141373956758                </td><td>0.139954990966         </td><td>0.112170234305                    </td><td>0.112170234305                   </td><td>0.224378636566             </td><td>0.163594972967                   </td><td>0.131486471186            </td><td>0.139622226133                       </td><td>0.139622226133                      </td><td>0.106567052008     </td><td>0.413191030487          </td><td>0.138901785131            </td><td>0.0933886985925         </td><td>0.0789465640215             </td><td>0.0561030708155             </td><td>0.0303180697274              </td><td>0.230505968523            </td><td>0.216174480651            </td><td>0.0165049856188            </td><td>0.0691958816928                           </td><td>0.19313611772            </td><td>2.78490080535   </td></tr>\n",
       "<tr><td>zeros  </td><td>944162          </td><td>0             </td><td>0              </td><td>0                                       </td><td>38                                           </td><td>0                                                  </td><td>834                                   </td><td>0                                          </td><td>0                                                </td><td>0                                            </td><td>2                                                 </td><td>0                                                       </td><td>144                                        </td><td>0                                               </td><td>0                                                     </td><td>5                             </td><td>198                           </td><td>4                             </td><td>0                                         </td><td>0                                        </td><td>260579                                </td><td>7718                       </td><td>260579                                </td><td>269673                            </td><td>261968                            </td><td>5                     </td><td>479082                 </td><td>5                       </td><td>479082                   </td><td>10                                  </td><td>19759                     </td><td>10                                  </td><td>5589                            </td><td>336                             </td><td>199467                                </td><td>8986                       </td><td>199467                                </td><td>209037                            </td><td>200800                            </td><td>2280                             </td><td>38                                          </td><td>26928                                 </td><td>26928                                    </td><td>26928                                         </td><td>26928                                      </td><td>26928                                           </td><td>26928                                 </td><td>26928                                    </td><td>26928                                         </td><td>26928                                      </td><td>26928                                           </td><td>99                                     </td><td>99                                        </td><td>99                                             </td><td>99                                          </td><td>99                                               </td><td>99                                     </td><td>99                                        </td><td>99                                             </td><td>99                                          </td><td>99                                               </td><td>673700                                       </td><td>72150                   </td><td>116025                        </td><td>0                      </td><td>0                                 </td><td>0                                </td><td>65325                      </td><td>151125                           </td><td>0                         </td><td>0                                    </td><td>22425                               </td><td>0                  </td><td>9                       </td><td>0                         </td><td>0                       </td><td>0                           </td><td>0                           </td><td>25279                        </td><td>0                         </td><td>0                         </td><td>61275                      </td><td>552                                       </td><td>0                        </td><td>1212            </td></tr>\n",
       "<tr><td>missing</td><td>0               </td><td>0             </td><td>0              </td><td>0                                       </td><td>0                                            </td><td>0                                                  </td><td>0                                     </td><td>0                                          </td><td>0                                                </td><td>0                                            </td><td>0                                                 </td><td>0                                                       </td><td>0                                          </td><td>0                                               </td><td>0                                                     </td><td>0                             </td><td>0                             </td><td>0                             </td><td>0                                         </td><td>0                                        </td><td>0                                     </td><td>0                          </td><td>0                                     </td><td>0                                 </td><td>0                                 </td><td>0                     </td><td>0                      </td><td>0                       </td><td>0                        </td><td>0                                   </td><td>0                         </td><td>0                                   </td><td>0                               </td><td>0                               </td><td>0                                     </td><td>0                          </td><td>0                                     </td><td>0                                 </td><td>0                                 </td><td>0                                </td><td>0                                           </td><td>0                                     </td><td>0                                        </td><td>0                                             </td><td>0                                          </td><td>0                                               </td><td>0                                     </td><td>0                                        </td><td>0                                             </td><td>0                                          </td><td>0                                               </td><td>0                                      </td><td>0                                         </td><td>0                                              </td><td>0                                           </td><td>0                                                </td><td>0                                      </td><td>0                                         </td><td>0                                              </td><td>0                                           </td><td>0                                                </td><td>0                                            </td><td>0                       </td><td>0                             </td><td>0                      </td><td>0                                 </td><td>0                                </td><td>0                          </td><td>0                                </td><td>0                         </td><td>0                                    </td><td>0                                   </td><td>0                  </td><td>0                       </td><td>0                         </td><td>0                       </td><td>0                           </td><td>0                           </td><td>0                            </td><td>0                         </td><td>0                         </td><td>0                          </td><td>0                                         </td><td>0                        </td><td>0               </td></tr>\n",
       "<tr><td>0      </td><td>NO              </td><td>0.86          </td><td>2.51           </td><td>0.69801121332                           </td><td>0.0129149079485                              </td><td>0.809199735874                                     </td><td>0.270974960511                        </td><td>0.0427896376978                            </td><td>0.876369116842                                   </td><td>0.868627475072                               </td><td>0.452406748573                                    </td><td>0.87672594583                                           </td><td>0.600177632149                             </td><td>0.263828426616                                  </td><td>0.935274598806                                        </td><td>0.439352251735                </td><td>0.339785228557                </td><td>0.093023255814                </td><td>1.75581395349                             </td><td>-2.1976744186                            </td><td>0.16976744186                         </td><td>-0.430782916092            </td><td>0.139534883721                        </td><td>0.33                              </td><td>0.33                              </td><td>-2.61511627907        </td><td>0.0                    </td><td>-0.873255813953         </td><td>-0.198450938724          </td><td>0.136046511628                      </td><td>1.50407739678             </td><td>0.232558139535                      </td><td>0.1                             </td><td>0.35                            </td><td>0.118604651163                        </td><td>2.63905732962              </td><td>0.0697674418605                       </td><td>0.0                               </td><td>0.5                               </td><td>0.220930232558                   </td><td>0.581395348837                              </td><td>0.0229472686905                       </td><td>0.526592567947                           </td><td>0.191639038818                                </td><td>0.537929373295                             </td><td>0.301708457176                                  </td><td>0.0139027040702                       </td><td>0.553370683028                           </td><td>0.26282427476                                 </td><td>0.503738286626                             </td><td>0.262898716447                                  </td><td>0.28208439942                          </td><td>0.763290997966                            </td><td>0.427663172777                                 </td><td>0.761204462629                              </td><td>0.578318193392                                   </td><td>0.241353475058                         </td><td>0.73209381135                             </td><td>0.309420190767                                 </td><td>0.710734993826                              </td><td>0.470352794231                                   </td><td>0.0                                          </td><td>0.627906976744          </td><td>0.0                           </td><td>0.372093023256         </td><td>0.546511627907                    </td><td>0.453488372093                   </td><td>0.374501992032             </td><td>0.223107569721                   </td><td>0.402390438247            </td><td>0.446215139442                       </td><td>0.553784860558                      </td><td>0.932923972259     </td><td>0.682791834197          </td><td>0.692490152514            </td><td>0.879875845455          </td><td>0.15                        </td><td>0.122093023256              </td><td>-0.0093023255814             </td><td>0.154651162791            </td><td>0.0941860465116           </td><td>-0.0313953488372           </td><td>0.0779069767442                           </td><td>0.395348837209           </td><td>0.0844290831909 </td></tr>\n",
       "<tr><td>1      </td><td>NO              </td><td>0.86          </td><td>1.4            </td><td>0.762213800753                          </td><td>0.230031710821                               </td><td>0.828307292175                                     </td><td>0.188450797209                        </td><td>-0.00435811988434                          </td><td>0.862555747227                                   </td><td>0.833398050038                               </td><td>0.266497645664                                    </td><td>0.863137158801                                          </td><td>0.487572776541                             </td><td>0.0939487737733                                 </td><td>0.925751564249                                        </td><td>0.57288364436                 </td><td>0.76                          </td><td>0.0348837209302               </td><td>1.54651162791                             </td><td>-0.906976744186                          </td><td>0.160465116279                        </td><td>-0.462035459597            </td><td>0.0697674418605                       </td><td>0.33                              </td><td>0.66                              </td><td>-1.19651162791        </td><td>0.0                    </td><td>-0.876744186047         </td><td>-0.186329578191          </td><td>0.158139534884                      </td><td>-0.478035800943           </td><td>0.0581395348837                     </td><td>0.4                             </td><td>0.6                             </td><td>0.126744186047                        </td><td>1.56861591791              </td><td>0.046511627907                        </td><td>0.25                              </td><td>0.5                               </td><td>0.197674418605                   </td><td>0.56976744186                               </td><td>0.0261394677193                       </td><td>0.566081564138                           </td><td>0.338105369392                                </td><td>0.559160939866                             </td><td>0.386797534671                                  </td><td>0.00987395312105                      </td><td>0.462420728567                           </td><td>0.169384728013                                </td><td>0.540077513131                             </td><td>0.36209926587                                   </td><td>0.169304193261                         </td><td>0.767769058904                            </td><td>0.447522039884                                 </td><td>0.72156160536                               </td><td>0.474078003177                                   </td><td>0.124980963252                         </td><td>0.761362542453                            </td><td>0.406607138393                                 </td><td>0.746894880611                              </td><td>0.501056593104                                   </td><td>0.0                                          </td><td>0.627906976744          </td><td>0.0                           </td><td>0.372093023256         </td><td>0.546511627907                    </td><td>0.453488372093                   </td><td>0.107142857143             </td><td>0.328571428571                   </td><td>0.564285714286            </td><td>0.557142857143                       </td><td>0.442857142857                      </td><td>0.790755476826     </td><td>-0.0942779967637        </td><td>0.524543194249            </td><td>0.782558139535          </td><td>0.133720930233              </td><td>0.0802325581395             </td><td>-0.0348837209302             </td><td>0.145348837209            </td><td>0.0848837209302           </td><td>0.00232558139535           </td><td>0.0453488372093                           </td><td>0.290697674419           </td><td>1.0464016876    </td></tr>\n",
       "<tr><td>2      </td><td>NO              </td><td>0.86          </td><td>1.27           </td><td>0.697333054468                          </td><td>0.0602577923089                              </td><td>0.807849694879                                     </td><td>0.18621203667                         </td><td>0.00994525399747                           </td><td>0.858690343217                                   </td><td>0.828297937863                               </td><td>0.236809785598                                    </td><td>0.861344591485                                          </td><td>0.479975136592                             </td><td>0.092627360172                                  </td><td>0.924702936288                                        </td><td>0.390562087566                </td><td>0.51                          </td><td>0.0581395348837               </td><td>1.66279069767                             </td><td>-0.81511627907                           </td><td>0.179069767442                        </td><td>-1.66073120682             </td><td>0.279069767442                        </td><td>0.29                              </td><td>0.37                              </td><td>-1.2023255814         </td><td>0.0                    </td><td>-0.968604651163         </td><td>0.0                      </td><td>0.140697674419                      </td><td>0.530628251062            </td><td>0.127906976744                      </td><td>0.36                            </td><td>0.54                            </td><td>0.104651162791                        </td><td>2.83321334406              </td><td>0.0232558139535                       </td><td>0.5                               </td><td>1.0                               </td><td>0.116279069767                   </td><td>0.476744186047                              </td><td>0.0306705648571                       </td><td>0.582030528513                           </td><td>0.277507653501                                </td><td>0.442828462403                             </td><td>0.185460378572                                  </td><td>0.016601086881                        </td><td>0.509460785777                           </td><td>0.164192793763                                </td><td>0.40268878202                              </td><td>0.13942905623                                   </td><td>0.199159094831                         </td><td>0.781881499993                            </td><td>0.464261790403                                 </td><td>0.775786611884                              </td><td>0.573653704501                                   </td><td>0.164283082867                         </td><td>0.753278008902                            </td><td>0.353662307565                                 </td><td>0.777224037807                              </td><td>0.55821001632                                    </td><td>0.0                                          </td><td>0.627906976744          </td><td>0.0                           </td><td>0.372093023256         </td><td>0.546511627907                    </td><td>0.453488372093                   </td><td>0.141732283465             </td><td>0.40157480315                    </td><td>0.456692913386            </td><td>0.566929133858                       </td><td>0.433070866142                      </td><td>0.792498908032     </td><td>-0.227614507588         </td><td>0.528938936692            </td><td>0.765152902399          </td><td>0.132558139535              </td><td>0.0906976744186             </td><td>-0.0220930232558             </td><td>0.143023255814            </td><td>0.0883720930233           </td><td>0.00116279069767           </td><td>0.056976744186                            </td><td>0.290697674419           </td><td>0.902107526397  </td></tr>\n",
       "<tr><td>3      </td><td>NO              </td><td>0.86          </td><td>1.25           </td><td>0.73188699459                           </td><td>0.324057245486                               </td><td>0.80993210157                                      </td><td>0.251544856589                        </td><td>0.0984522628612                            </td><td>0.861550134095                                   </td><td>0.8915770858                                 </td><td>0.567426316154                                    </td><td>0.8866606479                                            </td><td>0.541458939597                             </td><td>0.243104889836                                  </td><td>0.926599673517                                        </td><td>0.57288364436                 </td><td>0.513755265579                </td><td>0.046511627907                </td><td>1.83720930233                             </td><td>-0.852325581395                          </td><td>0.124418604651                        </td><td>1.5260563035               </td><td>0.151162790698                        </td><td>0.23                              </td><td>0.46                              </td><td>-1.66744186047        </td><td>0.0                    </td><td>-0.881395348837         </td><td>-0.150822889735          </td><td>0.152325581395                      </td><td>-0.235722333521           </td><td>0.046511627907                      </td><td>0.5                             </td><td>0.75                            </td><td>0.152325581395                        </td><td>-0.0512932943876           </td><td>0.046511627907                        </td><td>0.5                               </td><td>0.75                              </td><td>0.348837209302                   </td><td>0.697674418605                              </td><td>0.0332328787629                       </td><td>0.57473115821                            </td><td>0.268901336728                                </td><td>0.403359406703                             </td><td>0.0740421012883                                 </td><td>0.0115028680546                       </td><td>0.496111193775                           </td><td>0.141856196864                                </td><td>0.372534164029                             </td><td>0.0441030494539                                 </td><td>0.272502415242                         </td><td>0.838827764847                            </td><td>0.526259092191                                 </td><td>0.640697013913                              </td><td>0.273850131619                                   </td><td>0.245734481836                         </td><td>0.878058016076                            </td><td>0.631118980934                                 </td><td>0.716635437967                              </td><td>0.395930050856                                   </td><td>0.0                                          </td><td>0.627906976744          </td><td>0.0                           </td><td>0.372093023256         </td><td>0.546511627907                    </td><td>0.453488372093                   </td><td>0.344                      </td><td>0.328                            </td><td>0.328                     </td><td>0.536                                </td><td>0.464                               </td><td>0.903592886628     </td><td>0.447512043914          </td><td>0.646427722089            </td><td>0.841395348837          </td><td>0.137209302326              </td><td>0.110465116279              </td><td>0.0267441860465              </td><td>0.146511627907            </td><td>0.0988372093023           </td><td>0.00581395348837           </td><td>0.0639534883721                           </td><td>0.348837209302           </td><td>-0.76098309953  </td></tr>\n",
       "<tr><td>4      </td><td>NO              </td><td>0.86          </td><td>2.26           </td><td>0.834666848733                          </td><td>0.489393835919                               </td><td>0.853503362115                                     </td><td>0.274250900631                        </td><td>0.0594720488896                            </td><td>0.875494143581                                   </td><td>0.902063601211                               </td><td>0.575538030866                                    </td><td>0.893062254348                                          </td><td>0.61721873681                              </td><td>0.291761250757                                  </td><td>0.936711423368                                        </td><td>0.57288364436                 </td><td>0.342503510386                </td><td>0.186046511628                </td><td>1.82558139535                             </td><td>-1.97674418605                           </td><td>0.143023255814                        </td><td>1.19392246847              </td><td>0.220930232558                        </td><td>0.26                              </td><td>0.36                              </td><td>-2.25                 </td><td>0.0                    </td><td>-0.937209302326         </td><td>0.0                      </td><td>0.167441860465                      </td><td>-0.478035800943           </td><td>0.116279069767                      </td><td>0.3                             </td><td>0.6                             </td><td>0.167441860465                        </td><td>-0.371063681391            </td><td>0.116279069767                        </td><td>0.3                               </td><td>0.6                               </td><td>0.313953488372                   </td><td>0.523255813953                              </td><td>0.0200703156881                       </td><td>0.519053399564                           </td><td>0.144325992353                                </td><td>0.45447613025                              </td><td>0.122964439541                                  </td><td>0.00524405492752                      </td><td>0.413415276542                           </td><td>-0.0257059171813                              </td><td>0.434846777438                             </td><td>0.104153019924                                  </td><td>0.197308816859                         </td><td>0.765919780288                            </td><td>0.473000337504                                 </td><td>0.724084252078                              </td><td>0.487393205503                                   </td><td>0.147984311062                         </td><td>0.771209208563                            </td><td>0.475630234694                                 </td><td>0.774310790255                              </td><td>0.567424718619                                   </td><td>0.0                                          </td><td>0.627906976744          </td><td>0.0                           </td><td>0.372093023256         </td><td>0.546511627907                    </td><td>0.453488372093                   </td><td>0.309734513274             </td><td>0.247787610619                   </td><td>0.442477876106            </td><td>0.482300884956                       </td><td>0.517699115044                      </td><td>0.911298321357     </td><td>0.50924667367           </td><td>0.657491238648            </td><td>0.857480963161          </td><td>0.146511627907              </td><td>0.117441860465              </td><td>0.00581395348837             </td><td>0.152325581395            </td><td>0.0895348837209           </td><td>-0.00813953488372          </td><td>0.0372093023256                           </td><td>0.302325581395           </td><td>1.19388567607   </td></tr>\n",
       "<tr><td>5      </td><td>NO              </td><td>0.86          </td><td>0.92           </td><td>0.696224255522                          </td><td>0.134797195009                               </td><td>0.804850806912                                     </td><td>0.179513408799                        </td><td>0.0170406160982                            </td><td>0.853947270599                                   </td><td>0.827669936624                               </td><td>0.340746063445                                    </td><td>0.858366009156                                          </td><td>0.494979333377                             </td><td>0.191861661643                                  </td><td>0.921193733989                                        </td><td>0.390562087566                </td><td>0.413178837926                </td><td>0.0581395348837               </td><td>2.61627906977                             </td><td>-0.446511627907                          </td><td>0.106976744186                        </td><td>2.48490664979              </td><td>0.0348837209302                       </td><td>0.66                              </td><td>0.66                              </td><td>-1.08372093023        </td><td>0.0                    </td><td>-1.02093023256          </td><td>0.0                      </td><td>0.140697674419                      </td><td>0.0953101798043           </td><td>0.0697674418605                     </td><td>0.33                            </td><td>0.66                            </td><td>0.0                                   </td><td>3.91202300543              </td><td>0.0                                   </td><td>0.0                               </td><td>0.0                               </td><td>0.209302325581                   </td><td>0.604651162791                              </td><td>0.0235465923729                       </td><td>0.471020718295                           </td><td>0.181901689184                                </td><td>0.362560532781                             </td><td>0.0841274158657                                 </td><td>0.00873813309153                      </td><td>0.42677275023                            </td><td>0.121301154893                                </td><td>0.325409306942                             </td><td>0.0389880017503                                 </td><td>0.256961119086                         </td><td>0.616390876694                            </td><td>0.0352931690314                                </td><td>0.443670179606                              </td><td>-0.0451126379559                                 </td><td>0.246190598333                         </td><td>0.690476861754                            </td><td>0.176608021883                                 </td><td>0.534778364015                              </td><td>0.079833547383                                   </td><td>0.0                                          </td><td>0.627906976744          </td><td>0.0                           </td><td>0.372093023256         </td><td>0.546511627907                    </td><td>0.453488372093                   </td><td>0.184782608696             </td><td>0.141304347826                   </td><td>0.673913043478            </td><td>0.771739130435                       </td><td>0.228260869565                      </td><td>0.814752590612     </td><td>0.316934162684          </td><td>0.527590764481            </td><td>0.892062689585          </td><td>0.133720930233              </td><td>0.109302325581              </td><td>0.0151162790698              </td><td>0.141860465116            </td><td>0.096511627907            </td><td>0.0197674418605            </td><td>0.0639534883721                           </td><td>0.348837209302           </td><td>0.115049969147  </td></tr>\n",
       "<tr><td>6      </td><td>NO              </td><td>0.86          </td><td>2.24           </td><td>0.858702767797                          </td><td>0.599012470184                               </td><td>0.862152740006                                     </td><td>0.315011751634                        </td><td>0.138100932647                             </td><td>0.875423976367                                   </td><td>0.949049209897                               </td><td>0.808874895037                                    </td><td>0.920042997709                                          </td><td>0.723716461939                             </td><td>0.525637601735                                  </td><td>0.944012444247                                        </td><td>0.978348752468                </td><td>1.95444463466                 </td><td>0.232558139535                </td><td>1.83720930233                             </td><td>-1.87209302326                           </td><td>0.196511627907                        </td><td>-2.04022082853             </td><td>0.302325581395                        </td><td>0.26                              </td><td>0.42                              </td><td>-2.43372093023        </td><td>0.0                    </td><td>-0.670930232558         </td><td>-3.64965874096           </td><td>0.166279069767                      </td><td>-0.430782916092           </td><td>0.220930232558                      </td><td>0.47                            </td><td>0.52                            </td><td>0.166279069767                        </td><td>-0.31471074484             </td><td>0.220930232558                        </td><td>0.47                              </td><td>0.52                              </td><td>0.209302325581                   </td><td>0.56976744186                               </td><td>0.0486275488235                       </td><td>0.573228311296                           </td><td>0.391383823954                                </td><td>0.623946090197                             </td><td>0.540726819385                                  </td><td>0.0263623931275                       </td><td>0.498369244009                           </td><td>0.268745614329                                </td><td>0.612952673879                             </td><td>0.5225194047                                    </td><td>0.270739937143                         </td><td>0.88998879313                             </td><td>0.774464200672                                 </td><td>0.871474803411                              </td><td>0.800329679152                                   </td><td>0.253795529379                         </td><td>0.833766970526                            </td><td>0.633545218412                                 </td><td>0.826056104612                              </td><td>0.724312743911                                   </td><td>0.0                                          </td><td>0.627906976744          </td><td>0.0                           </td><td>0.372093023256         </td><td>0.546511627907                    </td><td>0.453488372093                   </td><td>0.316964285714             </td><td>0.21875                          </td><td>0.464285714286            </td><td>0.549107142857                       </td><td>0.450892857143                      </td><td>0.923299802892     </td><td>0.598280226865          </td><td>0.67623413712             </td><td>0.876349667774          </td><td>0.15                        </td><td>0.104651162791              </td><td>0.00813953488372             </td><td>0.155813953488            </td><td>0.1                       </td><td>0.0151162790698            </td><td>0.0674418604651                           </td><td>0.418604651163           </td><td>-0.662370810861 </td></tr>\n",
       "<tr><td>7      </td><td>NO              </td><td>0.86          </td><td>0.9            </td><td>0.86327878748                           </td><td>0.598302730796                               </td><td>0.8649218264                                       </td><td>0.28358588369                         </td><td>0.139501348528                             </td><td>0.863558654429                                   </td><td>0.919916036917                               </td><td>0.649300968833                                    </td><td>0.902837382388                                          </td><td>0.542066521141                             </td><td>0.245306642313                                  </td><td>0.926549075198                                        </td><td>0.57288364436                 </td><td>0.45938962901                 </td><td>0.0581395348837               </td><td>2.26744186047                             </td><td>-0.467441860465                          </td><td>0.0                                   </td><td>6.90775527898              </td><td>0.0                                   </td><td>0.0                               </td><td>0.0                               </td><td>-1.03837209302        </td><td>0.0                    </td><td>-0.846511627907         </td><td>-0.478035800943          </td><td>0.159302325581                      </td><td>-1.02165124753            </td><td>0.162790697674                      </td><td>0.28                            </td><td>0.57                            </td><td>0.118604651163                        </td><td>1.64865862559              </td><td>0.093023255814                        </td><td>0.37                              </td><td>0.62                              </td><td>0.418604651163                   </td><td>0.53488372093                               </td><td>0.0181503426786                       </td><td>0.427071834296                           </td><td>0.105344795322                                </td><td>0.48427153413                              </td><td>0.234757833281                                  </td><td>0.00814949438929                      </td><td>0.344905089641                           </td><td>-0.0111651342443                              </td><td>0.46057641714                              </td><td>0.214734509952                                  </td><td>0.271403473455                         </td><td>0.837980200902                            </td><td>0.510588830636                                 </td><td>0.776679902411                              </td><td>0.552586576387                                   </td><td>0.231396170815                         </td><td>0.818654948446                            </td><td>0.42082157619                                  </td><td>0.797085578468                              </td><td>0.589961715004                                   </td><td>0.0                                          </td><td>0.627906976744          </td><td>0.0                           </td><td>0.372093023256         </td><td>0.546511627907                    </td><td>0.453488372093                   </td><td>0.577777777778             </td><td>0.0                              </td><td>0.422222222222            </td><td>0.644444444444                       </td><td>0.355555555556                      </td><td>0.988454116977     </td><td>0.95124077884           </td><td>0.85591197193             </td><td>1.03333333333           </td><td>0.13023255814               </td><td>0.0941860465116             </td><td>-0.00232558139535            </td><td>0.141860465116            </td><td>0.0883720930233           </td><td>-0.00116279069767          </td><td>0.0674418604651                           </td><td>0.290697674419           </td><td>0.401182973614  </td></tr>\n",
       "<tr><td>8      </td><td>NO              </td><td>0.86          </td><td>0.57           </td><td>0.878200979139                          </td><td>0.677383727195                               </td><td>0.869394709485                                     </td><td>0.248525060874                        </td><td>0.12541408933                              </td><td>0.849043311701                                   </td><td>0.938726553772                               </td><td>0.742674485793                                    </td><td>0.914090802912                                          </td><td>0.589410660113                             </td><td>0.321071958624                                  </td><td>0.930480058206                                        </td><td>0.921190338628                </td><td>0.557247774834                </td><td>0.162790697674                </td><td>1.66279069767                             </td><td>-0.0118604651163                         </td><td>0.155813953488                        </td><td>-1.02165124753             </td><td>0.093023255814                        </td><td>0.37                              </td><td>0.75                              </td><td>-0.686046511628       </td><td>-0.105360515658        </td><td>-0.958139534884         </td><td>0.0                      </td><td>0.129069767442                      </td><td>0.182321556794            </td><td>0.0813953488372                     </td><td>0.42                            </td><td>0.85                            </td><td>0.129069767442                        </td><td>0.641853886172             </td><td>0.0813953488372                       </td><td>0.42                              </td><td>0.85                              </td><td>0.0813953488372                  </td><td>0.337209302326                              </td><td>0.0310228775591                       </td><td>0.712337881131                           </td><td>0.397894737738                                </td><td>0.830580363354                             </td><td>0.720931780724                                  </td><td>0.0172294203504                       </td><td>0.72262501204                            </td><td>0.453841831478                                </td><td>0.813434380012                             </td><td>0.700362909422                                  </td><td>0.209278150746                         </td><td>0.871270829217                            </td><td>0.736166514868                                 </td><td>0.916469228773                              </td><td>0.851355067066                                   </td><td>0.175158456426                         </td><td>0.81294893785                             </td><td>0.589139143032                                 </td><td>0.859026672947                              </td><td>0.745417795207                                   </td><td>0.0                                          </td><td>0.627906976744          </td><td>0.0                           </td><td>0.372093023256         </td><td>0.546511627907                    </td><td>0.453488372093                   </td><td>0.0526315789474            </td><td>0.508771929825                   </td><td>0.438596491228            </td><td>0.666666666667                       </td><td>0.333333333333                      </td><td>0.695610879143     </td><td>-0.395968839331         </td><td>0.454135743526            </td><td>0.711750305998          </td><td>0.123255813953              </td><td>0.0941860465116             </td><td>0.0162790697674              </td><td>0.139534883721            </td><td>0.11976744186             </td><td>0.0267441860465            </td><td>0.0779069767442                           </td><td>0.325581395349           </td><td>0.0528408598827 </td></tr>\n",
       "<tr><td>9      </td><td>NO              </td><td>0.86          </td><td>1.53           </td><td>0.725992150959                          </td><td>0.363881827737                               </td><td>0.802632126938                                     </td><td>0.216317947068                        </td><td>0.0759634307652                            </td><td>0.851619787812                                   </td><td>0.828390757408                               </td><td>0.550050542329                                    </td><td>0.845483142201                                          </td><td>0.432859379826                             </td><td>0.250179500451                                  </td><td>0.89284865744                                         </td><td>0.61370563888                 </td><td>0.28270131016                 </td><td>0.0697674418605               </td><td>2.44186046512                             </td><td>-1.0976744186                            </td><td>0.133720930233                        </td><td>1.28093384546              </td><td>0.0697674418605                       </td><td>0.33                              </td><td>0.66                              </td><td>-1.28023255814        </td><td>0.0                    </td><td>-0.697674418605         </td><td>-3.12356564506           </td><td>0.163953488372                      </td><td>-0.73396917508            </td><td>0.139534883721                      </td><td>0.41                            </td><td>0.66                            </td><td>0.0                                   </td><td>3.91202300543              </td><td>0.0                                   </td><td>0.0                               </td><td>0.0                               </td><td>0.43023255814                    </td><td>0.56976744186                               </td><td>0.0160425186364                       </td><td>0.43002453535                            </td><td>0.184785294502                                </td><td>0.336674078324                             </td><td>0.131486748135                                  </td><td>0.00823262863636                      </td><td>0.42482658916                            </td><td>0.184716911616                                </td><td>0.330817655735                             </td><td>0.130092193637                                  </td><td>0.274408275625                         </td><td>0.834527875347                            </td><td>0.59032996136                                  </td><td>0.803813303005                              </td><td>0.645651336873                                   </td><td>0.273357589053                         </td><td>0.840276381607                            </td><td>0.602386672497                                 </td><td>0.790936983097                              </td><td>0.609729600817                                   </td><td>0.0                                          </td><td>0.627906976744          </td><td>0.0                           </td><td>0.372093023256         </td><td>0.546511627907                    </td><td>0.453488372093                   </td><td>0.797385620915             </td><td>0.0                              </td><td>0.202614379085            </td><td>0.562091503268                       </td><td>0.437908496732                      </td><td>0.976078742753     </td><td>0.93348095502           </td><td>0.786085584356            </td><td>1.08185134519           </td><td>0.147674418605              </td><td>0.106976744186              </td><td>0.0151162790698              </td><td>0.152325581395            </td><td>0.103488372093            </td><td>0.0104651162791            </td><td>0.0697674418605                           </td><td>0.279069767442           </td><td>0.0861776962411 </td></tr>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "foldpro_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "h2o.frame.H2OFrame"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(foldpro_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Training a single model \n",
    "gbm_classifier = H2OGradientBoostingEstimator(\n",
    "                        distribution=\"multinomial\",\n",
    "                        ntrees=10, \n",
    "                        max_depth=3, \n",
    "                        min_rows=2, \n",
    "                        learn_rate=\"0.2\" ,\n",
    "                        nfolds = 10 , \n",
    "                        keep_cross_validation_predictions = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "gbm Model Build Progress: [##################################################] 100%\n"
     ]
    }
   ],
   "source": [
    "gbm_classifier.train(x=range(1,foldpro_df.ncol), \n",
    "                     y=0, \n",
    "                     training_frame= foldpro_df, \n",
    "                     seed = 1234\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OGradientBoostingEstimator :  Gradient Boosting Method\n",
      "Model Key:  GBM_model_python_1462800685859_1\n",
      "\n",
      "Model Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>model_size_in_bytes</b></td>\n",
       "<td><b>min_depth</b></td>\n",
       "<td><b>max_depth</b></td>\n",
       "<td><b>mean_depth</b></td>\n",
       "<td><b>min_leaves</b></td>\n",
       "<td><b>max_leaves</b></td>\n",
       "<td><b>mean_leaves</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>10.0</td>\n",
       "<td>1550.0</td>\n",
       "<td>3.0</td>\n",
       "<td>3.0</td>\n",
       "<td>3.0</td>\n",
       "<td>8.0</td>\n",
       "<td>8.0</td>\n",
       "<td>8.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    number_of_trees    model_size_in_bytes    min_depth    max_depth    mean_depth    min_leaves    max_leaves    mean_leaves\n",
       "--  -----------------  ---------------------  -----------  -----------  ------------  ------------  ------------  -------------\n",
       "    10                 1550                   3            3            3             8             8             8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.00607539176977\n",
      "R^2: 0.216605597742\n",
      "LogLoss: 0.0333002515568\n",
      "AUC: 0.882760782582\n",
      "Gini: 0.765521565164\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.167870822676: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>NO</b></td>\n",
       "<td><b>YES</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>NO</td>\n",
       "<td>942760.0</td>\n",
       "<td>1402.0</td>\n",
       "<td>0.0015</td>\n",
       "<td> (1402.0/944162.0)</td></tr>\n",
       "<tr><td>YES</td>\n",
       "<td>5481.0</td>\n",
       "<td>1957.0</td>\n",
       "<td>0.7369</td>\n",
       "<td> (5481.0/7438.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>948241.0</td>\n",
       "<td>3359.0</td>\n",
       "<td>0.0072</td>\n",
       "<td> (6883.0/951600.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       NO      YES    Error    Rate\n",
       "-----  ------  -----  -------  -----------------\n",
       "NO     942760  1402   0.0015   (1402.0/944162.0)\n",
       "YES    5481    1957   0.7369   (5481.0/7438.0)\n",
       "Total  948241  3359   0.0072   (6883.0/951600.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.1678708</td>\n",
       "<td>0.3625081</td>\n",
       "<td>193.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.0350622</td>\n",
       "<td>0.3560487</td>\n",
       "<td>295.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.5423960</td>\n",
       "<td>0.5397213</td>\n",
       "<td>62.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.5423960</td>\n",
       "<td>0.9936234</td>\n",
       "<td>62.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999985</td>\n",
       "<td>0.9256449</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0000171</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999985</td>\n",
       "<td>0.9998962</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_MCC</td>\n",
       "<td>0.5423960</td>\n",
       "<td>0.4303746</td>\n",
       "<td>62.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.0069754</td>\n",
       "<td>0.7987362</td>\n",
       "<td>376.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                      threshold    value     idx\n",
       "--------------------------  -----------  --------  -----\n",
       "max f1                      0.167871     0.362508  193\n",
       "max f2                      0.0350622    0.356049  295\n",
       "max f0point5                0.542396     0.539721  62\n",
       "max accuracy                0.542396     0.993623  62\n",
       "max precision               0.999999     0.925645  0\n",
       "max recall                  1.70583e-05  1         399\n",
       "max specificity             0.999999     0.999896  0\n",
       "max absolute_MCC            0.542396     0.430375  62\n",
       "max min_per_class_accuracy  0.00697539   0.798736  376"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate:  0.78 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0100126</td>\n",
       "<td>0.0438700</td>\n",
       "<td>36.9928775</td>\n",
       "<td>36.9928775</td>\n",
       "<td>0.2891478</td>\n",
       "<td>0.2891478</td>\n",
       "<td>0.3703953</td>\n",
       "<td>0.3703953</td>\n",
       "<td>3599.2877476</td>\n",
       "<td>3599.2877476</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200189</td>\n",
       "<td>0.0251556</td>\n",
       "<td>8.6124777</td>\n",
       "<td>22.8071470</td>\n",
       "<td>0.0673178</td>\n",
       "<td>0.1782677</td>\n",
       "<td>0.0861791</td>\n",
       "<td>0.4565743</td>\n",
       "<td>761.2477726</td>\n",
       "<td>2180.7146956</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0321227</td>\n",
       "<td>0.0212884</td>\n",
       "<td>4.8540319</td>\n",
       "<td>16.0424263</td>\n",
       "<td>0.0379406</td>\n",
       "<td>0.1253926</td>\n",
       "<td>0.0587524</td>\n",
       "<td>0.5153267</td>\n",
       "<td>385.4031855</td>\n",
       "<td>1504.2426342</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0402900</td>\n",
       "<td>0.0182520</td>\n",
       "<td>5.2017868</td>\n",
       "<td>13.8448924</td>\n",
       "<td>0.0406588</td>\n",
       "<td>0.1082160</td>\n",
       "<td>0.0424845</td>\n",
       "<td>0.5578112</td>\n",
       "<td>420.1786821</td>\n",
       "<td>1284.4892425</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0520481</td>\n",
       "<td>0.0148104</td>\n",
       "<td>3.2930587</td>\n",
       "<td>11.4611482</td>\n",
       "<td>0.0257396</td>\n",
       "<td>0.0895839</td>\n",
       "<td>0.0387201</td>\n",
       "<td>0.5965313</td>\n",
       "<td>229.3058708</td>\n",
       "<td>1046.1148205</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1017108</td>\n",
       "<td>0.0109854</td>\n",
       "<td>1.8895968</td>\n",
       "<td>6.7876149</td>\n",
       "<td>0.0147697</td>\n",
       "<td>0.0530541</td>\n",
       "<td>0.0938424</td>\n",
       "<td>0.6903738</td>\n",
       "<td>88.9596841</td>\n",
       "<td>578.7614855</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1502070</td>\n",
       "<td>0.0085776</td>\n",
       "<td>1.4554432</td>\n",
       "<td>5.0660565</td>\n",
       "<td>0.0113762</td>\n",
       "<td>0.0395979</td>\n",
       "<td>0.0705835</td>\n",
       "<td>0.7609572</td>\n",
       "<td>45.5443222</td>\n",
       "<td>406.6056485</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2004435</td>\n",
       "<td>0.0068416</td>\n",
       "<td>0.9018926</td>\n",
       "<td>4.0224067</td>\n",
       "<td>0.0070495</td>\n",
       "<td>0.0314404</td>\n",
       "<td>0.0453079</td>\n",
       "<td>0.8062651</td>\n",
       "<td>-9.8107371</td>\n",
       "<td>302.2406670</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3172751</td>\n",
       "<td>0.0050221</td>\n",
       "<td>0.5972424</td>\n",
       "<td>2.7611429</td>\n",
       "<td>0.0046682</td>\n",
       "<td>0.0215819</td>\n",
       "<td>0.0697768</td>\n",
       "<td>0.8760419</td>\n",
       "<td>-40.2757553</td>\n",
       "<td>176.1142944</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4278815</td>\n",
       "<td>0.0041592</td>\n",
       "<td>0.4120629</td>\n",
       "<td>2.1539113</td>\n",
       "<td>0.0032208</td>\n",
       "<td>0.0168356</td>\n",
       "<td>0.0455768</td>\n",
       "<td>0.9216187</td>\n",
       "<td>-58.7937138</td>\n",
       "<td>115.3911293</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5306452</td>\n",
       "<td>0.0035987</td>\n",
       "<td>0.2106346</td>\n",
       "<td>1.7775799</td>\n",
       "<td>0.0016464</td>\n",
       "<td>0.0138941</td>\n",
       "<td>0.0216456</td>\n",
       "<td>0.9432643</td>\n",
       "<td>-78.9365411</td>\n",
       "<td>77.7579947</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.9998518</td>\n",
       "<td>0.0034987</td>\n",
       "<td>0.1040127</td>\n",
       "<td>0.9922148</td>\n",
       "<td>0.0008130</td>\n",
       "<td>0.0077555</td>\n",
       "<td>0.0488034</td>\n",
       "<td>0.9920678</td>\n",
       "<td>-89.5987307</td>\n",
       "<td>-0.7785222</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>53.5341804</td>\n",
       "<td>1.0</td>\n",
       "<td>0.4184397</td>\n",
       "<td>0.0078163</td>\n",
       "<td>0.0079322</td>\n",
       "<td>1.0</td>\n",
       "<td>5253.4180431</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  --------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0100126                   0.04387            36.9929   36.9929            0.289148         0.289148                    0.370395        0.370395                   3599.29   3599.29\n",
       "    2        0.0200189                   0.0251556          8.61248   22.8071            0.0673178        0.178268                    0.0861791       0.456574                   761.248   2180.71\n",
       "    3        0.0321227                   0.0212884          4.85403   16.0424            0.0379406        0.125393                    0.0587524       0.515327                   385.403   1504.24\n",
       "    4        0.04029                     0.018252           5.20179   13.8449            0.0406588        0.108216                    0.0424845       0.557811                   420.179   1284.49\n",
       "    5        0.0520481                   0.0148104          3.29306   11.4611            0.0257396        0.0895839                   0.0387201       0.596531                   229.306   1046.11\n",
       "    6        0.101711                    0.0109854          1.8896    6.78761            0.0147697        0.0530541                   0.0938424       0.690374                   88.9597   578.761\n",
       "    7        0.150207                    0.00857764         1.45544   5.06606            0.0113762        0.0395979                   0.0705835       0.760957                   45.5443   406.606\n",
       "    8        0.200443                    0.00684164         0.901893  4.02241            0.00704947       0.0314404                   0.0453079       0.806265                   -9.81074  302.241\n",
       "    9        0.317275                    0.00502209         0.597242  2.76114            0.00466823       0.0215819                   0.0697768       0.876042                   -40.2758  176.114\n",
       "    10       0.427881                    0.0041592          0.412063  2.15391            0.00322081       0.0168356                   0.0455768       0.921619                   -58.7937  115.391\n",
       "    11       0.530645                    0.00359874         0.210635  1.77758            0.00164639       0.0138941                   0.0216456       0.943264                   -78.9365  77.758\n",
       "    12       0.999852                    0.00349874         0.104013  0.992215           0.000812995      0.00775546                  0.0488034       0.992068                   -89.5987  -0.778522\n",
       "    13       1                           4.51941e-14        53.5342   1                  0.41844          0.00781631                  0.00793224      1                          5253.42   0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.00622004453858\n",
      "R^2: 0.197953274788\n",
      "LogLoss: 0.038927101568\n",
      "AUC: 0.861220816776\n",
      "Gini: 0.722441633552\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.196466489041: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>NO</b></td>\n",
       "<td><b>YES</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>NO</td>\n",
       "<td>943111.0</td>\n",
       "<td>1051.0</td>\n",
       "<td>0.0011</td>\n",
       "<td> (1051.0/944162.0)</td></tr>\n",
       "<tr><td>YES</td>\n",
       "<td>5673.0</td>\n",
       "<td>1765.0</td>\n",
       "<td>0.7627</td>\n",
       "<td> (5673.0/7438.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>948784.0</td>\n",
       "<td>2816.0</td>\n",
       "<td>0.0071</td>\n",
       "<td> (6724.0/951600.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       NO      YES    Error    Rate\n",
       "-----  ------  -----  -------  -----------------\n",
       "NO     943111  1051   0.0011   (1051.0/944162.0)\n",
       "YES    5673    1765   0.7627   (5673.0/7438.0)\n",
       "Total  948784  2816   0.0071   (6724.0/951600.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.1964665</td>\n",
       "<td>0.3442559</td>\n",
       "<td>172.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.0465326</td>\n",
       "<td>0.3343888</td>\n",
       "<td>270.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.5344849</td>\n",
       "<td>0.5161110</td>\n",
       "<td>82.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.5344849</td>\n",
       "<td>0.9934815</td>\n",
       "<td>82.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999919</td>\n",
       "<td>0.9182909</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0000235</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999919</td>\n",
       "<td>0.9998846</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_MCC</td>\n",
       "<td>0.5344849</td>\n",
       "<td>0.4113982</td>\n",
       "<td>82.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.0065434</td>\n",
       "<td>0.7893264</td>\n",
       "<td>368.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                      threshold    value     idx\n",
       "--------------------------  -----------  --------  -----\n",
       "max f1                      0.196466     0.344256  172\n",
       "max f2                      0.0465326    0.334389  270\n",
       "max f0point5                0.534485     0.516111  82\n",
       "max accuracy                0.534485     0.993482  82\n",
       "max precision               0.999992     0.918291  0\n",
       "max recall                  2.34651e-05  1         399\n",
       "max specificity             0.999992     0.999885  0\n",
       "max absolute_MCC            0.534485     0.411398  82\n",
       "max min_per_class_accuracy  0.00654337   0.789326  368"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate:  0.78 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0100294</td>\n",
       "<td>0.0456968</td>\n",
       "<td>35.2150169</td>\n",
       "<td>35.2150169</td>\n",
       "<td>0.2752515</td>\n",
       "<td>0.2752515</td>\n",
       "<td>0.3531863</td>\n",
       "<td>0.3531863</td>\n",
       "<td>3421.5016926</td>\n",
       "<td>3421.5016926</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200431</td>\n",
       "<td>0.0249690</td>\n",
       "<td>7.7066001</td>\n",
       "<td>21.4716255</td>\n",
       "<td>0.0602372</td>\n",
       "<td>0.1678289</td>\n",
       "<td>0.0771713</td>\n",
       "<td>0.4303576</td>\n",
       "<td>670.6600118</td>\n",
       "<td>2047.1625547</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0302785</td>\n",
       "<td>0.0181687</td>\n",
       "<td>4.7418357</td>\n",
       "<td>15.8162563</td>\n",
       "<td>0.0370637</td>\n",
       "<td>0.1236248</td>\n",
       "<td>0.0485346</td>\n",
       "<td>0.4788922</td>\n",
       "<td>374.1835726</td>\n",
       "<td>1481.6256344</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0406484</td>\n",
       "<td>0.0157292</td>\n",
       "<td>4.4858549</td>\n",
       "<td>12.9257312</td>\n",
       "<td>0.0350628</td>\n",
       "<td>0.1010315</td>\n",
       "<td>0.0465179</td>\n",
       "<td>0.5254101</td>\n",
       "<td>348.5854854</td>\n",
       "<td>1192.5731231</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0504277</td>\n",
       "<td>0.0146231</td>\n",
       "<td>2.7908163</td>\n",
       "<td>10.9602923</td>\n",
       "<td>0.0218139</td>\n",
       "<td>0.0856690</td>\n",
       "<td>0.0272923</td>\n",
       "<td>0.5527023</td>\n",
       "<td>179.0816288</td>\n",
       "<td>996.0292290</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000631</td>\n",
       "<td>0.0103670</td>\n",
       "<td>2.3023516</td>\n",
       "<td>6.6656009</td>\n",
       "<td>0.0179959</td>\n",
       "<td>0.0521004</td>\n",
       "<td>0.1142780</td>\n",
       "<td>0.6669804</td>\n",
       "<td>130.2351640</td>\n",
       "<td>566.5600936</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1508249</td>\n",
       "<td>0.0080597</td>\n",
       "<td>1.3030806</td>\n",
       "<td>4.8607826</td>\n",
       "<td>0.0101853</td>\n",
       "<td>0.0379934</td>\n",
       "<td>0.0661468</td>\n",
       "<td>0.7331272</td>\n",
       "<td>30.3080590</td>\n",
       "<td>386.0782644</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2013840</td>\n",
       "<td>0.0069109</td>\n",
       "<td>0.8828419</td>\n",
       "<td>3.8620888</td>\n",
       "<td>0.0069006</td>\n",
       "<td>0.0301873</td>\n",
       "<td>0.0446357</td>\n",
       "<td>0.7777628</td>\n",
       "<td>-11.7158109</td>\n",
       "<td>286.2088835</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3043127</td>\n",
       "<td>0.0050831</td>\n",
       "<td>0.6844448</td>\n",
       "<td>2.7873033</td>\n",
       "<td>0.0053498</td>\n",
       "<td>0.0217864</td>\n",
       "<td>0.0704490</td>\n",
       "<td>0.8482119</td>\n",
       "<td>-31.5555232</td>\n",
       "<td>178.7303268</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4580307</td>\n",
       "<td>0.0041566</td>\n",
       "<td>0.3437255</td>\n",
       "<td>1.9672234</td>\n",
       "<td>0.0026867</td>\n",
       "<td>0.0153764</td>\n",
       "<td>0.0528368</td>\n",
       "<td>0.9010487</td>\n",
       "<td>-65.6274466</td>\n",
       "<td>96.7223372</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5310120</td>\n",
       "<td>0.0041247</td>\n",
       "<td>0.2063243</td>\n",
       "<td>1.7252087</td>\n",
       "<td>0.0016127</td>\n",
       "<td>0.0134848</td>\n",
       "<td>0.0150578</td>\n",
       "<td>0.9161065</td>\n",
       "<td>-79.3675745</td>\n",
       "<td>72.5208687</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6338819</td>\n",
       "<td>0.0037660</td>\n",
       "<td>0.1881993</td>\n",
       "<td>1.4757742</td>\n",
       "<td>0.0014710</td>\n",
       "<td>0.0115351</td>\n",
       "<td>0.0193600</td>\n",
       "<td>0.9354665</td>\n",
       "<td>-81.1800708</td>\n",
       "<td>47.5774191</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7351072</td>\n",
       "<td>0.0037010</td>\n",
       "<td>0.1261765</td>\n",
       "<td>1.2899327</td>\n",
       "<td>0.0009862</td>\n",
       "<td>0.0100825</td>\n",
       "<td>0.0127723</td>\n",
       "<td>0.9482388</td>\n",
       "<td>-87.3823540</td>\n",
       "<td>28.9932665</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8080990</td>\n",
       "<td>0.0035540</td>\n",
       "<td>0.1381437</td>\n",
       "<td>1.1858970</td>\n",
       "<td>0.0010798</td>\n",
       "<td>0.0092693</td>\n",
       "<td>0.0100834</td>\n",
       "<td>0.9583221</td>\n",
       "<td>-86.1856328</td>\n",
       "<td>18.5896951</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.9041541</td>\n",
       "<td>0.0035229</td>\n",
       "<td>0.1119731</td>\n",
       "<td>1.0718060</td>\n",
       "<td>0.0008752</td>\n",
       "<td>0.0083776</td>\n",
       "<td>0.0107556</td>\n",
       "<td>0.9690777</td>\n",
       "<td>-88.8026941</td>\n",
       "<td>7.1805963</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.3226249</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0025217</td>\n",
       "<td>0.0078163</td>\n",
       "<td>0.0309223</td>\n",
       "<td>1.0</td>\n",
       "<td>-67.7375069</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  --------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0100294                   0.0456968          35.215    35.215             0.275251         0.275251                    0.353186        0.353186                   3421.5    3421.5\n",
       "    2        0.0200431                   0.024969           7.7066    21.4716            0.0602372        0.167829                    0.0771713       0.430358                   670.66    2047.16\n",
       "    3        0.0302785                   0.0181687          4.74184   15.8163            0.0370637        0.123625                    0.0485346       0.478892                   374.184   1481.63\n",
       "    4        0.0406484                   0.0157292          4.48585   12.9257            0.0350628        0.101032                    0.0465179       0.52541                    348.585   1192.57\n",
       "    5        0.0504277                   0.0146231          2.79082   10.9603            0.0218139        0.085669                    0.0272923       0.552702                   179.082   996.029\n",
       "    6        0.100063                    0.010367           2.30235   6.6656             0.0179959        0.0521004                   0.114278        0.66698                    130.235   566.56\n",
       "    7        0.150825                    0.00805974         1.30308   4.86078            0.0101853        0.0379934                   0.0661468       0.733127                   30.3081   386.078\n",
       "    8        0.201384                    0.00691089         0.882842  3.86209            0.00690057       0.0301873                   0.0446357       0.777763                   -11.7158  286.209\n",
       "    9        0.304313                    0.0050831          0.684445  2.7873             0.00534983       0.0217864                   0.070449        0.848212                   -31.5555  178.73\n",
       "    10       0.458031                    0.0041566          0.343726  1.96722            0.00268667       0.0153764                   0.0528368       0.901049                   -65.6274  96.7223\n",
       "    11       0.531012                    0.00412474         0.206324  1.72521            0.00161269       0.0134848                   0.0150578       0.916106                   -79.3676  72.5209\n",
       "    12       0.633882                    0.00376602         0.188199  1.47577            0.00147102       0.0115351                   0.01936         0.935467                   -81.1801  47.5774\n",
       "    13       0.735107                    0.00370097         0.126176  1.28993            0.000986234      0.0100825                   0.0127723       0.948239                   -87.3824  28.9933\n",
       "    14       0.808099                    0.003554           0.138144  1.1859             0.00107977       0.00926934                  0.0100834       0.958322                   -86.1856  18.5897\n",
       "    15       0.904154                    0.00352293         0.111973  1.07181            0.000875216      0.00837757                  0.0107556       0.969078                   -88.8027  7.1806\n",
       "    16       1                           0                  0.322625  1                  0.00252174       0.00781631                  0.0309223       1                          -67.7375  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>mean</b></td>\n",
       "<td><b>sd</b></td>\n",
       "<td><b>cv_1_valid</b></td>\n",
       "<td><b>cv_2_valid</b></td>\n",
       "<td><b>cv_3_valid</b></td>\n",
       "<td><b>cv_4_valid</b></td>\n",
       "<td><b>cv_5_valid</b></td>\n",
       "<td><b>cv_6_valid</b></td>\n",
       "<td><b>cv_7_valid</b></td>\n",
       "<td><b>cv_8_valid</b></td>\n",
       "<td><b>cv_9_valid</b></td>\n",
       "<td><b>cv_10_valid</b></td></tr>\n",
       "<tr><td>F0point5</td>\n",
       "<td>0.4539879</td>\n",
       "<td>0.0647445</td>\n",
       "<td>0.4915021</td>\n",
       "<td>0.4781801</td>\n",
       "<td>0.4208461</td>\n",
       "<td>0.5178467</td>\n",
       "<td>0.4770318</td>\n",
       "<td>0.2000702</td>\n",
       "<td>0.4553947</td>\n",
       "<td>0.5419030</td>\n",
       "<td>0.4416404</td>\n",
       "<td>0.5154639</td></tr>\n",
       "<tr><td>F1</td>\n",
       "<td>0.3463672</td>\n",
       "<td>0.0405876</td>\n",
       "<td>0.3797693</td>\n",
       "<td>0.3731884</td>\n",
       "<td>0.3428064</td>\n",
       "<td>0.3634497</td>\n",
       "<td>0.3223880</td>\n",
       "<td>0.1846154</td>\n",
       "<td>0.3584559</td>\n",
       "<td>0.3640212</td>\n",
       "<td>0.3767872</td>\n",
       "<td>0.3981901</td></tr>\n",
       "<tr><td>F2</td>\n",
       "<td>0.2821959</td>\n",
       "<td>0.0310770</td>\n",
       "<td>0.3094274</td>\n",
       "<td>0.3060012</td>\n",
       "<td>0.2891819</td>\n",
       "<td>0.2799747</td>\n",
       "<td>0.2434626</td>\n",
       "<td>0.1713770</td>\n",
       "<td>0.2955441</td>\n",
       "<td>0.2740599</td>\n",
       "<td>0.3285421</td>\n",
       "<td>0.3243881</td></tr>\n",
       "<tr><td>accuracy</td>\n",
       "<td>0.9924927</td>\n",
       "<td>0.0007915</td>\n",
       "<td>0.9926484</td>\n",
       "<td>0.9927451</td>\n",
       "<td>0.992224</td>\n",
       "<td>0.9934733</td>\n",
       "<td>0.9928487</td>\n",
       "<td>0.9894103</td>\n",
       "<td>0.9926602</td>\n",
       "<td>0.9936746</td>\n",
       "<td>0.9922194</td>\n",
       "<td>0.9930227</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.8591340</td>\n",
       "<td>0.0354914</td>\n",
       "<td>0.885972</td>\n",
       "<td>0.8902291</td>\n",
       "<td>0.8822546</td>\n",
       "<td>0.8785925</td>\n",
       "<td>0.8505257</td>\n",
       "<td>0.7151047</td>\n",
       "<td>0.8478289</td>\n",
       "<td>0.888331</td>\n",
       "<td>0.8864397</td>\n",
       "<td>0.8660611</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.0075073</td>\n",
       "<td>0.0007915</td>\n",
       "<td>0.0073516</td>\n",
       "<td>0.0072549</td>\n",
       "<td>0.0077760</td>\n",
       "<td>0.0065267</td>\n",
       "<td>0.0071513</td>\n",
       "<td>0.0105897</td>\n",
       "<td>0.0073398</td>\n",
       "<td>0.0063254</td>\n",
       "<td>0.0077806</td>\n",
       "<td>0.0069773</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>714.4</td>\n",
       "<td>75.27031</td>\n",
       "<td>699.0</td>\n",
       "<td>692.0</td>\n",
       "<td>740.0</td>\n",
       "<td>620.0</td>\n",
       "<td>681.0</td>\n",
       "<td>1007.0</td>\n",
       "<td>698.0</td>\n",
       "<td>601.0</td>\n",
       "<td>741.0</td>\n",
       "<td>665.0</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>34.417076</td>\n",
       "<td>3.7437735</td>\n",
       "<td>38.57424</td>\n",
       "<td>38.903942</td>\n",
       "<td>35.80735</td>\n",
       "<td>34.97366</td>\n",
       "<td>32.980385</td>\n",
       "<td>19.652815</td>\n",
       "<td>33.340126</td>\n",
       "<td>38.24487</td>\n",
       "<td>35.24948</td>\n",
       "<td>36.44388</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>0.0389285</td>\n",
       "<td>0.0072217</td>\n",
       "<td>0.0341337</td>\n",
       "<td>0.0341313</td>\n",
       "<td>0.0361717</td>\n",
       "<td>0.0326795</td>\n",
       "<td>0.0467681</td>\n",
       "<td>0.0669204</td>\n",
       "<td>0.0393646</td>\n",
       "<td>0.0321810</td>\n",
       "<td>0.0333400</td>\n",
       "<td>0.0335946</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.7482544</td>\n",
       "<td>0.0275508</td>\n",
       "<td>0.7245817</td>\n",
       "<td>0.7267904</td>\n",
       "<td>0.7381275</td>\n",
       "<td>0.7572017</td>\n",
       "<td>0.7906977</td>\n",
       "<td>0.8364419</td>\n",
       "<td>0.7354139</td>\n",
       "<td>0.7647059</td>\n",
       "<td>0.6972973</td>\n",
       "<td>0.7112861</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.376574</td>\n",
       "<td>0.0487466</td>\n",
       "<td>0.4072942</td>\n",
       "<td>0.3979209</td>\n",
       "<td>0.3569389</td>\n",
       "<td>0.4165068</td>\n",
       "<td>0.3806934</td>\n",
       "<td>0.1808998</td>\n",
       "<td>0.3802233</td>\n",
       "<td>0.4328649</td>\n",
       "<td>0.3849565</td>\n",
       "<td>0.4274414</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.0062200</td>\n",
       "<td>0.0001868</td>\n",
       "<td>0.0062712</td>\n",
       "<td>0.0061636</td>\n",
       "<td>0.0062393</td>\n",
       "<td>0.0059621</td>\n",
       "<td>0.0066260</td>\n",
       "<td>0.0067871</td>\n",
       "<td>0.0060853</td>\n",
       "<td>0.0059793</td>\n",
       "<td>0.0060412</td>\n",
       "<td>0.0060453</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.5831367</td>\n",
       "<td>0.1094317</td>\n",
       "<td>0.6114286</td>\n",
       "<td>0.5885714</td>\n",
       "<td>0.4961440</td>\n",
       "<td>0.722449</td>\n",
       "<td>0.7012987</td>\n",
       "<td>0.2118959</td>\n",
       "<td>0.5555556</td>\n",
       "<td>0.8037383</td>\n",
       "<td>0.4988864</td>\n",
       "<td>0.6413994</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.1970470</td>\n",
       "<td>0.0327131</td>\n",
       "<td>0.2262737</td>\n",
       "<td>0.2140686</td>\n",
       "<td>0.1880778</td>\n",
       "<td>0.2170921</td>\n",
       "<td>0.1781126</td>\n",
       "<td>0.0672020</td>\n",
       "<td>0.2086612</td>\n",
       "<td>0.2168000</td>\n",
       "<td>0.2164110</td>\n",
       "<td>0.2377707</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.2517456</td>\n",
       "<td>0.0275508</td>\n",
       "<td>0.2754183</td>\n",
       "<td>0.2732095</td>\n",
       "<td>0.2618725</td>\n",
       "<td>0.2427984</td>\n",
       "<td>0.2093023</td>\n",
       "<td>0.1635581</td>\n",
       "<td>0.2645862</td>\n",
       "<td>0.2352941</td>\n",
       "<td>0.3027027</td>\n",
       "<td>0.2887139</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.9983236</td>\n",
       "<td>0.0007786</td>\n",
       "<td>0.9985579</td>\n",
       "<td>0.9984783</td>\n",
       "<td>0.9979243</td>\n",
       "<td>0.9992786</td>\n",
       "<td>0.9992695</td>\n",
       "<td>0.9955082</td>\n",
       "<td>0.9983467</td>\n",
       "<td>0.9995545</td>\n",
       "<td>0.997619</td>\n",
       "<td>0.9986991</td></tr></table></div>"
      ],
      "text/plain": [
       "                     mean        sd           cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid    cv_6_valid    cv_7_valid    cv_8_valid    cv_9_valid    cv_10_valid\n",
       "-------------------  ----------  -----------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  -------------\n",
       "F0point5             0.453988    0.0647445    0.491502      0.47818       0.420846      0.517847      0.477032      0.20007       0.455395      0.541903      0.44164       0.515464\n",
       "F1                   0.346367    0.0405876    0.379769      0.373188      0.342806      0.36345       0.322388      0.184615      0.358456      0.364021      0.376787      0.39819\n",
       "F2                   0.282196    0.031077     0.309427      0.306001      0.289182      0.279975      0.243463      0.171377      0.295544      0.27406       0.328542      0.324388\n",
       "accuracy             0.992493    0.000791531  0.992648      0.992745      0.992224      0.993473      0.992849      0.98941       0.99266       0.993675      0.992219      0.993023\n",
       "auc                  0.859134    0.0354914    0.885972      0.890229      0.882255      0.878592      0.850526      0.715105      0.847829      0.888331      0.88644       0.866061\n",
       "err                  0.00750734  0.000791531  0.00735163    0.00725489    0.00777605    0.00652673    0.00715133    0.0105897     0.0073398     0.00632538    0.00778059    0.00697731\n",
       "err_count            714.4       75.2703      699           692           740           620           681           1007          698           601           741           665\n",
       "lift_top_group       34.4171     3.74377      38.5742       38.9039       35.8073       34.9737       32.9804       19.6528       33.3401       38.2449       35.2495       36.4439\n",
       "logloss              0.0389285   0.00722169   0.0341337     0.0341313     0.0361717     0.0326795     0.0467681     0.0669204     0.0393646     0.032181      0.03334       0.0335946\n",
       "max_per_class_error  0.748254    0.0275508    0.724582      0.72679       0.738128      0.757202      0.790698      0.836442      0.735414      0.764706      0.697297      0.711286\n",
       "mcc                  0.376574    0.0487466    0.407294      0.397921      0.356939      0.416507      0.380693      0.1809        0.380223      0.432865      0.384957      0.427441\n",
       "mse                  0.00622002  0.000186765  0.00627121    0.00616359    0.00623925    0.00596206    0.00662596    0.00678706    0.00608527    0.00597927    0.00604125    0.00604534\n",
       "precision            0.583137    0.109432     0.611429      0.588571      0.496144      0.722449      0.701299      0.211896      0.555556      0.803738      0.498886      0.641399\n",
       "r2                   0.197047    0.0327131    0.226274      0.214069      0.188078      0.217092      0.178113      0.067202      0.208661      0.2168        0.216411      0.237771\n",
       "recall               0.251746    0.0275508    0.275418      0.27321       0.261872      0.242798      0.209302      0.163558      0.264586      0.235294      0.302703      0.288714\n",
       "specificity          0.998324    0.000778603  0.998558      0.998478      0.997924      0.999279      0.99927       0.995508      0.998347      0.999555      0.997619      0.998699"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>training_MSE</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_AUC</b></td>\n",
       "<td><b>training_lift</b></td>\n",
       "<td><b>training_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-05-09 06:32:24</td>\n",
       "<td>49.285 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0077552</td>\n",
       "<td>0.0457068</td>\n",
       "<td>0.5</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9921837</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-05-09 06:32:27</td>\n",
       "<td>51.936 sec</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0066323</td>\n",
       "<td>0.0398267</td>\n",
       "<td>0.6402205</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0071049</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-05-09 06:32:27</td>\n",
       "<td>52.546 sec</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0064571</td>\n",
       "<td>0.0382052</td>\n",
       "<td>0.8010979</td>\n",
       "<td>5.3145791</td>\n",
       "<td>0.0065122</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-05-09 06:32:28</td>\n",
       "<td>53.069 sec</td>\n",
       "<td>3.0</td>\n",
       "<td>0.0063418</td>\n",
       "<td>0.0371359</td>\n",
       "<td>0.8115121</td>\n",
       "<td>30.9566854</td>\n",
       "<td>0.0064145</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-05-09 06:32:30</td>\n",
       "<td>55.079 sec</td>\n",
       "<td>10.0</td>\n",
       "<td>0.0060754</td>\n",
       "<td>0.0333003</td>\n",
       "<td>0.8827608</td>\n",
       "<td>36.9928775</td>\n",
       "<td>0.0072331</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration    number_of_trees    training_MSE    training_logloss    training_AUC    training_lift    training_classification_error\n",
       "--  -------------------  ----------  -----------------  --------------  ------------------  --------------  ---------------  -------------------------------\n",
       "    2016-05-09 06:32:24  49.285 sec  0                  0.00775521      0.0457068           0.5             1                0.992184\n",
       "    2016-05-09 06:32:27  51.936 sec  1                  0.00663228      0.0398267           0.640221        1                0.00710488\n",
       "    2016-05-09 06:32:27  52.546 sec  2                  0.00645711      0.0382052           0.801098        5.31458          0.00651219\n",
       "    2016-05-09 06:32:28  53.069 sec  3                  0.00634184      0.0371359           0.811512        30.9567          0.00641446\n",
       "    2016-05-09 06:32:30  55.079 sec  10                 0.00607539      0.0333003           0.882761        36.9929          0.00723308"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>COMPASS_EVALUE</td>\n",
       "<td>1278.4888916</td>\n",
       "<td>1.0</td>\n",
       "<td>0.4408846</td></tr>\n",
       "<tr><td>HHSEARCH_PROFILE_PROFILE_ALIGNMENT_SCORE</td>\n",
       "<td>478.9384460</td>\n",
       "<td>0.3746129</td>\n",
       "<td>0.1651611</td></tr>\n",
       "<tr><td>PFAM_ALIGNMENT_SCORE</td>\n",
       "<td>393.2412415</td>\n",
       "<td>0.3075828</td>\n",
       "<td>0.1356085</td></tr>\n",
       "<tr><td>HMMER_PRCHMMM_REVERSE_SCORE</td>\n",
       "<td>194.4378662</td>\n",
       "<td>0.1520841</td>\n",
       "<td>0.0670515</td></tr>\n",
       "<tr><td>LOBSTER_PROFILE_PROFILE_ALIGNMENT_SCORE</td>\n",
       "<td>143.8402710</td>\n",
       "<td>0.1125080</td>\n",
       "<td>0.0496031</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>GAUSSIAN_FUNC_SS_SA_COMP</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>HMMER_PRCHMMM_COEMIS_SCORE</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>HMMER_PRCHMMM_SIMPLE_SCORE</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>CHK_PRCHMMM_COEMIS_SCORE</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>CHK_PRCHMMM_SIMPLE_SCORE</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "variable                                  relative_importance    scaled_importance    percentage\n",
       "----------------------------------------  ---------------------  -------------------  ---------------\n",
       "COMPASS_EVALUE                            1278.4888916           1.0                  0.440884573361\n",
       "HHSEARCH_PROFILE_PROFILE_ALIGNMENT_SCORE  478.938446045          0.374612911533       0.165161053677\n",
       "PFAM_ALIGNMENT_SCORE                      393.241241455          0.307582837863       0.135608528244\n",
       "HMMER_PRCHMMM_REVERSE_SCORE               194.437866211          0.152084126415       0.0670515451897\n",
       "LOBSTER_PROFILE_PROFILE_ALIGNMENT_SCORE   143.840270996          0.112508033461       0.0496030563323\n",
       "---                                       ---                    ---                  ---\n",
       "GAUSSIAN_FUNC_SS_SA_COMP                  0.0                    0.0                  0.0\n",
       "HMMER_PRCHMMM_COEMIS_SCORE                0.0                    0.0                  0.0\n",
       "HMMER_PRCHMMM_SIMPLE_SCORE                0.0                    0.0                  0.0\n",
       "CHK_PRCHMMM_COEMIS_SCORE                  0.0                    0.0                  0.0\n",
       "CHK_PRCHMMM_SIMPLE_SCORE                  0.0                    0.0                  0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing model build report for the GBM classifier\n",
    "gbm_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean CV AUC: 0.85913396\n"
     ]
    }
   ],
   "source": [
    "# The chosen True north metric in this case Mean CV AUC\n",
    "# To avoid clutter, looking at only Mean CV AUC going forward\n",
    "# Mean CV AUC can be extracted from the report as follows\n",
    "\n",
    "print \"Mean CV AUC:\" , gbm_classifier.cross_validation_metrics_summary().as_data_frame().iloc[4][\"mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "gbm Model Build Progress: [##################################################] 100%\n",
      "Trees count: 10 AUC: 0.876683\n",
      "\n",
      "gbm Model Build Progress: [##################################################] 100%\n",
      "Trees count: 25 AUC: 0.91330415\n",
      "\n",
      "gbm Model Build Progress: [##################################################] 100%\n",
      "Trees count: 50 AUC: 0.92643166\n",
      "\n",
      "gbm Model Build Progress: [##################################################] 100%\n",
      "Trees count: 100 AUC: 0.9395223\n",
      "\n",
      "gbm Model Build Progress: [##################################################] 100%\n",
      "Trees count: 200 AUC: 0.9467536\n",
      "\n",
      "gbm Model Build Progress: [##################################################] 100%\n",
      "Trees count: 500 AUC: 0.9518011\n"
     ]
    }
   ],
   "source": [
    "# Determining optimal Tree count using Line search\n",
    "\n",
    "#h2o.__PROGRESS_BAR__=False\n",
    "#h2o.no_progress()\n",
    "\n",
    "for trees_count in [10, 25, 50, 100, 200 , 500] :\n",
    "    gbm_classifier2 = H2OGradientBoostingEstimator(\n",
    "                            distribution=\"multinomial\",\n",
    "                            ntrees=trees_count, \n",
    "                            max_depth=3, \n",
    "                            min_rows=2, \n",
    "                            learn_rate=\"0.2\" ,\n",
    "                            nfolds = 10 , \n",
    "                            keep_cross_validation_predictions = True )\n",
    "\n",
    "    gbm_classifier2.train(x=range(1,foldpro_df.ncol), \n",
    "                         y=0, \n",
    "                         training_frame= foldpro_df ,\n",
    "                         seed = 1234\n",
    "                         )\n",
    "\n",
    "    mean_cv_auc = gbm_classifier2.cross_validation_metrics_summary().as_data_frame().iloc[4][\"mean\"]\n",
    "    print \"Trees count:\" , trees_count , \"AUC:\"  , mean_cv_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trees_count_opt = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "gbm Model Build Progress: [##################################################] 100%\n",
      "max Tree depth: 3 AUC: 0.91501796\n",
      "\n",
      "gbm Model Build Progress: [##################################################] 100%\n",
      "max Tree depth: 6 AUC: 0.95585245\n",
      "\n",
      "gbm Model Build Progress: [##################################################] 100%\n",
      "max Tree depth: 12 AUC: 0.9340079\n",
      "\n",
      "gbm Model Build Progress: [##################################################] 100%\n",
      "max Tree depth: 24 AUC: 0.7728958\n"
     ]
    }
   ],
   "source": [
    "# Determining optimal max Tree depth using Line search\n",
    "for md in [3, 6, 12, 24] :\n",
    "    gbm_classifier2 = H2OGradientBoostingEstimator(\n",
    "                            distribution=\"multinomial\",\n",
    "                            ntrees=trees_count_opt, \n",
    "                            max_depth=md, \n",
    "                            min_rows=2, \n",
    "                            learn_rate=\"0.2\" ,\n",
    "                            nfolds = 10 , \n",
    "                            keep_cross_validation_predictions = True )\n",
    "\n",
    "    gbm_classifier2.train(x=range(1,foldpro_df.ncol), \n",
    "                         y=0, \n",
    "                         training_frame= foldpro_df ,\n",
    "                         seed = 1234\n",
    "                         )\n",
    "\n",
    "    mean_cv_auc = gbm_classifier2.cross_validation_metrics_summary().as_data_frame().iloc[4][\"mean\"]\n",
    "    print \"max Tree depth:\" , md , \"AUC:\"  , mean_cv_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "md_opt = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "gbm Model Build Progress: [##################################################] 100%\n",
      "min Row count: 2 AUC: 0.9426868\n",
      "\n",
      "gbm Model Build Progress: [##################################################] 100%\n",
      "min Row count: 3 AUC: 0.95622885\n",
      "\n",
      "gbm Model Build Progress: [##################################################] 100%\n",
      "min Row count: 6 AUC: 0.9527614\n",
      "\n",
      "gbm Model Build Progress: [##################################################] 100%\n",
      "min Row count: 12 AUC: 0.9465982\n"
     ]
    }
   ],
   "source": [
    "# Determining optimal min Rows using Line search\n",
    "for mr in [2, 3, 6, 12] :\n",
    "    gbm_classifier2 = H2OGradientBoostingEstimator(\n",
    "                            distribution=\"multinomial\",\n",
    "                            ntrees=trees_count_opt, \n",
    "                            max_depth=md_opt, \n",
    "                            min_rows=mr, \n",
    "                            learn_rate=\"0.2\" ,\n",
    "                            nfolds = 10 , \n",
    "                            keep_cross_validation_predictions = True)\n",
    "\n",
    "    gbm_classifier2.train(x=range(1,foldpro_df.ncol), \n",
    "                         y=0, \n",
    "                         training_frame= foldpro_df ,\n",
    "                         seed = 1234\n",
    "                         )\n",
    "\n",
    "    mean_cv_auc = gbm_classifier2.cross_validation_metrics_summary().as_data_frame().iloc[4][\"mean\"]\n",
    "    print \"min Row count:\" , mr , \"AUC:\"  , mean_cv_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mr_opt = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "gbm Model Build Progress: [##################################################] 100%\n",
      "learning rate: 0.01 AUC: 0.9226934\n",
      "\n",
      "gbm Model Build Progress: [##################################################] 100%\n",
      "learning rate: 0.05 AUC: 0.959417\n",
      "\n",
      "gbm Model Build Progress: [##################################################] 100%\n",
      "learning rate: 0.1 AUC: 0.96463823\n",
      "\n",
      "gbm Model Build Progress: [##################################################] 100%\n",
      "learning rate: 0.2 AUC: 0.95765305\n",
      "\n",
      "gbm Model Build Progress: [##################################################] 100%\n",
      "learning rate: 0.3 AUC: 0.92509305\n"
     ]
    }
   ],
   "source": [
    "# Determining optimal learn rate using Line search\n",
    "for lr in [.01, .05, 0.1, 0.2, 0.3] :\n",
    "    gbm_classifier2 = H2OGradientBoostingEstimator(\n",
    "                            distribution=\"multinomial\",\n",
    "                            ntrees=trees_count_opt, \n",
    "                            max_depth=md_opt, \n",
    "                            min_rows=mr_opt, \n",
    "                            learn_rate=lr ,\n",
    "                            nfolds = 10 , \n",
    "                            keep_cross_validation_predictions = True)\n",
    "\n",
    "    gbm_classifier2.train(x=range(1,foldpro_df.ncol), \n",
    "                         y=0, \n",
    "                         training_frame= foldpro_df ,\n",
    "                         seed = 1234\n",
    "                         )\n",
    "\n",
    "    mean_cv_auc = gbm_classifier2.cross_validation_metrics_summary().as_data_frame().iloc[4][\"mean\"]\n",
    "    print \"learning rate:\" , lr , \"AUC:\"  , mean_cv_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_opt = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyper parameter tuned single GBM model has the following parameters\n",
    "# ntrees = 200\n",
    "# max_depth = 6\n",
    "# min_rows = 3\n",
    "# learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "gbm Model Build Progress: [##################################################] 100%\n"
     ]
    }
   ],
   "source": [
    "# Creating 10-Fold predictions corresponding to Best GBM Model for Benchmarking Purpose\n",
    "\n",
    "gbm_classifier3 = H2OGradientBoostingEstimator(\n",
    "                            distribution=\"multinomial\",\n",
    "                            ntrees=trees_count_opt, \n",
    "                            max_depth=md_opt, \n",
    "                            min_rows=mr_opt, \n",
    "                            learn_rate=lr_opt ,\n",
    "                            nfolds = 10 , \n",
    "                            keep_cross_validation_predictions = True)\n",
    "\n",
    "gbm_classifier3.train(x=range(1,foldpro_df.ncol), \n",
    "                         y=0, \n",
    "                         training_frame= foldpro_df ,\n",
    "                         seed = 1234\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv_pred_gbm = gbm_classifier3.cross_validation_holdout_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>predict  </th><th style=\"text-align: right;\">      NO</th><th style=\"text-align: right;\">        YES</th></tr>\n",
       "<tr><td>NO       </td><td style=\"text-align: right;\">0.9998  </td><td style=\"text-align: right;\">0.000200331</td></tr>\n",
       "<tr><td>NO       </td><td style=\"text-align: right;\">0.999764</td><td style=\"text-align: right;\">0.000235823</td></tr>\n",
       "<tr><td>NO       </td><td style=\"text-align: right;\">0.999728</td><td style=\"text-align: right;\">0.000271758</td></tr>\n",
       "<tr><td>NO       </td><td style=\"text-align: right;\">0.999372</td><td style=\"text-align: right;\">0.000628083</td></tr>\n",
       "<tr><td>NO       </td><td style=\"text-align: right;\">0.999815</td><td style=\"text-align: right;\">0.000185375</td></tr>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_pred_gbm.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(951600, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_pred_gbm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv_pred_gbm_df = cv_pred_gbm.as_data_frame(use_pandas=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict</th>\n",
       "      <th>NO</th>\n",
       "      <th>YES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NO</td>\n",
       "      <td>0.999800</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NO</td>\n",
       "      <td>0.999764</td>\n",
       "      <td>0.000236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NO</td>\n",
       "      <td>0.999728</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NO</td>\n",
       "      <td>0.999372</td>\n",
       "      <td>0.000628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NO</td>\n",
       "      <td>0.999815</td>\n",
       "      <td>0.000185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  predict        NO       YES\n",
       "0      NO  0.999800  0.000200\n",
       "1      NO  0.999764  0.000236\n",
       "2      NO  0.999728  0.000272\n",
       "3      NO  0.999372  0.000628\n",
       "4      NO  0.999815  0.000185"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_pred_gbm_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "IdText = pd.read_csv(\"/home/anusha/cscie-63/project/IdFile.txt\" , \n",
    "                     header = None , \n",
    "                     names = [\"PairId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PairId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1aca-d1aca 1abra-d1abra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1aca-d1aca 1abrb-d1abrb1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1aca-d1aca 1abrb-d1abrb2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1aca-d1aca 1acf-d1acf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1aca-d1aca 1aco-d1aco_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     PairId\n",
       "0   1aca-d1aca 1abra-d1abra\n",
       "1  1aca-d1aca 1abrb-d1abrb1\n",
       "2  1aca-d1aca 1abrb-d1abrb2\n",
       "3     1aca-d1aca 1acf-d1acf\n",
       "4   1aca-d1aca 1aco-d1aco_1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IdText.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outDf1 = pd.DataFrame( zip (IdText.PairId , cv_pred_gbm_df.YES ) , columns = [\"PairId\",\"Probability\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PairId</th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1aca-d1aca 1abra-d1abra</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1aca-d1aca 1abrb-d1abrb1</td>\n",
       "      <td>0.000236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1aca-d1aca 1abrb-d1abrb2</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1aca-d1aca 1acf-d1acf</td>\n",
       "      <td>0.000628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1aca-d1aca 1aco-d1aco_1</td>\n",
       "      <td>0.000185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     PairId  Probability\n",
       "0   1aca-d1aca 1abra-d1abra     0.000200\n",
       "1  1aca-d1aca 1abrb-d1abrb1     0.000236\n",
       "2  1aca-d1aca 1abrb-d1abrb2     0.000272\n",
       "3     1aca-d1aca 1acf-d1acf     0.000628\n",
       "4   1aca-d1aca 1aco-d1aco_1     0.000185"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outDf1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "outDf1.to_csv(\"gbm_prediction.csv\" , \n",
    "              sep = \" \" , \n",
    "              header = False , \n",
    "              index = False , \n",
    "              quoting= csv.QUOTE_NONE , \n",
    "              quotechar='',\n",
    "              escapechar=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "glm Model Build Progress: [##################################################] 100%\n"
     ]
    }
   ],
   "source": [
    "# Completed end-to-end process for creating predictions corresponding to one h2o classifier until now\n",
    "# Repeating the above process for following h20 ( except Line search for optimal parameters due to lack of time)\n",
    "# a.H2OGeneralizedLinearEstimator\n",
    "# b.H2ORandomForestEstimator\n",
    "# c.H2ODeepLearningEstimator\n",
    "\n",
    "glm_classifier = H2OGeneralizedLinearEstimator(family=\"binomial\",\n",
    "                                               nfolds=10, \n",
    "                                               alpha=0.5,\n",
    "                                               keep_cross_validation_predictions = True)\n",
    "glm_classifier.train(x=range(1,foldpro_df.ncol), \n",
    "                         y=0, \n",
    "                         training_frame= foldpro_df ,\n",
    "                         seed = 1234 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OGeneralizedLinearEstimator :  Generalized Linear Modeling\n",
      "Model Key:  GLM_model_python_1462800685859_9485\n",
      "\n",
      "GLM Model: summary\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>family</b></td>\n",
       "<td><b>link</b></td>\n",
       "<td><b>regularization</b></td>\n",
       "<td><b>number_of_predictors_total</b></td>\n",
       "<td><b>number_of_active_predictors</b></td>\n",
       "<td><b>number_of_iterations</b></td>\n",
       "<td><b>training_frame</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>binomial</td>\n",
       "<td>logit</td>\n",
       "<td>Elastic Net (alpha = 0.5, lambda = 4.991E-5 )</td>\n",
       "<td>85</td>\n",
       "<td>69</td>\n",
       "<td>8</td>\n",
       "<td>foldpro_final.hex</td></tr></table></div>"
      ],
      "text/plain": [
       "    family    link    regularization                                 number_of_predictors_total    number_of_active_predictors    number_of_iterations    training_frame\n",
       "--  --------  ------  ---------------------------------------------  ----------------------------  -----------------------------  ----------------------  -----------------\n",
       "    binomial  logit   Elastic Net (alpha = 0.5, lambda = 4.991E-5 )  85                            69                             8                       foldpro_final.hex"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomialGLM: glm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.00556028805115\n",
      "R^2: 0.283025901985\n",
      "LogLoss: 0.0263811540365\n",
      "Null degrees of freedom: 951599\n",
      "Residual degrees of freedom: 951530\n",
      "Null deviance: 86989.2606608\n",
      "Residual deviance: 50208.6123533\n",
      "AIC: 50348.6123533\n",
      "AUC: 0.93670055489\n",
      "Gini: 0.87340110978\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.189668029438: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>NO</b></td>\n",
       "<td><b>YES</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>NO</td>\n",
       "<td>942200.0</td>\n",
       "<td>1962.0</td>\n",
       "<td>0.0021</td>\n",
       "<td> (1962.0/944162.0)</td></tr>\n",
       "<tr><td>YES</td>\n",
       "<td>4818.0</td>\n",
       "<td>2620.0</td>\n",
       "<td>0.6478</td>\n",
       "<td> (4818.0/7438.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>947018.0</td>\n",
       "<td>4582.0</td>\n",
       "<td>0.0071</td>\n",
       "<td> (6780.0/951600.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       NO      YES    Error    Rate\n",
       "-----  ------  -----  -------  -----------------\n",
       "NO     942200  1962   0.0021   (1962.0/944162.0)\n",
       "YES    4818    2620   0.6478   (4818.0/7438.0)\n",
       "Total  947018  4582   0.0071   (6780.0/951600.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.1896680</td>\n",
       "<td>0.4359401</td>\n",
       "<td>175.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.0767611</td>\n",
       "<td>0.4347826</td>\n",
       "<td>239.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.4490971</td>\n",
       "<td>0.5782025</td>\n",
       "<td>102.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.5296679</td>\n",
       "<td>0.9938157</td>\n",
       "<td>87.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9979828</td>\n",
       "<td>0.9990010</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0000099</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999356</td>\n",
       "<td>0.9999989</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_MCC</td>\n",
       "<td>0.4206589</td>\n",
       "<td>0.4630991</td>\n",
       "<td>108.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.0085311</td>\n",
       "<td>0.8574886</td>\n",
       "<td>350.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                      threshold    value     idx\n",
       "--------------------------  -----------  --------  -----\n",
       "max f1                      0.189668     0.43594   175\n",
       "max f2                      0.0767611    0.434783  239\n",
       "max f0point5                0.449097     0.578202  102\n",
       "max accuracy                0.529668     0.993816  87\n",
       "max precision               0.997983     0.999001  1\n",
       "max recall                  9.90476e-06  1         399\n",
       "max specificity             0.999936     0.999999  0\n",
       "max absolute_MCC            0.420659     0.463099  108\n",
       "max min_per_class_accuracy  0.00853107   0.857489  350"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate:  0.78 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.01</td>\n",
       "<td>0.0949161</td>\n",
       "<td>45.0658779</td>\n",
       "<td>45.0658779</td>\n",
       "<td>0.3522488</td>\n",
       "<td>0.3522488</td>\n",
       "<td>0.4506588</td>\n",
       "<td>0.4506588</td>\n",
       "<td>4406.5877924</td>\n",
       "<td>4406.5877924</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.02</td>\n",
       "<td>0.0531006</td>\n",
       "<td>10.5942458</td>\n",
       "<td>27.8300618</td>\n",
       "<td>0.0828079</td>\n",
       "<td>0.2175284</td>\n",
       "<td>0.1059425</td>\n",
       "<td>0.5566012</td>\n",
       "<td>959.4245765</td>\n",
       "<td>2683.0061845</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.03</td>\n",
       "<td>0.0383524</td>\n",
       "<td>6.8970153</td>\n",
       "<td>20.8523797</td>\n",
       "<td>0.0539092</td>\n",
       "<td>0.1629887</td>\n",
       "<td>0.0689702</td>\n",
       "<td>0.6255714</td>\n",
       "<td>589.7015327</td>\n",
       "<td>1985.2379672</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.04</td>\n",
       "<td>0.0301747</td>\n",
       "<td>4.3022318</td>\n",
       "<td>16.7148427</td>\n",
       "<td>0.0336276</td>\n",
       "<td>0.1306484</td>\n",
       "<td>0.0430223</td>\n",
       "<td>0.6685937</td>\n",
       "<td>330.2231783</td>\n",
       "<td>1571.4842700</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.05</td>\n",
       "<td>0.0248977</td>\n",
       "<td>3.4686744</td>\n",
       "<td>14.0656090</td>\n",
       "<td>0.0271122</td>\n",
       "<td>0.1099412</td>\n",
       "<td>0.0346867</td>\n",
       "<td>0.7032805</td>\n",
       "<td>246.8674375</td>\n",
       "<td>1306.5609035</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1</td>\n",
       "<td>0.0128814</td>\n",
       "<td>1.9225598</td>\n",
       "<td>7.9940844</td>\n",
       "<td>0.0150273</td>\n",
       "<td>0.0624842</td>\n",
       "<td>0.0961280</td>\n",
       "<td>0.7994084</td>\n",
       "<td>92.2559828</td>\n",
       "<td>699.4084431</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.15</td>\n",
       "<td>0.0081950</td>\n",
       "<td>1.2100027</td>\n",
       "<td>5.7327239</td>\n",
       "<td>0.0094578</td>\n",
       "<td>0.0448087</td>\n",
       "<td>0.0605001</td>\n",
       "<td>0.8599086</td>\n",
       "<td>21.0002689</td>\n",
       "<td>473.2723851</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2</td>\n",
       "<td>0.0056647</td>\n",
       "<td>0.6641570</td>\n",
       "<td>4.4655821</td>\n",
       "<td>0.0051913</td>\n",
       "<td>0.0349044</td>\n",
       "<td>0.0332079</td>\n",
       "<td>0.8931164</td>\n",
       "<td>-33.5842969</td>\n",
       "<td>346.5582146</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3</td>\n",
       "<td>0.0030374</td>\n",
       "<td>0.4786233</td>\n",
       "<td>3.1365959</td>\n",
       "<td>0.0037411</td>\n",
       "<td>0.0245166</td>\n",
       "<td>0.0478623</td>\n",
       "<td>0.9409788</td>\n",
       "<td>-52.1376714</td>\n",
       "<td>213.6595859</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4</td>\n",
       "<td>0.0017569</td>\n",
       "<td>0.2756117</td>\n",
       "<td>2.4213498</td>\n",
       "<td>0.0021543</td>\n",
       "<td>0.0189260</td>\n",
       "<td>0.0275612</td>\n",
       "<td>0.9685399</td>\n",
       "<td>-72.4388276</td>\n",
       "<td>142.1349825</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0010426</td>\n",
       "<td>0.1438559</td>\n",
       "<td>1.9658510</td>\n",
       "<td>0.0011244</td>\n",
       "<td>0.0153657</td>\n",
       "<td>0.0143856</td>\n",
       "<td>0.9829255</td>\n",
       "<td>-85.6144125</td>\n",
       "<td>96.5851035</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6</td>\n",
       "<td>0.0006038</td>\n",
       "<td>0.0712557</td>\n",
       "<td>1.6500851</td>\n",
       "<td>0.0005570</td>\n",
       "<td>0.0128976</td>\n",
       "<td>0.0071256</td>\n",
       "<td>0.9900511</td>\n",
       "<td>-92.8744286</td>\n",
       "<td>65.0085148</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7</td>\n",
       "<td>0.0003211</td>\n",
       "<td>0.0389890</td>\n",
       "<td>1.4199286</td>\n",
       "<td>0.0003047</td>\n",
       "<td>0.0110986</td>\n",
       "<td>0.0038989</td>\n",
       "<td>0.9939500</td>\n",
       "<td>-96.1011024</td>\n",
       "<td>41.9928552</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8</td>\n",
       "<td>0.0001361</td>\n",
       "<td>0.0336112</td>\n",
       "<td>1.2466389</td>\n",
       "<td>0.0002627</td>\n",
       "<td>0.0097441</td>\n",
       "<td>0.0033611</td>\n",
       "<td>0.9973111</td>\n",
       "<td>-96.6388814</td>\n",
       "<td>24.6638881</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.9</td>\n",
       "<td>0.0000261</td>\n",
       "<td>0.0134445</td>\n",
       "<td>1.1096173</td>\n",
       "<td>0.0001051</td>\n",
       "<td>0.0086731</td>\n",
       "<td>0.0013444</td>\n",
       "<td>0.9986556</td>\n",
       "<td>-98.6555526</td>\n",
       "<td>10.9617281</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0134445</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0001051</td>\n",
       "<td>0.0078163</td>\n",
       "<td>0.0013444</td>\n",
       "<td>1.0</td>\n",
       "<td>-98.6555526</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.01                        0.0949161          45.0659    45.0659            0.352249         0.352249                    0.450659        0.450659                   4406.59   4406.59\n",
       "    2        0.02                        0.0531006          10.5942    27.8301            0.0828079        0.217528                    0.105942        0.556601                   959.425   2683.01\n",
       "    3        0.03                        0.0383524          6.89702    20.8524            0.0539092        0.162989                    0.0689702       0.625571                   589.702   1985.24\n",
       "    4        0.04                        0.0301747          4.30223    16.7148            0.0336276        0.130648                    0.0430223       0.668594                   330.223   1571.48\n",
       "    5        0.05                        0.0248977          3.46867    14.0656            0.0271122        0.109941                    0.0346867       0.70328                    246.867   1306.56\n",
       "    6        0.1                         0.0128814          1.92256    7.99408            0.0150273        0.0624842                   0.096128        0.799408                   92.256    699.408\n",
       "    7        0.15                        0.00819504         1.21       5.73272            0.00945776       0.0448087                   0.0605001       0.859909                   21.0003   473.272\n",
       "    8        0.2                         0.00566466         0.664157   4.46558            0.00519126       0.0349044                   0.0332079       0.893116                   -33.5843  346.558\n",
       "    9        0.3                         0.00303736         0.478623   3.1366             0.00374107       0.0245166                   0.0478623       0.940979                   -52.1377  213.66\n",
       "    10       0.4                         0.00175694         0.275612   2.42135            0.00215427       0.018926                    0.0275612       0.96854                    -72.4388  142.135\n",
       "    11       0.5                         0.00104264         0.143856   1.96585            0.00112442       0.0153657                   0.0143856       0.982926                   -85.6144  96.5851\n",
       "    12       0.6                         0.000603794        0.0712557  1.65009            0.000556957      0.0128976                   0.00712557      0.990051                   -92.8744  65.0085\n",
       "    13       0.7                         0.000321066        0.038989   1.41993            0.00030475       0.0110986                   0.0038989       0.99395                    -96.1011  41.9929\n",
       "    14       0.8                         0.000136112        0.0336112  1.24664            0.000262715      0.00974412                  0.00336112      0.997311                   -96.6389  24.6639\n",
       "    15       0.9                         2.60869e-05        0.0134445  1.10962            0.000105086      0.00867311                  0.00134445      0.998656                   -98.6556  10.9617\n",
       "    16       1                           1.41413e-22        0.0134445  1                  0.000105086      0.00781631                  0.00134445      1                          -98.6556  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomialGLM: glm\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.00556874879852\n",
      "R^2: 0.281934926724\n",
      "LogLoss: 0.026451413465\n",
      "Null degrees of freedom: 951599\n",
      "Residual degrees of freedom: 951532\n",
      "Null deviance: 86990.3951916\n",
      "Residual deviance: 50342.3300916\n",
      "AIC: 50478.3300916\n",
      "AUC: 0.936120866614\n",
      "Gini: 0.872241733228\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.176536366121: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>NO</b></td>\n",
       "<td><b>YES</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>NO</td>\n",
       "<td>941956.0</td>\n",
       "<td>2206.0</td>\n",
       "<td>0.0023</td>\n",
       "<td> (2206.0/944162.0)</td></tr>\n",
       "<tr><td>YES</td>\n",
       "<td>4758.0</td>\n",
       "<td>2680.0</td>\n",
       "<td>0.6397</td>\n",
       "<td> (4758.0/7438.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>946714.0</td>\n",
       "<td>4886.0</td>\n",
       "<td>0.0073</td>\n",
       "<td> (6964.0/951600.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       NO      YES    Error    Rate\n",
       "-----  ------  -----  -------  -----------------\n",
       "NO     941956  2206   0.0023   (2206.0/944162.0)\n",
       "YES    4758    2680   0.6397   (4758.0/7438.0)\n",
       "Total  946714  4886   0.0073   (6964.0/951600.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.1765364</td>\n",
       "<td>0.4349237</td>\n",
       "<td>172.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.0709385</td>\n",
       "<td>0.4327279</td>\n",
       "<td>236.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.4506865</td>\n",
       "<td>0.5766437</td>\n",
       "<td>94.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.5310180</td>\n",
       "<td>0.9938104</td>\n",
       "<td>78.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9980002</td>\n",
       "<td>0.9990020</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0000148</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999502</td>\n",
       "<td>0.9999989</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_MCC</td>\n",
       "<td>0.4329258</td>\n",
       "<td>0.4621272</td>\n",
       "<td>97.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.0083747</td>\n",
       "<td>0.8563838</td>\n",
       "<td>347.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                      threshold    value     idx\n",
       "--------------------------  -----------  --------  -----\n",
       "max f1                      0.176536     0.434924  172\n",
       "max f2                      0.0709385    0.432728  236\n",
       "max f0point5                0.450687     0.576644  94\n",
       "max accuracy                0.531018     0.99381   78\n",
       "max precision               0.998        0.999002  1\n",
       "max recall                  1.4777e-05   1         399\n",
       "max specificity             0.99995      0.999999  0\n",
       "max absolute_MCC            0.432926     0.462127  97\n",
       "max min_per_class_accuracy  0.00837471   0.856384  347"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate:  0.78 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.01</td>\n",
       "<td>0.0948544</td>\n",
       "<td>44.9179887</td>\n",
       "<td>44.9179887</td>\n",
       "<td>0.3510929</td>\n",
       "<td>0.3510929</td>\n",
       "<td>0.4491799</td>\n",
       "<td>0.4491799</td>\n",
       "<td>4391.7988707</td>\n",
       "<td>4391.7988707</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.02</td>\n",
       "<td>0.0529933</td>\n",
       "<td>10.5673568</td>\n",
       "<td>27.7426728</td>\n",
       "<td>0.0825977</td>\n",
       "<td>0.2168453</td>\n",
       "<td>0.1056736</td>\n",
       "<td>0.5548535</td>\n",
       "<td>956.7356816</td>\n",
       "<td>2674.2672761</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.03</td>\n",
       "<td>0.0382336</td>\n",
       "<td>7.0180156</td>\n",
       "<td>20.8344537</td>\n",
       "<td>0.0548550</td>\n",
       "<td>0.1628485</td>\n",
       "<td>0.0701802</td>\n",
       "<td>0.6250336</td>\n",
       "<td>601.8015596</td>\n",
       "<td>1983.4453706</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.04</td>\n",
       "<td>0.0301653</td>\n",
       "<td>4.1005647</td>\n",
       "<td>16.6509814</td>\n",
       "<td>0.0320513</td>\n",
       "<td>0.1301492</td>\n",
       "<td>0.0410056</td>\n",
       "<td>0.6660393</td>\n",
       "<td>310.0564668</td>\n",
       "<td>1565.0981447</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.05</td>\n",
       "<td>0.0248209</td>\n",
       "<td>3.3745631</td>\n",
       "<td>13.9956978</td>\n",
       "<td>0.0263766</td>\n",
       "<td>0.1093947</td>\n",
       "<td>0.0337456</td>\n",
       "<td>0.6997849</td>\n",
       "<td>237.4563055</td>\n",
       "<td>1299.5697768</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1</td>\n",
       "<td>0.0128655</td>\n",
       "<td>1.9709599</td>\n",
       "<td>7.9833289</td>\n",
       "<td>0.0154056</td>\n",
       "<td>0.0624002</td>\n",
       "<td>0.0985480</td>\n",
       "<td>0.7983329</td>\n",
       "<td>97.0959935</td>\n",
       "<td>698.3328852</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.15</td>\n",
       "<td>0.0081801</td>\n",
       "<td>1.2100027</td>\n",
       "<td>5.7255535</td>\n",
       "<td>0.0094578</td>\n",
       "<td>0.0447527</td>\n",
       "<td>0.0605001</td>\n",
       "<td>0.8588330</td>\n",
       "<td>21.0002689</td>\n",
       "<td>472.5553464</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2</td>\n",
       "<td>0.0056594</td>\n",
       "<td>0.6722237</td>\n",
       "<td>4.4622210</td>\n",
       "<td>0.0052543</td>\n",
       "<td>0.0348781</td>\n",
       "<td>0.0336112</td>\n",
       "<td>0.8924442</td>\n",
       "<td>-32.7776284</td>\n",
       "<td>346.2221027</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3</td>\n",
       "<td>0.0030337</td>\n",
       "<td>0.4786233</td>\n",
       "<td>3.1343551</td>\n",
       "<td>0.0037411</td>\n",
       "<td>0.0244991</td>\n",
       "<td>0.0478623</td>\n",
       "<td>0.9403065</td>\n",
       "<td>-52.1376714</td>\n",
       "<td>213.4355113</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4</td>\n",
       "<td>0.0017560</td>\n",
       "<td>0.2742673</td>\n",
       "<td>2.4193332</td>\n",
       "<td>0.0021438</td>\n",
       "<td>0.0189103</td>\n",
       "<td>0.0274267</td>\n",
       "<td>0.9677333</td>\n",
       "<td>-72.5732724</td>\n",
       "<td>141.9333154</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0010420</td>\n",
       "<td>0.1425114</td>\n",
       "<td>1.9639688</td>\n",
       "<td>0.0011139</td>\n",
       "<td>0.0153510</td>\n",
       "<td>0.0142511</td>\n",
       "<td>0.9819844</td>\n",
       "<td>-85.7488572</td>\n",
       "<td>96.3968809</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6</td>\n",
       "<td>0.0006038</td>\n",
       "<td>0.0793224</td>\n",
       "<td>1.6498611</td>\n",
       "<td>0.0006200</td>\n",
       "<td>0.0128958</td>\n",
       "<td>0.0079322</td>\n",
       "<td>0.9899166</td>\n",
       "<td>-92.0677602</td>\n",
       "<td>64.9861074</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7</td>\n",
       "<td>0.0003209</td>\n",
       "<td>0.0389890</td>\n",
       "<td>1.4197365</td>\n",
       "<td>0.0003047</td>\n",
       "<td>0.0110971</td>\n",
       "<td>0.0038989</td>\n",
       "<td>0.9938155</td>\n",
       "<td>-96.1011024</td>\n",
       "<td>41.9736488</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8</td>\n",
       "<td>0.0001360</td>\n",
       "<td>0.0349556</td>\n",
       "<td>1.2466389</td>\n",
       "<td>0.0002732</td>\n",
       "<td>0.0097441</td>\n",
       "<td>0.0034956</td>\n",
       "<td>0.9973111</td>\n",
       "<td>-96.5044367</td>\n",
       "<td>24.6638881</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.9</td>\n",
       "<td>0.0000261</td>\n",
       "<td>0.0134445</td>\n",
       "<td>1.1096173</td>\n",
       "<td>0.0001051</td>\n",
       "<td>0.0086731</td>\n",
       "<td>0.0013444</td>\n",
       "<td>0.9986556</td>\n",
       "<td>-98.6555526</td>\n",
       "<td>10.9617281</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0134445</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0001051</td>\n",
       "<td>0.0078163</td>\n",
       "<td>0.0013444</td>\n",
       "<td>1.0</td>\n",
       "<td>-98.6555526</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.01                        0.0948544          44.918     44.918             0.351093         0.351093                    0.44918         0.44918                    4391.8    4391.8\n",
       "    2        0.02                        0.0529933          10.5674    27.7427            0.0825977        0.216845                    0.105674        0.554853                   956.736   2674.27\n",
       "    3        0.03                        0.0382336          7.01802    20.8345            0.054855         0.162849                    0.0701802       0.625034                   601.802   1983.45\n",
       "    4        0.04                        0.0301653          4.10056    16.651             0.0320513        0.130149                    0.0410056       0.666039                   310.056   1565.1\n",
       "    5        0.05                        0.0248209          3.37456    13.9957            0.0263766        0.109395                    0.0337456       0.699785                   237.456   1299.57\n",
       "    6        0.1                         0.0128655          1.97096    7.98333            0.0154056        0.0624002                   0.098548        0.798333                   97.096    698.333\n",
       "    7        0.15                        0.00818013         1.21       5.72555            0.00945776       0.0447527                   0.0605001       0.858833                   21.0003   472.555\n",
       "    8        0.2                         0.00565935         0.672224   4.46222            0.00525431       0.0348781                   0.0336112       0.892444                   -32.7776  346.222\n",
       "    9        0.3                         0.00303372         0.478623   3.13436            0.00374107       0.0244991                   0.0478623       0.940307                   -52.1377  213.436\n",
       "    10       0.4                         0.00175605         0.274267   2.41933            0.00214376       0.0189103                   0.0274267       0.967733                   -72.5733  141.933\n",
       "    11       0.5                         0.00104197         0.142511   1.96397            0.00111391       0.015351                    0.0142511       0.981984                   -85.7489  96.3969\n",
       "    12       0.6                         0.000603818        0.0793224  1.64986            0.000620008      0.0128958                   0.00793224      0.989917                   -92.0678  64.9861\n",
       "    13       0.7                         0.000320908        0.038989   1.41974            0.00030475       0.0110971                   0.0038989       0.993816                   -96.1011  41.9736\n",
       "    14       0.8                         0.000136025        0.0349556  1.24664            0.000273224      0.00974412                  0.00349556      0.997311                   -96.5044  24.6639\n",
       "    15       0.9                         2.60842e-05        0.0134445  1.10962            0.000105086      0.00867311                  0.00134445      0.998656                   -98.6556  10.9617\n",
       "    16       1                           2.23095e-23        0.0134445  1                  0.000105086      0.00781631                  0.00134445      1                          -98.6556  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>mean</b></td>\n",
       "<td><b>sd</b></td>\n",
       "<td><b>cv_1_valid</b></td>\n",
       "<td><b>cv_2_valid</b></td>\n",
       "<td><b>cv_3_valid</b></td>\n",
       "<td><b>cv_4_valid</b></td>\n",
       "<td><b>cv_5_valid</b></td>\n",
       "<td><b>cv_6_valid</b></td>\n",
       "<td><b>cv_7_valid</b></td>\n",
       "<td><b>cv_8_valid</b></td>\n",
       "<td><b>cv_9_valid</b></td>\n",
       "<td><b>cv_10_valid</b></td></tr>\n",
       "<tr><td>F0point5</td>\n",
       "<td>0.5152696</td>\n",
       "<td>0.0250176</td>\n",
       "<td>0.5109205</td>\n",
       "<td>0.4865424</td>\n",
       "<td>0.5091044</td>\n",
       "<td>0.4912215</td>\n",
       "<td>0.5683387</td>\n",
       "<td>0.5555556</td>\n",
       "<td>0.4489164</td>\n",
       "<td>0.5089629</td>\n",
       "<td>0.5113863</td>\n",
       "<td>0.5617477</td></tr>\n",
       "<tr><td>F1</td>\n",
       "<td>0.4389611</td>\n",
       "<td>0.0103761</td>\n",
       "<td>0.4327003</td>\n",
       "<td>0.4111986</td>\n",
       "<td>0.4455285</td>\n",
       "<td>0.4283388</td>\n",
       "<td>0.4422560</td>\n",
       "<td>0.4408602</td>\n",
       "<td>0.4261572</td>\n",
       "<td>0.4676471</td>\n",
       "<td>0.4429066</td>\n",
       "<td>0.4520179</td></tr>\n",
       "<tr><td>F2</td>\n",
       "<td>0.3841367</td>\n",
       "<td>0.0154139</td>\n",
       "<td>0.3752506</td>\n",
       "<td>0.3560606</td>\n",
       "<td>0.3960682</td>\n",
       "<td>0.3797286</td>\n",
       "<td>0.3619578</td>\n",
       "<td>0.3654189</td>\n",
       "<td>0.4055944</td>\n",
       "<td>0.4325353</td>\n",
       "<td>0.3906012</td>\n",
       "<td>0.3781513</td></tr>\n",
       "<tr><td>accuracy</td>\n",
       "<td>0.992906</td>\n",
       "<td>0.0003683</td>\n",
       "<td>0.99278</td>\n",
       "<td>0.9929234</td>\n",
       "<td>0.9928451</td>\n",
       "<td>0.9926658</td>\n",
       "<td>0.9934509</td>\n",
       "<td>0.9934075</td>\n",
       "<td>0.9917685</td>\n",
       "<td>0.9924114</td>\n",
       "<td>0.9932408</td>\n",
       "<td>0.9935661</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.9361212</td>\n",
       "<td>0.0037140</td>\n",
       "<td>0.9312317</td>\n",
       "<td>0.9263271</td>\n",
       "<td>0.9406282</td>\n",
       "<td>0.9357829</td>\n",
       "<td>0.9381734</td>\n",
       "<td>0.9299654</td>\n",
       "<td>0.9415209</td>\n",
       "<td>0.9421389</td>\n",
       "<td>0.9411147</td>\n",
       "<td>0.9343290</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.0070940</td>\n",
       "<td>0.0003683</td>\n",
       "<td>0.0072200</td>\n",
       "<td>0.0070766</td>\n",
       "<td>0.0071549</td>\n",
       "<td>0.0073342</td>\n",
       "<td>0.0065491</td>\n",
       "<td>0.0065925</td>\n",
       "<td>0.0082315</td>\n",
       "<td>0.0075885</td>\n",
       "<td>0.0067592</td>\n",
       "<td>0.0064339</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>675.1</td>\n",
       "<td>35.302197</td>\n",
       "<td>687.0</td>\n",
       "<td>673.0</td>\n",
       "<td>682.0</td>\n",
       "<td>702.0</td>\n",
       "<td>623.0</td>\n",
       "<td>624.0</td>\n",
       "<td>781.0</td>\n",
       "<td>724.0</td>\n",
       "<td>644.0</td>\n",
       "<td>611.0</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>44.910137</td>\n",
       "<td>1.1284207</td>\n",
       "<td>43.13659</td>\n",
       "<td>42.37636</td>\n",
       "<td>45.5871</td>\n",
       "<td>43.988243</td>\n",
       "<td>45.194077</td>\n",
       "<td>44.11143</td>\n",
       "<td>44.163666</td>\n",
       "<td>47.880787</td>\n",
       "<td>46.806732</td>\n",
       "<td>45.856384</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>0.0264521</td>\n",
       "<td>0.0005841</td>\n",
       "<td>0.0277108</td>\n",
       "<td>0.0272276</td>\n",
       "<td>0.0258456</td>\n",
       "<td>0.0266480</td>\n",
       "<td>0.0267848</td>\n",
       "<td>0.0272965</td>\n",
       "<td>0.0262747</td>\n",
       "<td>0.0259731</td>\n",
       "<td>0.0247288</td>\n",
       "<td>0.0260313</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.6447783</td>\n",
       "<td>0.0197214</td>\n",
       "<td>0.6552632</td>\n",
       "<td>0.6731572</td>\n",
       "<td>0.6312248</td>\n",
       "<td>0.6469799</td>\n",
       "<td>0.6771242</td>\n",
       "<td>0.672</td>\n",
       "<td>0.6070461</td>\n",
       "<td>0.5880829</td>\n",
       "<td>0.6379067</td>\n",
       "<td>0.6589987</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.4512001</td>\n",
       "<td>0.0132510</td>\n",
       "<td>0.4441879</td>\n",
       "<td>0.4223513</td>\n",
       "<td>0.4521102</td>\n",
       "<td>0.4349573</td>\n",
       "<td>0.4733117</td>\n",
       "<td>0.4667479</td>\n",
       "<td>0.4235782</td>\n",
       "<td>0.4682626</td>\n",
       "<td>0.4511914</td>\n",
       "<td>0.4753026</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.0055688</td>\n",
       "<td>0.0001001</td>\n",
       "<td>0.0057960</td>\n",
       "<td>0.0056343</td>\n",
       "<td>0.0054985</td>\n",
       "<td>0.0056006</td>\n",
       "<td>0.0056604</td>\n",
       "<td>0.0056263</td>\n",
       "<td>0.0056170</td>\n",
       "<td>0.0055826</td>\n",
       "<td>0.0052462</td>\n",
       "<td>0.0054262</td></tr>\n",
       "<tr><td>null_deviance</td>\n",
       "<td>8699.039</td>\n",
       "<td>129.67957</td>\n",
       "<td>8855.836</td>\n",
       "<td>8457.957</td>\n",
       "<td>8693.673</td>\n",
       "<td>8719.28</td>\n",
       "<td>8903.928</td>\n",
       "<td>8751.063</td>\n",
       "<td>8638.333</td>\n",
       "<td>8976.207</td>\n",
       "<td>8344.733</td>\n",
       "<td>8649.386</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.5862829</td>\n",
       "<td>0.0489969</td>\n",
       "<td>0.5809313</td>\n",
       "<td>0.5542453</td>\n",
       "<td>0.5626283</td>\n",
       "<td>0.5445135</td>\n",
       "<td>0.7017046</td>\n",
       "<td>0.6721311</td>\n",
       "<td>0.4654896</td>\n",
       "<td>0.5408163</td>\n",
       "<td>0.5701559</td>\n",
       "<td>0.6702128</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.2817735</td>\n",
       "<td>0.0107426</td>\n",
       "<td>0.2684955</td>\n",
       "<td>0.2490805</td>\n",
       "<td>0.289058</td>\n",
       "<td>0.2748079</td>\n",
       "<td>0.2904295</td>\n",
       "<td>0.2842717</td>\n",
       "<td>0.2721981</td>\n",
       "<td>0.3044534</td>\n",
       "<td>0.2877113</td>\n",
       "<td>0.2972288</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.3552217</td>\n",
       "<td>0.0197214</td>\n",
       "<td>0.3447368</td>\n",
       "<td>0.3268428</td>\n",
       "<td>0.3687752</td>\n",
       "<td>0.3530201</td>\n",
       "<td>0.3228758</td>\n",
       "<td>0.328</td>\n",
       "<td>0.3929539</td>\n",
       "<td>0.4119171</td>\n",
       "<td>0.3620934</td>\n",
       "<td>0.3410014</td></tr>\n",
       "<tr><td>residual_deviance</td>\n",
       "<td>5034.233</td>\n",
       "<td>108.60929</td>\n",
       "<td>5273.5356</td>\n",
       "<td>5178.796</td>\n",
       "<td>4927.145</td>\n",
       "<td>5101.2773</td>\n",
       "<td>5095.92</td>\n",
       "<td>5167.3857</td>\n",
       "<td>4985.8364</td>\n",
       "<td>4956.0356</td>\n",
       "<td>4712.223</td>\n",
       "<td>4944.1763</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.9979289</td>\n",
       "<td>0.0004991</td>\n",
       "<td>0.9979978</td>\n",
       "<td>0.9979975</td>\n",
       "<td>0.9977478</td>\n",
       "<td>0.9976835</td>\n",
       "<td>0.9988872</td>\n",
       "<td>0.9987221</td>\n",
       "<td>0.9964628</td>\n",
       "<td>0.9971469</td>\n",
       "<td>0.9979592</td>\n",
       "<td>0.9986841</td></tr></table></div>"
      ],
      "text/plain": [
       "                     mean        sd           cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid    cv_6_valid    cv_7_valid    cv_8_valid    cv_9_valid    cv_10_valid\n",
       "-------------------  ----------  -----------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  -------------\n",
       "F0point5             0.51527     0.0250176    0.51092       0.486542      0.509104      0.491222      0.568339      0.555556      0.448916      0.508963      0.511386      0.561748\n",
       "F1                   0.438961    0.0103761    0.4327        0.411199      0.445528      0.428339      0.442256      0.44086       0.426157      0.467647      0.442907      0.452018\n",
       "F2                   0.384137    0.0154139    0.375251      0.356061      0.396068      0.379729      0.361958      0.365419      0.405594      0.432535      0.390601      0.378151\n",
       "accuracy             0.992906    0.000368265  0.99278       0.992923      0.992845      0.992666      0.993451      0.993407      0.991769      0.992411      0.993241      0.993566\n",
       "auc                  0.936121    0.00371404   0.931232      0.926327      0.940628      0.935783      0.938173      0.929965      0.941521      0.942139      0.941115      0.934329\n",
       "err                  0.00709405  0.000368265  0.00721995    0.00707661    0.00715492    0.0073342     0.00654914    0.0065925     0.00823154    0.00758854    0.00675917    0.00643388\n",
       "err_count            675.1       35.3022      687           673           682           702           623           624           781           724           644           611\n",
       "lift_top_group       44.9101     1.12842      43.1366       42.3764       45.5871       43.9882       45.1941       44.1114       44.1637       47.8808       46.8067       45.8564\n",
       "logloss              0.0264521   0.000584097  0.0277108     0.0272276     0.0258456     0.026648      0.0267848     0.0272965     0.0262747     0.0259731     0.0247288     0.0260313\n",
       "max_per_class_error  0.644778    0.0197214    0.655263      0.673157      0.631225      0.64698       0.677124      0.672         0.607046      0.588083      0.637907      0.658999\n",
       "mcc                  0.4512      0.013251     0.444188      0.422351      0.45211       0.434957      0.473312      0.466748      0.423578      0.468263      0.451191      0.475303\n",
       "mse                  0.0055688   0.000100105  0.00579596    0.00563426    0.00549851    0.00560056    0.00566039    0.00562626    0.00561705    0.00558258    0.00524624    0.00542622\n",
       "null_deviance        8699.04     129.68       8855.84       8457.96       8693.67       8719.28       8903.93       8751.06       8638.33       8976.21       8344.73       8649.39\n",
       "precision            0.586283    0.0489969    0.580931      0.554245      0.562628      0.544513      0.701705      0.672131      0.46549       0.540816      0.570156      0.670213\n",
       "r2                   0.281773    0.0107426    0.268495      0.249081      0.289058      0.274808      0.290429      0.284272      0.272198      0.304453      0.287711      0.297229\n",
       "recall               0.355222    0.0197214    0.344737      0.326843      0.368775      0.35302       0.322876      0.328         0.392954      0.411917      0.362093      0.341001\n",
       "residual_deviance    5034.23     108.609      5273.54       5178.8        4927.15       5101.28       5095.92       5167.39       4985.84       4956.04       4712.22       4944.18\n",
       "specificity          0.997929    0.000499112  0.997998      0.997997      0.997748      0.997683      0.998887      0.998722      0.996463      0.997147      0.997959      0.998684"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>iteration</b></td>\n",
       "<td><b>negative_log_likelihood</b></td>\n",
       "<td><b>objective</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-05-09 14:33:38</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>0</td>\n",
       "<td>32000.4571252</td>\n",
       "<td>0.0339572</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-05-09 14:33:39</td>\n",
       "<td> 0.712 sec</td>\n",
       "<td>1</td>\n",
       "<td>27197.5649912</td>\n",
       "<td>0.0289662</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-05-09 14:33:40</td>\n",
       "<td> 1.361 sec</td>\n",
       "<td>2</td>\n",
       "<td>25804.3687672</td>\n",
       "<td>0.0275705</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-05-09 14:33:40</td>\n",
       "<td> 2.050 sec</td>\n",
       "<td>3</td>\n",
       "<td>25266.9568584</td>\n",
       "<td>0.0270804</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-05-09 14:33:41</td>\n",
       "<td> 2.724 sec</td>\n",
       "<td>4</td>\n",
       "<td>25139.7690902</td>\n",
       "<td>0.0269536</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-05-09 14:33:42</td>\n",
       "<td> 3.374 sec</td>\n",
       "<td>5</td>\n",
       "<td>25106.4599817</td>\n",
       "<td>0.0269251</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-05-09 14:33:42</td>\n",
       "<td> 3.937 sec</td>\n",
       "<td>6</td>\n",
       "<td>25104.6547756</td>\n",
       "<td>0.0269216</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-05-09 14:33:43</td>\n",
       "<td> 4.473 sec</td>\n",
       "<td>7</td>\n",
       "<td>25104.3061767</td>\n",
       "<td>0.0269214</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration    iteration    negative_log_likelihood    objective\n",
       "--  -------------------  ----------  -----------  -------------------------  -----------\n",
       "    2016-05-09 14:33:38  0.000 sec   0            32000.5                    0.0339572\n",
       "    2016-05-09 14:33:39  0.712 sec   1            27197.6                    0.0289662\n",
       "    2016-05-09 14:33:40  1.361 sec   2            25804.4                    0.0275705\n",
       "    2016-05-09 14:33:40  2.050 sec   3            25267                      0.0270804\n",
       "    2016-05-09 14:33:41  2.724 sec   4            25139.8                    0.0269536\n",
       "    2016-05-09 14:33:42  3.374 sec   5            25106.5                    0.0269251\n",
       "    2016-05-09 14:33:42  3.937 sec   6            25104.7                    0.0269216\n",
       "    2016-05-09 14:33:43  4.473 sec   7            25104.3                    0.0269214"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving cross-validation predictions to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv_pred_glm = glm_classifier.cross_validation_holdout_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_pred_glm_df = cv_pred_glm.as_data_frame(use_pandas=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outDf2 = pd.DataFrame( zip (IdText.PairId , cv_pred_glm_df.YES ) , columns = [\"PairId\",\"Probability\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outDf2.to_csv(\"glm_prediction.csv\" , \n",
    "              sep = \" \" , \n",
    "              header = False , \n",
    "              index = False , \n",
    "              quoting= csv.QUOTE_NONE , \n",
    "              quotechar='',\n",
    "              escapechar=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a RandomForestEstimator & Saving cross-validation predictions to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "drf Model Build Progress: [##################################################] 100%\n"
     ]
    }
   ],
   "source": [
    "rf_classifier = H2ORandomForestEstimator(ntrees=10, \n",
    "                                         max_depth=20, \n",
    "                                         balance_classes=False,\n",
    "                                         nfolds = 10 ,\n",
    "                                         keep_cross_validation_predictions = True )\n",
    "\n",
    "rf_classifier.train(x=range(1,foldpro_df.ncol), \n",
    "                         y=0, \n",
    "                         training_frame= foldpro_df ,\n",
    "                         seed = 1234 )\n",
    "\n",
    "cv_pred_rf = rf_classifier.cross_validation_holdout_predictions()\n",
    "cv_pred_rf_df = cv_pred_rf.as_data_frame(use_pandas=True)\n",
    "outDf3 = pd.DataFrame( zip (IdText.PairId , cv_pred_rf_df.YES ) , columns = [\"PairId\",\"Probability\"])\n",
    "outDf3.to_csv(\"rf_prediction.csv\" , \n",
    "              sep = \" \" , \n",
    "              header = False , \n",
    "              index = False , \n",
    "              quoting= csv.QUOTE_NONE , \n",
    "              quotechar='',\n",
    "              escapechar=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2ORandomForestEstimator :  Distributed Random Forest\n",
      "Model Key:  DRF_model_python_1462800685859_9518\n",
      "\n",
      "Model Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>model_size_in_bytes</b></td>\n",
       "<td><b>min_depth</b></td>\n",
       "<td><b>max_depth</b></td>\n",
       "<td><b>mean_depth</b></td>\n",
       "<td><b>min_leaves</b></td>\n",
       "<td><b>max_leaves</b></td>\n",
       "<td><b>mean_leaves</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>10.0</td>\n",
       "<td>320227.0</td>\n",
       "<td>20.0</td>\n",
       "<td>20.0</td>\n",
       "<td>20.0</td>\n",
       "<td>2333.0</td>\n",
       "<td>3233.0</td>\n",
       "<td>2768.3</td></tr></table></div>"
      ],
      "text/plain": [
       "    number_of_trees    model_size_in_bytes    min_depth    max_depth    mean_depth    min_leaves    max_leaves    mean_leaves\n",
       "--  -----------------  ---------------------  -----------  -----------  ------------  ------------  ------------  -------------\n",
       "    10                 320227                 20           20           20            2333          3233          2768.3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: drf\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.00605094194869\n",
      "R^2: 0.219293702091\n",
      "LogLoss: 0.0452897726089\n",
      "AUC: 0.889635541423\n",
      "Gini: 0.779271082847\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.350888384713: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>NO</b></td>\n",
       "<td><b>YES</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>NO</td>\n",
       "<td>933250.0</td>\n",
       "<td>1576.0</td>\n",
       "<td>0.0017</td>\n",
       "<td> (1576.0/934826.0)</td></tr>\n",
       "<tr><td>YES</td>\n",
       "<td>4998.0</td>\n",
       "<td>2362.0</td>\n",
       "<td>0.6791</td>\n",
       "<td> (4998.0/7360.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>938248.0</td>\n",
       "<td>3938.0</td>\n",
       "<td>0.007</td>\n",
       "<td> (6574.0/942186.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       NO      YES    Error    Rate\n",
       "-----  ------  -----  -------  -----------------\n",
       "NO     933250  1576   0.0017   (1576.0/934826.0)\n",
       "YES    4998    2362   0.6791   (4998.0/7360.0)\n",
       "Total  938248  3938   0.007    (6574.0/942186.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.3508884</td>\n",
       "<td>0.4181271</td>\n",
       "<td>104.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1759541</td>\n",
       "<td>0.3937087</td>\n",
       "<td>185.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.5368051</td>\n",
       "<td>0.5601532</td>\n",
       "<td>59.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.6000566</td>\n",
       "<td>0.9936998</td>\n",
       "<td>47.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9818182</td>\n",
       "<td>0.8847203</td>\n",
       "<td>2.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0000002</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9998192</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_MCC</td>\n",
       "<td>0.5368051</td>\n",
       "<td>0.4479836</td>\n",
       "<td>59.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.0046077</td>\n",
       "<td>0.8157304</td>\n",
       "<td>360.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                      threshold    value     idx\n",
       "--------------------------  -----------  --------  -----\n",
       "max f1                      0.350888     0.418127  104\n",
       "max f2                      0.175954     0.393709  185\n",
       "max f0point5                0.536805     0.560153  59\n",
       "max accuracy                0.600057     0.9937    47\n",
       "max precision               0.981818     0.88472   2\n",
       "max recall                  1.94484e-07  1         399\n",
       "max specificity             1            0.999819  0\n",
       "max absolute_MCC            0.536805     0.447984  59\n",
       "max min_per_class_accuracy  0.00460769   0.81573   360"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate:  0.78 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.01</td>\n",
       "<td>0.1110421</td>\n",
       "<td>84.4312987</td>\n",
       "<td>84.4312987</td>\n",
       "<td>0.6599412</td>\n",
       "<td>0.6599412</td>\n",
       "<td>0.8443130</td>\n",
       "<td>0.8443130</td>\n",
       "<td>8343.1298736</td>\n",
       "<td>8343.1298736</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.02</td>\n",
       "<td>0.0404700</td>\n",
       "<td>6.3726808</td>\n",
       "<td>45.4019898</td>\n",
       "<td>0.0498108</td>\n",
       "<td>0.3548760</td>\n",
       "<td>0.0637268</td>\n",
       "<td>0.9080398</td>\n",
       "<td>537.2680828</td>\n",
       "<td>4440.1989782</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.03</td>\n",
       "<td>0.0240376</td>\n",
       "<td>2.1242269</td>\n",
       "<td>30.9760688</td>\n",
       "<td>0.0166036</td>\n",
       "<td>0.2421185</td>\n",
       "<td>0.0212423</td>\n",
       "<td>0.9292821</td>\n",
       "<td>112.4226943</td>\n",
       "<td>2997.6068836</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.04</td>\n",
       "<td>0.0185004</td>\n",
       "<td>1.1562248</td>\n",
       "<td>23.5211078</td>\n",
       "<td>0.0090374</td>\n",
       "<td>0.1838483</td>\n",
       "<td>0.0115622</td>\n",
       "<td>0.9408443</td>\n",
       "<td>15.6224792</td>\n",
       "<td>2252.1107825</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.05</td>\n",
       "<td>0.0154483</td>\n",
       "<td>0.9276687</td>\n",
       "<td>19.0024200</td>\n",
       "<td>0.0072509</td>\n",
       "<td>0.1485288</td>\n",
       "<td>0.0092767</td>\n",
       "<td>0.9501210</td>\n",
       "<td>-7.2331272</td>\n",
       "<td>1800.2420005</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1</td>\n",
       "<td>0.0089384</td>\n",
       "<td>0.4598010</td>\n",
       "<td>9.7311105</td>\n",
       "<td>0.0035939</td>\n",
       "<td>0.0760614</td>\n",
       "<td>0.0229901</td>\n",
       "<td>0.9731111</td>\n",
       "<td>-54.0198978</td>\n",
       "<td>873.1110514</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.15</td>\n",
       "<td>0.0063389</td>\n",
       "<td>0.2312450</td>\n",
       "<td>6.5644887</td>\n",
       "<td>0.0018075</td>\n",
       "<td>0.0513101</td>\n",
       "<td>0.0115622</td>\n",
       "<td>0.9846733</td>\n",
       "<td>-76.8755042</td>\n",
       "<td>556.4488662</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2</td>\n",
       "<td>0.0047647</td>\n",
       "<td>0.1613337</td>\n",
       "<td>4.9636999</td>\n",
       "<td>0.0012610</td>\n",
       "<td>0.0387978</td>\n",
       "<td>0.0080667</td>\n",
       "<td>0.9927400</td>\n",
       "<td>-83.8666308</td>\n",
       "<td>396.3699919</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3</td>\n",
       "<td>0.0027616</td>\n",
       "<td>0.0578112</td>\n",
       "<td>3.3284037</td>\n",
       "<td>0.0004519</td>\n",
       "<td>0.0260158</td>\n",
       "<td>0.0057811</td>\n",
       "<td>0.9985211</td>\n",
       "<td>-94.2188760</td>\n",
       "<td>232.8403693</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4</td>\n",
       "<td>0.0016075</td>\n",
       "<td>0.0134445</td>\n",
       "<td>2.4996639</td>\n",
       "<td>0.0001051</td>\n",
       "<td>0.0195381</td>\n",
       "<td>0.0013444</td>\n",
       "<td>0.9998656</td>\n",
       "<td>-98.6555526</td>\n",
       "<td>149.9663888</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5000011</td>\n",
       "<td>0.0009018</td>\n",
       "<td>0.0013444</td>\n",
       "<td>1.9999958</td>\n",
       "<td>0.0000105</td>\n",
       "<td>0.0156326</td>\n",
       "<td>0.0001344</td>\n",
       "<td>1.0</td>\n",
       "<td>-99.8655567</td>\n",
       "<td>99.9995797</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6000179</td>\n",
       "<td>0.0004850</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6666170</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0130268</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.6617044</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7000042</td>\n",
       "<td>0.0002277</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4285629</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0111661</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.8562850</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8002354</td>\n",
       "<td>0.0001112</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2496323</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0097675</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>24.9632307</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.9047446</td>\n",
       "<td>0.0000205</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1052842</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0086392</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>10.5284248</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0078163</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.01                        0.111042           84.4313     84.4313            0.659941         0.659941                    0.844313        0.844313                   8343.13   8343.13\n",
       "    2        0.02                        0.04047            6.37268     45.402             0.0498108        0.354876                    0.0637268       0.90804                    537.268   4440.2\n",
       "    3        0.03                        0.0240376          2.12423     30.9761            0.0166036        0.242119                    0.0212423       0.929282                   112.423   2997.61\n",
       "    4        0.04                        0.0185004          1.15622     23.5211            0.00903741       0.183848                    0.0115622       0.940844                   15.6225   2252.11\n",
       "    5        0.05                        0.0154483          0.927669    19.0024            0.00725095       0.148529                    0.00927669      0.950121                   -7.23313  1800.24\n",
       "    6        0.1                         0.00893835         0.459801    9.73111            0.00359395       0.0760614                   0.0229901       0.973111                   -54.0199  873.111\n",
       "    7        0.15                        0.00633892         0.231245    6.56449            0.00180748       0.0513101                   0.0115622       0.984673                   -76.8755  556.449\n",
       "    8        0.2                         0.00476469         0.161334    4.9637             0.00126103       0.0387978                   0.00806668      0.99274                    -83.8666  396.37\n",
       "    9        0.3                         0.00276155         0.0578112   3.3284             0.000451871      0.0260158                   0.00578112      0.998521                   -94.2189  232.84\n",
       "    10       0.4                         0.0016075          0.0134445   2.49966            0.000105086      0.0195381                   0.00134445      0.999866                   -98.6556  149.966\n",
       "    11       0.500001                    0.000901812        0.00134443  2                  1.05085e-05      0.0156326                   0.000134445     1                          -99.8656  99.9996\n",
       "    12       0.600018                    0.000484973        0           1.66662            0                0.0130268                   0               1                          -100      66.6617\n",
       "    13       0.700004                    0.000227749        0           1.42856            0                0.0111661                   0               1                          -100      42.8563\n",
       "    14       0.800235                    0.000111175        0           1.24963            0                0.00976751                  0               1                          -100      24.9632\n",
       "    15       0.904745                    2.05219e-05        0           1.10528            0                0.00863924                  0               1                          -100      10.5284\n",
       "    16       1                           0                  0           1                  0                0.00781631                  0               1                          -100      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: drf\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.00542970485134\n",
      "R^2: 0.299864017392\n",
      "LogLoss: 0.0264797057582\n",
      "AUC: 0.940252056569\n",
      "Gini: 0.880504113138\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.23379885455: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>NO</b></td>\n",
       "<td><b>YES</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>NO</td>\n",
       "<td>942787.0</td>\n",
       "<td>1375.0</td>\n",
       "<td>0.0015</td>\n",
       "<td> (1375.0/944162.0)</td></tr>\n",
       "<tr><td>YES</td>\n",
       "<td>4619.0</td>\n",
       "<td>2819.0</td>\n",
       "<td>0.621</td>\n",
       "<td> (4619.0/7438.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>947406.0</td>\n",
       "<td>4194.0</td>\n",
       "<td>0.0063</td>\n",
       "<td> (5994.0/951600.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       NO      YES    Error    Rate\n",
       "-----  ------  -----  -------  -----------------\n",
       "NO     942787  1375   0.0015   (1375.0/944162.0)\n",
       "YES    4619    2819   0.621    (4619.0/7438.0)\n",
       "Total  947406  4194   0.0063   (5994.0/951600.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.2337989</td>\n",
       "<td>0.4846974</td>\n",
       "<td>129.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1230797</td>\n",
       "<td>0.4617256</td>\n",
       "<td>191.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.4049074</td>\n",
       "<td>0.6224537</td>\n",
       "<td>78.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4049074</td>\n",
       "<td>0.9941194</td>\n",
       "<td>78.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9036093</td>\n",
       "<td>0.9958974</td>\n",
       "<td>3.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0000187</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999958</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_MCC</td>\n",
       "<td>0.3223929</td>\n",
       "<td>0.5074221</td>\n",
       "<td>98.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.0066538</td>\n",
       "<td>0.8552030</td>\n",
       "<td>344.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                      threshold    value     idx\n",
       "--------------------------  -----------  --------  -----\n",
       "max f1                      0.233799     0.484697  129\n",
       "max f2                      0.12308      0.461726  191\n",
       "max f0point5                0.404907     0.622454  78\n",
       "max accuracy                0.404907     0.994119  78\n",
       "max precision               0.903609     0.995897  3\n",
       "max recall                  1.86952e-05  1         399\n",
       "max specificity             1            0.999996  0\n",
       "max absolute_MCC            0.322393     0.507422  98\n",
       "max min_per_class_accuracy  0.00665381   0.855203  344"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate:  0.78 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.01</td>\n",
       "<td>0.1213896</td>\n",
       "<td>48.6958860</td>\n",
       "<td>48.6958860</td>\n",
       "<td>0.3806221</td>\n",
       "<td>0.3806221</td>\n",
       "<td>0.4869589</td>\n",
       "<td>0.4869589</td>\n",
       "<td>4769.5885991</td>\n",
       "<td>4769.5885991</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.02</td>\n",
       "<td>0.1029618</td>\n",
       "<td>6.1441248</td>\n",
       "<td>27.4200054</td>\n",
       "<td>0.0480244</td>\n",
       "<td>0.2143232</td>\n",
       "<td>0.0614412</td>\n",
       "<td>0.5484001</td>\n",
       "<td>514.4124765</td>\n",
       "<td>2642.0005378</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.03</td>\n",
       "<td>0.0463944</td>\n",
       "<td>4.5711213</td>\n",
       "<td>19.8037107</td>\n",
       "<td>0.0357293</td>\n",
       "<td>0.1547919</td>\n",
       "<td>0.0457112</td>\n",
       "<td>0.5941113</td>\n",
       "<td>357.1121269</td>\n",
       "<td>1880.3710675</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.04</td>\n",
       "<td>0.0241943</td>\n",
       "<td>5.4719010</td>\n",
       "<td>16.2207583</td>\n",
       "<td>0.0427701</td>\n",
       "<td>0.1267865</td>\n",
       "<td>0.0547190</td>\n",
       "<td>0.6488303</td>\n",
       "<td>447.1901049</td>\n",
       "<td>1522.0758268</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.05</td>\n",
       "<td>0.0181290</td>\n",
       "<td>3.8585641</td>\n",
       "<td>13.7483194</td>\n",
       "<td>0.0301597</td>\n",
       "<td>0.1074611</td>\n",
       "<td>0.0385856</td>\n",
       "<td>0.6874160</td>\n",
       "<td>285.8564130</td>\n",
       "<td>1274.8319441</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1</td>\n",
       "<td>0.0093107</td>\n",
       "<td>2.1860715</td>\n",
       "<td>7.9671955</td>\n",
       "<td>0.0170870</td>\n",
       "<td>0.0622741</td>\n",
       "<td>0.1093036</td>\n",
       "<td>0.7967195</td>\n",
       "<td>118.6071525</td>\n",
       "<td>696.7195483</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.15</td>\n",
       "<td>0.0064319</td>\n",
       "<td>1.2315138</td>\n",
       "<td>5.7219683</td>\n",
       "<td>0.0096259</td>\n",
       "<td>0.0447247</td>\n",
       "<td>0.0615757</td>\n",
       "<td>0.8582952</td>\n",
       "<td>23.1513848</td>\n",
       "<td>472.1968271</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2</td>\n",
       "<td>0.0047662</td>\n",
       "<td>0.8147351</td>\n",
       "<td>4.4951600</td>\n",
       "<td>0.0063682</td>\n",
       "<td>0.0351356</td>\n",
       "<td>0.0407368</td>\n",
       "<td>0.8990320</td>\n",
       "<td>-18.5264856</td>\n",
       "<td>349.5159989</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3</td>\n",
       "<td>0.0027073</td>\n",
       "<td>0.5350901</td>\n",
       "<td>3.1751367</td>\n",
       "<td>0.0041824</td>\n",
       "<td>0.0248179</td>\n",
       "<td>0.0535090</td>\n",
       "<td>0.9525410</td>\n",
       "<td>-46.4909922</td>\n",
       "<td>217.5136685</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4</td>\n",
       "<td>0.0015267</td>\n",
       "<td>0.2594784</td>\n",
       "<td>2.4462221</td>\n",
       "<td>0.0020282</td>\n",
       "<td>0.0191204</td>\n",
       "<td>0.0259478</td>\n",
       "<td>0.9784888</td>\n",
       "<td>-74.0521646</td>\n",
       "<td>144.6222103</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0008341</td>\n",
       "<td>0.1210003</td>\n",
       "<td>1.9811777</td>\n",
       "<td>0.0009458</td>\n",
       "<td>0.0154855</td>\n",
       "<td>0.0121000</td>\n",
       "<td>0.9905889</td>\n",
       "<td>-87.8999731</td>\n",
       "<td>98.1177736</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6</td>\n",
       "<td>0.0004441</td>\n",
       "<td>0.0470557</td>\n",
       "<td>1.6588241</td>\n",
       "<td>0.0003678</td>\n",
       "<td>0.0129659</td>\n",
       "<td>0.0047056</td>\n",
       "<td>0.9952944</td>\n",
       "<td>-95.2944340</td>\n",
       "<td>65.8824057</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7000011</td>\n",
       "<td>0.0002174</td>\n",
       "<td>0.0201665</td>\n",
       "<td>1.4247280</td>\n",
       "<td>0.0001576</td>\n",
       "<td>0.0111361</td>\n",
       "<td>0.0020167</td>\n",
       "<td>0.9973111</td>\n",
       "<td>-97.9833500</td>\n",
       "<td>42.4728011</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8000011</td>\n",
       "<td>0.0000999</td>\n",
       "<td>0.0053778</td>\n",
       "<td>1.2473095</td>\n",
       "<td>0.0000420</td>\n",
       "<td>0.0097494</td>\n",
       "<td>0.0005378</td>\n",
       "<td>0.9978489</td>\n",
       "<td>-99.4622210</td>\n",
       "<td>24.7309467</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.9000504</td>\n",
       "<td>0.0000319</td>\n",
       "<td>0.0080627</td>\n",
       "<td>1.1095551</td>\n",
       "<td>0.0000630</td>\n",
       "<td>0.0086726</td>\n",
       "<td>0.0008067</td>\n",
       "<td>0.9986556</td>\n",
       "<td>-99.1937298</td>\n",
       "<td>10.9555095</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0134513</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0001051</td>\n",
       "<td>0.0078163</td>\n",
       "<td>0.0013444</td>\n",
       "<td>1.0</td>\n",
       "<td>-98.6548741</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.01                        0.12139            48.6959     48.6959            0.380622         0.380622                    0.486959        0.486959                   4769.59   4769.59\n",
       "    2        0.02                        0.102962           6.14412     27.42              0.0480244        0.214323                    0.0614412       0.5484                     514.412   2642\n",
       "    3        0.03                        0.0463944          4.57112     19.8037            0.0357293        0.154792                    0.0457112       0.594111                   357.112   1880.37\n",
       "    4        0.04                        0.0241943          5.4719      16.2208            0.0427701        0.126786                    0.054719        0.64883                    447.19    1522.08\n",
       "    5        0.05                        0.018129           3.85856     13.7483            0.0301597        0.107461                    0.0385856       0.687416                   285.856   1274.83\n",
       "    6        0.1                         0.00931068         2.18607     7.9672             0.017087         0.0622741                   0.109304        0.79672                    118.607   696.72\n",
       "    7        0.15                        0.00643191         1.23151     5.72197            0.00962589       0.0447247                   0.0615757       0.858295                   23.1514   472.197\n",
       "    8        0.2                         0.00476619         0.814735    4.49516            0.00636822       0.0351356                   0.0407368       0.899032                   -18.5265  349.516\n",
       "    9        0.3                         0.00270735         0.53509     3.17514            0.00418243       0.0248179                   0.053509        0.952541                   -46.491   217.514\n",
       "    10       0.4                         0.00152669         0.259478    2.44622            0.00202816       0.0191204                   0.0259478       0.978489                   -74.0522  144.622\n",
       "    11       0.5                         0.000834125        0.121       1.98118            0.000945776      0.0154855                   0.0121          0.990589                   -87.9     98.1178\n",
       "    12       0.6                         0.00044413         0.0470557   1.65882            0.000367802      0.0129659                   0.00470557      0.995294                   -95.2944  65.8824\n",
       "    13       0.700001                    0.000217414        0.0201665   1.42473            0.000157628      0.0111361                   0.00201667      0.997311                   -97.9834  42.4728\n",
       "    14       0.800001                    9.99451e-05        0.00537779  1.24731            4.20345e-05      0.00974936                  0.000537779     0.997849                   -99.4622  24.7309\n",
       "    15       0.90005                     3.18587e-05        0.0080627   1.10956            6.30206e-05      0.00867263                  0.000806668     0.998656                   -99.1937  10.9555\n",
       "    16       1                           0                  0.0134513   1                  0.000105139      0.00781631                  0.00134445      1                          -98.6549  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>mean</b></td>\n",
       "<td><b>sd</b></td>\n",
       "<td><b>cv_1_valid</b></td>\n",
       "<td><b>cv_2_valid</b></td>\n",
       "<td><b>cv_3_valid</b></td>\n",
       "<td><b>cv_4_valid</b></td>\n",
       "<td><b>cv_5_valid</b></td>\n",
       "<td><b>cv_6_valid</b></td>\n",
       "<td><b>cv_7_valid</b></td>\n",
       "<td><b>cv_8_valid</b></td>\n",
       "<td><b>cv_9_valid</b></td>\n",
       "<td><b>cv_10_valid</b></td></tr>\n",
       "<tr><td>F0point5</td>\n",
       "<td>0.5865772</td>\n",
       "<td>0.0145475</td>\n",
       "<td>0.5857915</td>\n",
       "<td>0.5405405</td>\n",
       "<td>0.590115</td>\n",
       "<td>0.5735230</td>\n",
       "<td>0.6006071</td>\n",
       "<td>0.59412</td>\n",
       "<td>0.6055734</td>\n",
       "<td>0.6198536</td>\n",
       "<td>0.5726016</td>\n",
       "<td>0.5830465</td></tr>\n",
       "<tr><td>F1</td>\n",
       "<td>0.4864603</td>\n",
       "<td>0.0122031</td>\n",
       "<td>0.4956063</td>\n",
       "<td>0.4632953</td>\n",
       "<td>0.4779983</td>\n",
       "<td>0.4654418</td>\n",
       "<td>0.4968610</td>\n",
       "<td>0.4995708</td>\n",
       "<td>0.5243620</td>\n",
       "<td>0.4834969</td>\n",
       "<td>0.4770477</td>\n",
       "<td>0.4809228</td></tr>\n",
       "<tr><td>F2</td>\n",
       "<td>0.4159570</td>\n",
       "<td>0.0141607</td>\n",
       "<td>0.4294852</td>\n",
       "<td>0.4053668</td>\n",
       "<td>0.4016821</td>\n",
       "<td>0.3916372</td>\n",
       "<td>0.4236770</td>\n",
       "<td>0.4309834</td>\n",
       "<td>0.4623568</td>\n",
       "<td>0.3963147</td>\n",
       "<td>0.4088244</td>\n",
       "<td>0.4092419</td></tr>\n",
       "<tr><td>accuracy</td>\n",
       "<td>0.9937451</td>\n",
       "<td>0.0001988</td>\n",
       "<td>0.9939905</td>\n",
       "<td>0.9930501</td>\n",
       "<td>0.9936373</td>\n",
       "<td>0.9936208</td>\n",
       "<td>0.9940887</td>\n",
       "<td>0.9938572</td>\n",
       "<td>0.993562</td>\n",
       "<td>0.9938953</td>\n",
       "<td>0.9938734</td>\n",
       "<td>0.9938762</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.9402362</td>\n",
       "<td>0.0025008</td>\n",
       "<td>0.9392077</td>\n",
       "<td>0.9394108</td>\n",
       "<td>0.9447169</td>\n",
       "<td>0.9384804</td>\n",
       "<td>0.9388769</td>\n",
       "<td>0.9386054</td>\n",
       "<td>0.9467832</td>\n",
       "<td>0.9351624</td>\n",
       "<td>0.936894</td>\n",
       "<td>0.9442239</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.0062549</td>\n",
       "<td>0.0001988</td>\n",
       "<td>0.0060095</td>\n",
       "<td>0.0069499</td>\n",
       "<td>0.0063627</td>\n",
       "<td>0.0063792</td>\n",
       "<td>0.0059113</td>\n",
       "<td>0.0061428</td>\n",
       "<td>0.0064380</td>\n",
       "<td>0.0061047</td>\n",
       "<td>0.0061266</td>\n",
       "<td>0.0061239</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>595.2</td>\n",
       "<td>18.73179</td>\n",
       "<td>574.0</td>\n",
       "<td>658.0</td>\n",
       "<td>605.0</td>\n",
       "<td>611.0</td>\n",
       "<td>561.0</td>\n",
       "<td>583.0</td>\n",
       "<td>615.0</td>\n",
       "<td>579.0</td>\n",
       "<td>581.0</td>\n",
       "<td>585.0</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>48.71211</td>\n",
       "<td>1.0397636</td>\n",
       "<td>49.326733</td>\n",
       "<td>47.683254</td>\n",
       "<td>47.829937</td>\n",
       "<td>47.260437</td>\n",
       "<td>49.114147</td>\n",
       "<td>51.103786</td>\n",
       "<td>51.54035</td>\n",
       "<td>47.492043</td>\n",
       "<td>48.41599</td>\n",
       "<td>47.35442</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>0.0264798</td>\n",
       "<td>0.0004478</td>\n",
       "<td>0.0260009</td>\n",
       "<td>0.0272829</td>\n",
       "<td>0.0269557</td>\n",
       "<td>0.0271711</td>\n",
       "<td>0.0258655</td>\n",
       "<td>0.0257614</td>\n",
       "<td>0.0265415</td>\n",
       "<td>0.0274119</td>\n",
       "<td>0.0258692</td>\n",
       "<td>0.0259381</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.6205695</td>\n",
       "<td>0.0151620</td>\n",
       "<td>0.6055944</td>\n",
       "<td>0.6258234</td>\n",
       "<td>0.6369594</td>\n",
       "<td>0.6458056</td>\n",
       "<td>0.6142061</td>\n",
       "<td>0.6051561</td>\n",
       "<td>0.5714286</td>\n",
       "<td>0.6462141</td>\n",
       "<td>0.6267605</td>\n",
       "<td>0.6277472</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.5050454</td>\n",
       "<td>0.0117257</td>\n",
       "<td>0.5100552</td>\n",
       "<td>0.4738027</td>\n",
       "<td>0.5012043</td>\n",
       "<td>0.4874960</td>\n",
       "<td>0.5162343</td>\n",
       "<td>0.5153745</td>\n",
       "<td>0.5349967</td>\n",
       "<td>0.5172455</td>\n",
       "<td>0.4939105</td>\n",
       "<td>0.5001344</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.0054298</td>\n",
       "<td>0.0001331</td>\n",
       "<td>0.0051905</td>\n",
       "<td>0.0057057</td>\n",
       "<td>0.0056135</td>\n",
       "<td>0.0055803</td>\n",
       "<td>0.0051812</td>\n",
       "<td>0.0053181</td>\n",
       "<td>0.0054698</td>\n",
       "<td>0.0056419</td>\n",
       "<td>0.0052302</td>\n",
       "<td>0.0053666</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.6809235</td>\n",
       "<td>0.0258572</td>\n",
       "<td>0.6666667</td>\n",
       "<td>0.6081371</td>\n",
       "<td>0.6994950</td>\n",
       "<td>0.6785714</td>\n",
       "<td>0.697733</td>\n",
       "<td>0.6799065</td>\n",
       "<td>0.6752988</td>\n",
       "<td>0.7633803</td>\n",
       "<td>0.6608479</td>\n",
       "<td>0.6791980</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.2997332</td>\n",
       "<td>0.0102574</td>\n",
       "<td>0.3013858</td>\n",
       "<td>0.2825113</td>\n",
       "<td>0.2947933</td>\n",
       "<td>0.2826839</td>\n",
       "<td>0.3099476</td>\n",
       "<td>0.3097997</td>\n",
       "<td>0.3339135</td>\n",
       "<td>0.2957462</td>\n",
       "<td>0.2961570</td>\n",
       "<td>0.2903939</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.3794304</td>\n",
       "<td>0.0151620</td>\n",
       "<td>0.3944056</td>\n",
       "<td>0.3741766</td>\n",
       "<td>0.3630406</td>\n",
       "<td>0.3541944</td>\n",
       "<td>0.3857939</td>\n",
       "<td>0.3948440</td>\n",
       "<td>0.4285714</td>\n",
       "<td>0.3537859</td>\n",
       "<td>0.3732394</td>\n",
       "<td>0.3722527</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.9985839</td>\n",
       "<td>0.0001889</td>\n",
       "<td>0.9985127</td>\n",
       "<td>0.9980515</td>\n",
       "<td>0.9987383</td>\n",
       "<td>0.9986741</td>\n",
       "<td>0.9987259</td>\n",
       "<td>0.9985452</td>\n",
       "<td>0.9982794</td>\n",
       "<td>0.9991071</td>\n",
       "<td>0.9985551</td>\n",
       "<td>0.9986498</td></tr></table></div>"
      ],
      "text/plain": [
       "                     mean        sd           cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid    cv_6_valid    cv_7_valid    cv_8_valid    cv_9_valid    cv_10_valid\n",
       "-------------------  ----------  -----------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  -------------\n",
       "F0point5             0.586577    0.0145475    0.585791      0.54054       0.590115      0.573523      0.600607      0.59412       0.605573      0.619854      0.572602      0.583047\n",
       "F1                   0.48646     0.0122031    0.495606      0.463295      0.477998      0.465442      0.496861      0.499571      0.524362      0.483497      0.477048      0.480923\n",
       "F2                   0.415957    0.0141607    0.429485      0.405367      0.401682      0.391637      0.423677      0.430983      0.462357      0.396315      0.408824      0.409242\n",
       "accuracy             0.993745    0.000198825  0.99399       0.99305       0.993637      0.993621      0.994089      0.993857      0.993562      0.993895      0.993873      0.993876\n",
       "auc                  0.940236    0.00250084   0.939208      0.939411      0.944717      0.93848       0.938877      0.938605      0.946783      0.935162      0.936894      0.944224\n",
       "err                  0.00625486  0.000198825  0.00600953    0.00694987    0.00636273    0.0063792     0.0059113     0.00614279    0.00643804    0.0061047     0.00612662    0.00612386\n",
       "err_count            595.2       18.7318      574           658           605           611           561           583           615           579           581           585\n",
       "lift_top_group       48.7121     1.03976      49.3267       47.6833       47.8299       47.2604       49.1141       51.1038       51.5403       47.492        48.416        47.3544\n",
       "logloss              0.0264798   0.000447837  0.0260009     0.0272829     0.0269557     0.0271711     0.0258655     0.0257614     0.0265415     0.0274119     0.0258692     0.0259381\n",
       "max_per_class_error  0.620569    0.015162     0.605594      0.625823      0.636959      0.645806      0.614206      0.605156      0.571429      0.646214      0.626761      0.627747\n",
       "mcc                  0.505045    0.0117257    0.510055      0.473803      0.501204      0.487496      0.516234      0.515374      0.534997      0.517246      0.49391       0.500134\n",
       "mse                  0.00542976  0.000133137  0.00519049    0.00570574    0.00561345    0.00558029    0.00518118    0.00531807    0.00546984    0.00564185    0.00523017    0.00536656\n",
       "precision            0.680923    0.0258572    0.666667      0.608137      0.699495      0.678571      0.697733      0.679907      0.675299      0.76338       0.660848      0.679198\n",
       "r2                   0.299733    0.0102574    0.301386      0.282511      0.294793      0.282684      0.309948      0.3098        0.333913      0.295746      0.296157      0.290394\n",
       "recall               0.37943     0.015162     0.394406      0.374177      0.363041      0.354194      0.385794      0.394844      0.428571      0.353786      0.373239      0.372253\n",
       "specificity          0.998584    0.000188922  0.998513      0.998051      0.998738      0.998674      0.998726      0.998545      0.998279      0.999107      0.998555      0.99865"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>training_MSE</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_AUC</b></td>\n",
       "<td><b>training_lift</b></td>\n",
       "<td><b>training_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-05-09 14:35:18</td>\n",
       "<td> 1 min 26.344 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-05-09 14:35:19</td>\n",
       "<td> 1 min 27.461 sec</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0081169</td>\n",
       "<td>0.1769458</td>\n",
       "<td>0.7409081</td>\n",
       "<td>54.4435071</td>\n",
       "<td>0.0080563</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-05-09 14:35:21</td>\n",
       "<td> 1 min 28.615 sec</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0076844</td>\n",
       "<td>0.1449407</td>\n",
       "<td>0.7625157</td>\n",
       "<td>65.9703528</td>\n",
       "<td>0.0077581</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-05-09 14:35:22</td>\n",
       "<td> 1 min 29.914 sec</td>\n",
       "<td>3.0</td>\n",
       "<td>0.0073989</td>\n",
       "<td>0.1256042</td>\n",
       "<td>0.7898958</td>\n",
       "<td>72.1833826</td>\n",
       "<td>0.0088188</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-05-09 14:35:26</td>\n",
       "<td> 1 min 34.011 sec</td>\n",
       "<td>10.0</td>\n",
       "<td>0.0060509</td>\n",
       "<td>0.0452898</td>\n",
       "<td>0.8896355</td>\n",
       "<td>84.4312987</td>\n",
       "<td>0.0069774</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration          number_of_trees    training_MSE    training_logloss    training_AUC    training_lift    training_classification_error\n",
       "--  -------------------  ----------------  -----------------  --------------  ------------------  --------------  ---------------  -------------------------------\n",
       "    2016-05-09 14:35:18  1 min 26.344 sec  0                  nan             nan                 nan             nan              nan\n",
       "    2016-05-09 14:35:19  1 min 27.461 sec  1                  0.00811688      0.176946            0.740908        54.4435          0.00805627\n",
       "    2016-05-09 14:35:21  1 min 28.615 sec  2                  0.00768442      0.144941            0.762516        65.9704          0.00775808\n",
       "    2016-05-09 14:35:22  1 min 29.914 sec  3                  0.00739894      0.125604            0.789896        72.1834          0.00881878\n",
       "    2016-05-09 14:35:26  1 min 34.011 sec  10                 0.00605094      0.0452898           0.889636        84.4313          0.00697739"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>HHSEARCH_PROFILE_PROFILE_ALIGNMENT_SCORE</td>\n",
       "<td>2087.1127930</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0688841</td></tr>\n",
       "<tr><td>HMMER_PRCHMMM_SIMPLE_SCORE</td>\n",
       "<td>1833.0692139</td>\n",
       "<td>0.8782799</td>\n",
       "<td>0.0604995</td></tr>\n",
       "<tr><td>COMPASS_EVALUE</td>\n",
       "<td>1810.7846680</td>\n",
       "<td>0.8676027</td>\n",
       "<td>0.0597640</td></tr>\n",
       "<tr><td>HMMER_PRCHMMM_REVERSE_SCORE</td>\n",
       "<td>1654.1962891</td>\n",
       "<td>0.7925764</td>\n",
       "<td>0.0545959</td></tr>\n",
       "<tr><td>PFAM_ALIGNMENT_EVALUE</td>\n",
       "<td>1341.0898438</td>\n",
       "<td>0.6425574</td>\n",
       "<td>0.0442620</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>PSIBLAST_PROFILE_SEQ_ALIGNMENT_SCORE</td>\n",
       "<td>160.4424896</td>\n",
       "<td>0.0768729</td>\n",
       "<td>0.0052953</td></tr>\n",
       "<tr><td>PSIBLAST_IDENTITY_RATE_ALIGNMENT</td>\n",
       "<td>151.0586548</td>\n",
       "<td>0.0723769</td>\n",
       "<td>0.0049856</td></tr>\n",
       "<tr><td>RPSBLAST_SEQ_PROFILE_ALIGNMENT_SCORE</td>\n",
       "<td>145.6327667</td>\n",
       "<td>0.0697771</td>\n",
       "<td>0.0048065</td></tr>\n",
       "<tr><td>RPSBLAST_ALIGNMENT_POSITIVE_RATE</td>\n",
       "<td>141.6556396</td>\n",
       "<td>0.0678716</td>\n",
       "<td>0.0046753</td></tr>\n",
       "<tr><td>CHK_PRCHMMM_COEMIS_SCORE</td>\n",
       "<td>130.8580322</td>\n",
       "<td>0.0626981</td>\n",
       "<td>0.0043189</td></tr></table></div>"
      ],
      "text/plain": [
       "variable                                  relative_importance    scaled_importance    percentage\n",
       "----------------------------------------  ---------------------  -------------------  ----------------\n",
       "HHSEARCH_PROFILE_PROFILE_ALIGNMENT_SCORE  2087.11279297          1.0                  0.068884071643\n",
       "HMMER_PRCHMMM_SIMPLE_SCORE                1833.06921387          0.878279899411       0.0604994955136\n",
       "COMPASS_EVALUE                            1810.78466797          0.867602687344       0.0597640056726\n",
       "HMMER_PRCHMMM_REVERSE_SCORE               1654.19628906          0.792576373752       0.054595887712\n",
       "PFAM_ALIGNMENT_EVALUE                     1341.08984375          0.642557435452       0.0442619724184\n",
       "---                                       ---                    ---                  ---\n",
       "PSIBLAST_PROFILE_SEQ_ALIGNMENT_SCORE      160.442489624          0.0768729367021      0.00529532087919\n",
       "PSIBLAST_IDENTITY_RATE_ALIGNMENT          151.058654785          0.0723768525084      0.00498561229348\n",
       "RPSBLAST_SEQ_PROFILE_ALIGNMENT_SCORE      145.632766724          0.0697771424785      0.00480653368153\n",
       "RPSBLAST_ALIGNMENT_POSITIVE_RATE          141.655639648          0.0678715784435      0.00467527067202\n",
       "CHK_PRCHMMM_COEMIS_SCORE                  130.858032227          0.0626981122762      0.00431890125791"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a DeepLearningEstimator & Saving cross-validation predictions to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "deeplearning Model Build Progress: [##################################################] 100%\n"
     ]
    }
   ],
   "source": [
    "dl_classifier = H2ODeepLearningEstimator(activation = \"Tanh\", \n",
    "                                         hidden = [150, 150], \n",
    "                                         epochs = 20,\n",
    "                                         nfolds = 10,\n",
    "                                         keep_cross_validation_predictions = True)\n",
    "\n",
    "dl_classifier.train(x=range(1,foldpro_df.ncol), \n",
    "                         y=0, \n",
    "                         training_frame= foldpro_df ,\n",
    "                         seed = 1234 )\n",
    "\n",
    "cv_pred_dl = dl_classifier.cross_validation_holdout_predictions()\n",
    "cv_pred_dl_df = cv_pred_dl.as_data_frame(use_pandas=True)\n",
    "outDf4 = pd.DataFrame( zip (IdText.PairId , cv_pred_dl_df.YES ) , columns = [\"PairId\",\"Probability\"])\n",
    "outDf4.to_csv(\"dl_prediction.csv\" , \n",
    "              sep = \" \" , \n",
    "              header = False , \n",
    "              index = False , \n",
    "              quoting= csv.QUOTE_NONE , \n",
    "              quotechar='',\n",
    "              escapechar=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2ODeepLearningEstimator :  Deep Learning\n",
      "Model Key:  DeepLearning_model_python_1462800685859_9761\n",
      "\n",
      "Status of Neuron Layers: predicting LABEL, 2-class classification, bernoulli distribution, CrossEntropy loss, 35,702 weights/biases, 443.8 KB, 1,599,884 training samples, mini-batch size 1\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>layer</b></td>\n",
       "<td><b>units</b></td>\n",
       "<td><b>type</b></td>\n",
       "<td><b>dropout</b></td>\n",
       "<td><b>l1</b></td>\n",
       "<td><b>l2</b></td>\n",
       "<td><b>mean_rate</b></td>\n",
       "<td><b>rate_RMS</b></td>\n",
       "<td><b>momentum</b></td>\n",
       "<td><b>mean_weight</b></td>\n",
       "<td><b>weight_RMS</b></td>\n",
       "<td><b>mean_bias</b></td>\n",
       "<td><b>bias_RMS</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>84</td>\n",
       "<td>Input</td>\n",
       "<td>0.0</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>150</td>\n",
       "<td>Tanh</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.2445311</td>\n",
       "<td>0.2353449</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0005960</td>\n",
       "<td>0.1155204</td>\n",
       "<td>0.0268856</td>\n",
       "<td>0.4435843</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>150</td>\n",
       "<td>Tanh</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.3135319</td>\n",
       "<td>0.2396311</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0012912</td>\n",
       "<td>0.1163543</td>\n",
       "<td>-0.0009453</td>\n",
       "<td>0.2404694</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>2</td>\n",
       "<td>Softmax</td>\n",
       "<td></td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0028194</td>\n",
       "<td>0.0014500</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0113643</td>\n",
       "<td>0.3644748</td>\n",
       "<td>0.0132739</td>\n",
       "<td>1.3574300</td></tr></table></div>"
      ],
      "text/plain": [
       "    layer    units    type     dropout    l1    l2    mean_rate         rate_RMS          momentum    mean_weight         weight_RMS      mean_bias           bias_RMS\n",
       "--  -------  -------  -------  ---------  ----  ----  ----------------  ----------------  ----------  ------------------  --------------  ------------------  --------------\n",
       "    1        84       Input    0.0\n",
       "    2        150      Tanh     0.0        0.0   0.0   0.244531084514    0.235344946384    0.0         -0.000596037632376  0.115520447493  0.0268855848699     0.443584322929\n",
       "    3        150      Tanh     0.0        0.0   0.0   0.313531937563    0.23963111639     0.0         0.00129121584964    0.116354286671  -0.000945330118388  0.240469396114\n",
       "    4        2        Softmax             0.0   0.0   0.00281940288531  0.00145002268255  0.0         -0.0113642720125    0.364474773407  0.0132738536358     1.35742998123"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: deeplearning\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.00663297473438\n",
      "R^2: 0.176965465821\n",
      "LogLoss: 0.0405167610189\n",
      "AUC: 0.923772798554\n",
      "Gini: 0.847545597107\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.028016563511: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>NO</b></td>\n",
       "<td><b>YES</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>NO</td>\n",
       "<td>9879.0</td>\n",
       "<td>9.0</td>\n",
       "<td>0.0009</td>\n",
       "<td> (9.0/9888.0)</td></tr>\n",
       "<tr><td>YES</td>\n",
       "<td>63.0</td>\n",
       "<td>18.0</td>\n",
       "<td>0.7778</td>\n",
       "<td> (63.0/81.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>9942.0</td>\n",
       "<td>27.0</td>\n",
       "<td>0.0072</td>\n",
       "<td> (72.0/9969.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       NO    YES    Error    Rate\n",
       "-----  ----  -----  -------  -------------\n",
       "NO     9879  9      0.0009   (9.0/9888.0)\n",
       "YES    63    18     0.7778   (63.0/81.0)\n",
       "Total  9942  27     0.0072   (72.0/9969.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.0280166</td>\n",
       "<td>0.3333333</td>\n",
       "<td>16.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.0036594</td>\n",
       "<td>0.3646677</td>\n",
       "<td>160.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.1594616</td>\n",
       "<td>0.5172414</td>\n",
       "<td>5.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.9641654</td>\n",
       "<td>0.9932792</td>\n",
       "<td>3.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999971</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0000771</td>\n",
       "<td>1.0</td>\n",
       "<td>388.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999971</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_MCC</td>\n",
       "<td>0.1594616</td>\n",
       "<td>0.4150771</td>\n",
       "<td>5.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.0008115</td>\n",
       "<td>0.8440534</td>\n",
       "<td>289.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                      threshold    value     idx\n",
       "--------------------------  -----------  --------  -----\n",
       "max f1                      0.0280166    0.333333  16\n",
       "max f2                      0.00365937   0.364668  160\n",
       "max f0point5                0.159462     0.517241  5\n",
       "max accuracy                0.964165     0.993279  3\n",
       "max precision               0.999997     1         0\n",
       "max recall                  7.71149e-05  1         388\n",
       "max specificity             0.999997     1         0\n",
       "max absolute_MCC            0.159462     0.415077  5\n",
       "max min_per_class_accuracy  0.000811456  0.844053  289"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate:  0.81 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0100311</td>\n",
       "<td>0.0083072</td>\n",
       "<td>31.9992593</td>\n",
       "<td>31.9992593</td>\n",
       "<td>0.26</td>\n",
       "<td>0.26</td>\n",
       "<td>0.3209877</td>\n",
       "<td>0.3209877</td>\n",
       "<td>3099.9259259</td>\n",
       "<td>3099.9259259</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200622</td>\n",
       "<td>0.0049246</td>\n",
       "<td>9.8459259</td>\n",
       "<td>20.9225926</td>\n",
       "<td>0.08</td>\n",
       "<td>0.17</td>\n",
       "<td>0.0987654</td>\n",
       "<td>0.4197531</td>\n",
       "<td>884.5925926</td>\n",
       "<td>1992.2592593</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0300933</td>\n",
       "<td>0.0035886</td>\n",
       "<td>13.5381481</td>\n",
       "<td>18.4611111</td>\n",
       "<td>0.11</td>\n",
       "<td>0.15</td>\n",
       "<td>0.1358025</td>\n",
       "<td>0.5555556</td>\n",
       "<td>1253.8148148</td>\n",
       "<td>1746.1111111</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400241</td>\n",
       "<td>0.0029170</td>\n",
       "<td>3.7295174</td>\n",
       "<td>14.8059036</td>\n",
       "<td>0.0303030</td>\n",
       "<td>0.1203008</td>\n",
       "<td>0.0370370</td>\n",
       "<td>0.5925926</td>\n",
       "<td>272.9517396</td>\n",
       "<td>1380.5903648</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0500552</td>\n",
       "<td>0.0024416</td>\n",
       "<td>3.6922222</td>\n",
       "<td>12.5787130</td>\n",
       "<td>0.03</td>\n",
       "<td>0.1022044</td>\n",
       "<td>0.0370370</td>\n",
       "<td>0.6296296</td>\n",
       "<td>269.2222222</td>\n",
       "<td>1157.8712982</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000100</td>\n",
       "<td>0.0013297</td>\n",
       "<td>1.4828202</td>\n",
       "<td>7.0363312</td>\n",
       "<td>0.0120482</td>\n",
       "<td>0.0571715</td>\n",
       "<td>0.0740741</td>\n",
       "<td>0.7037037</td>\n",
       "<td>48.2820170</td>\n",
       "<td>603.6331216</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1500652</td>\n",
       "<td>0.0008783</td>\n",
       "<td>2.2197729</td>\n",
       "<td>5.4297386</td>\n",
       "<td>0.0180361</td>\n",
       "<td>0.0441176</td>\n",
       "<td>0.1111111</td>\n",
       "<td>0.8148148</td>\n",
       "<td>121.9772879</td>\n",
       "<td>442.9738562</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2000201</td>\n",
       "<td>0.0006317</td>\n",
       "<td>1.7299569</td>\n",
       "<td>4.5057209</td>\n",
       "<td>0.0140562</td>\n",
       "<td>0.0366098</td>\n",
       "<td>0.0864198</td>\n",
       "<td>0.9012346</td>\n",
       "<td>72.9956864</td>\n",
       "<td>350.5720866</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3000301</td>\n",
       "<td>0.0003646</td>\n",
       "<td>0.4937776</td>\n",
       "<td>3.1684065</td>\n",
       "<td>0.0040120</td>\n",
       "<td>0.0257439</td>\n",
       "<td>0.0493827</td>\n",
       "<td>0.9506173</td>\n",
       "<td>-50.6222371</td>\n",
       "<td>216.8406454</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4000401</td>\n",
       "<td>0.0002410</td>\n",
       "<td>0.2468888</td>\n",
       "<td>2.4380270</td>\n",
       "<td>0.0020060</td>\n",
       "<td>0.0198094</td>\n",
       "<td>0.0246914</td>\n",
       "<td>0.9753086</td>\n",
       "<td>-75.3111185</td>\n",
       "<td>143.8027044</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5000502</td>\n",
       "<td>0.0001747</td>\n",
       "<td>0.1234444</td>\n",
       "<td>1.9751105</td>\n",
       "<td>0.0010030</td>\n",
       "<td>0.0160481</td>\n",
       "<td>0.0123457</td>\n",
       "<td>0.9876543</td>\n",
       "<td>-87.6555593</td>\n",
       "<td>97.5110517</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.5999599</td>\n",
       "<td>0.0001344</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6462006</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0133757</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9876543</td>\n",
       "<td>-100.0</td>\n",
       "<td>64.6200623</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.6999699</td>\n",
       "<td>0.0001053</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4109954</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0114646</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9876543</td>\n",
       "<td>-100.0</td>\n",
       "<td>41.0995404</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7999799</td>\n",
       "<td>0.0000844</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2345989</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0100313</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9876543</td>\n",
       "<td>-100.0</td>\n",
       "<td>23.4598862</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8999900</td>\n",
       "<td>0.0000657</td>\n",
       "<td>0.1234444</td>\n",
       "<td>1.1111235</td>\n",
       "<td>0.0010030</td>\n",
       "<td>0.0090281</td>\n",
       "<td>0.0123457</td>\n",
       "<td>1.0</td>\n",
       "<td>-87.6555593</td>\n",
       "<td>11.1123495</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000345</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0081252</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  --------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0100311                   0.00830718         31.9993   31.9993            0.26             0.26                        0.320988        0.320988                   3099.93   3099.93\n",
       "    2        0.0200622                   0.00492465         9.84593   20.9226            0.08             0.17                        0.0987654       0.419753                   884.593   1992.26\n",
       "    3        0.0300933                   0.00358858         13.5381   18.4611            0.11             0.15                        0.135802        0.555556                   1253.81   1746.11\n",
       "    4        0.0400241                   0.00291702         3.72952   14.8059            0.030303         0.120301                    0.037037        0.592593                   272.952   1380.59\n",
       "    5        0.0500552                   0.00244159         3.69222   12.5787            0.03             0.102204                    0.037037        0.62963                    269.222   1157.87\n",
       "    6        0.10001                     0.00132966         1.48282   7.03633            0.0120482        0.0571715                   0.0740741       0.703704                   48.282    603.633\n",
       "    7        0.150065                    0.000878271        2.21977   5.42974            0.0180361        0.0441176                   0.111111        0.814815                   121.977   442.974\n",
       "    8        0.20002                     0.000631747        1.72996   4.50572            0.0140562        0.0366098                   0.0864198       0.901235                   72.9957   350.572\n",
       "    9        0.30003                     0.000364626        0.493778  3.16841            0.00401204       0.0257439                   0.0493827       0.950617                   -50.6222  216.841\n",
       "    10       0.40004                     0.000240961        0.246889  2.43803            0.00200602       0.0198094                   0.0246914       0.975309                   -75.3111  143.803\n",
       "    11       0.50005                     0.000174693        0.123444  1.97511            0.00100301       0.0160481                   0.0123457       0.987654                   -87.6556  97.5111\n",
       "    12       0.59996                     0.000134362        0         1.6462             0                0.0133757                   0               0.987654                   -100      64.6201\n",
       "    13       0.69997                     0.000105251        0         1.411              0                0.0114646                   0               0.987654                   -100      41.0995\n",
       "    14       0.79998                     8.43668e-05        0         1.2346             0                0.0100313                   0               0.987654                   -100      23.4599\n",
       "    15       0.89999                     6.5743e-05         0.123444  1.11112            0.00100301       0.00902809                  0.0123457       1                          -87.6556  11.1123\n",
       "    16       1                           3.45386e-05        0         1                  0                0.00812519                  0               1                          -100      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: deeplearning\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.00604724321853\n",
      "R^2: 0.22023522663\n",
      "LogLoss: 0.0317514514349\n",
      "AUC: 0.895328075091\n",
      "Gini: 0.790656150182\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.177368462761: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>NO</b></td>\n",
       "<td><b>YES</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>NO</td>\n",
       "<td>942865.0</td>\n",
       "<td>1297.0</td>\n",
       "<td>0.0014</td>\n",
       "<td> (1297.0/944162.0)</td></tr>\n",
       "<tr><td>YES</td>\n",
       "<td>5474.0</td>\n",
       "<td>1964.0</td>\n",
       "<td>0.736</td>\n",
       "<td> (5474.0/7438.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>948339.0</td>\n",
       "<td>3261.0</td>\n",
       "<td>0.0071</td>\n",
       "<td> (6771.0/951600.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       NO      YES    Error    Rate\n",
       "-----  ------  -----  -------  -----------------\n",
       "NO     942865  1297   0.0014   (1297.0/944162.0)\n",
       "YES    5474    1964   0.736    (5474.0/7438.0)\n",
       "Total  948339  3261   0.0071   (6771.0/951600.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.1773685</td>\n",
       "<td>0.3671371</td>\n",
       "<td>172.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.0522277</td>\n",
       "<td>0.3350254</td>\n",
       "<td>252.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.5604746</td>\n",
       "<td>0.5376419</td>\n",
       "<td>81.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.6083109</td>\n",
       "<td>0.9936150</td>\n",
       "<td>74.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9998769</td>\n",
       "<td>0.9987030</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0000530</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9998769</td>\n",
       "<td>0.9999989</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_MCC</td>\n",
       "<td>0.5604746</td>\n",
       "<td>0.4288253</td>\n",
       "<td>81.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.0032381</td>\n",
       "<td>0.8070416</td>\n",
       "<td>365.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                      threshold    value     idx\n",
       "--------------------------  -----------  --------  -----\n",
       "max f1                      0.177368     0.367137  172\n",
       "max f2                      0.0522277    0.335025  252\n",
       "max f0point5                0.560475     0.537642  81\n",
       "max accuracy                0.608311     0.993615  74\n",
       "max precision               0.999877     0.998703  0\n",
       "max recall                  5.3018e-05   1         399\n",
       "max specificity             0.999877     0.999999  0\n",
       "max absolute_MCC            0.560475     0.428825  81\n",
       "max min_per_class_accuracy  0.00323812   0.807042  365"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate:  0.78 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.01</td>\n",
       "<td>0.0572326</td>\n",
       "<td>35.2648561</td>\n",
       "<td>35.2648561</td>\n",
       "<td>0.2756410</td>\n",
       "<td>0.2756410</td>\n",
       "<td>0.3526486</td>\n",
       "<td>0.3526486</td>\n",
       "<td>3426.4856144</td>\n",
       "<td>3426.4856144</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.02</td>\n",
       "<td>0.0316894</td>\n",
       "<td>7.2465717</td>\n",
       "<td>21.2557139</td>\n",
       "<td>0.0566414</td>\n",
       "<td>0.1661412</td>\n",
       "<td>0.0724657</td>\n",
       "<td>0.4251143</td>\n",
       "<td>624.6571659</td>\n",
       "<td>2025.5713902</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.03</td>\n",
       "<td>0.0224310</td>\n",
       "<td>5.3643453</td>\n",
       "<td>15.9585910</td>\n",
       "<td>0.0419294</td>\n",
       "<td>0.1247373</td>\n",
       "<td>0.0536435</td>\n",
       "<td>0.4787577</td>\n",
       "<td>436.4345254</td>\n",
       "<td>1495.8591019</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.04</td>\n",
       "<td>0.0174400</td>\n",
       "<td>4.0602312</td>\n",
       "<td>12.9840011</td>\n",
       "<td>0.0317360</td>\n",
       "<td>0.1014870</td>\n",
       "<td>0.0406023</td>\n",
       "<td>0.5193600</td>\n",
       "<td>306.0231245</td>\n",
       "<td>1198.4001076</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.05</td>\n",
       "<td>0.0142044</td>\n",
       "<td>3.5896746</td>\n",
       "<td>11.1051358</td>\n",
       "<td>0.0280580</td>\n",
       "<td>0.0868012</td>\n",
       "<td>0.0358967</td>\n",
       "<td>0.5552568</td>\n",
       "<td>258.9674644</td>\n",
       "<td>1010.5135789</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1</td>\n",
       "<td>0.0071005</td>\n",
       "<td>2.4226943</td>\n",
       "<td>6.7639150</td>\n",
       "<td>0.0189365</td>\n",
       "<td>0.0528689</td>\n",
       "<td>0.1211347</td>\n",
       "<td>0.6763915</td>\n",
       "<td>142.2694273</td>\n",
       "<td>576.3915031</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.15</td>\n",
       "<td>0.0044799</td>\n",
       "<td>1.6267814</td>\n",
       "<td>5.0515372</td>\n",
       "<td>0.0127154</td>\n",
       "<td>0.0394844</td>\n",
       "<td>0.0813391</td>\n",
       "<td>0.7577306</td>\n",
       "<td>62.6781393</td>\n",
       "<td>405.1537152</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2</td>\n",
       "<td>0.0031061</td>\n",
       "<td>1.1508470</td>\n",
       "<td>4.0763646</td>\n",
       "<td>0.0089954</td>\n",
       "<td>0.0318621</td>\n",
       "<td>0.0575424</td>\n",
       "<td>0.8152729</td>\n",
       "<td>15.0847002</td>\n",
       "<td>307.6364614</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3</td>\n",
       "<td>0.0017576</td>\n",
       "<td>0.7407905</td>\n",
       "<td>2.9645066</td>\n",
       "<td>0.0057902</td>\n",
       "<td>0.0231715</td>\n",
       "<td>0.0740791</td>\n",
       "<td>0.8893520</td>\n",
       "<td>-25.9209465</td>\n",
       "<td>196.4506588</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4</td>\n",
       "<td>0.0011139</td>\n",
       "<td>0.4463565</td>\n",
       "<td>2.3349691</td>\n",
       "<td>0.0034889</td>\n",
       "<td>0.0182508</td>\n",
       "<td>0.0446357</td>\n",
       "<td>0.9339876</td>\n",
       "<td>-55.3643453</td>\n",
       "<td>133.4969078</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0007592</td>\n",
       "<td>0.2446894</td>\n",
       "<td>1.9169131</td>\n",
       "<td>0.0019126</td>\n",
       "<td>0.0149832</td>\n",
       "<td>0.0244689</td>\n",
       "<td>0.9584566</td>\n",
       "<td>-75.5310567</td>\n",
       "<td>91.6913149</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6</td>\n",
       "<td>0.0005370</td>\n",
       "<td>0.1667115</td>\n",
       "<td>1.6252129</td>\n",
       "<td>0.0013031</td>\n",
       "<td>0.0127032</td>\n",
       "<td>0.0166711</td>\n",
       "<td>0.9751277</td>\n",
       "<td>-83.3288518</td>\n",
       "<td>62.5212871</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7</td>\n",
       "<td>0.0003817</td>\n",
       "<td>0.0994891</td>\n",
       "<td>1.4072523</td>\n",
       "<td>0.0007776</td>\n",
       "<td>0.0109995</td>\n",
       "<td>0.0099489</td>\n",
       "<td>0.9850766</td>\n",
       "<td>-90.0510890</td>\n",
       "<td>40.7252334</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8</td>\n",
       "<td>0.0002644</td>\n",
       "<td>0.0685668</td>\n",
       "<td>1.2399166</td>\n",
       "<td>0.0005359</td>\n",
       "<td>0.0096916</td>\n",
       "<td>0.0068567</td>\n",
       "<td>0.9919333</td>\n",
       "<td>-93.1433181</td>\n",
       "<td>23.9916644</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.9</td>\n",
       "<td>0.0001545</td>\n",
       "<td>0.0389890</td>\n",
       "<td>1.1064802</td>\n",
       "<td>0.0003047</td>\n",
       "<td>0.0086486</td>\n",
       "<td>0.0038989</td>\n",
       "<td>0.9958322</td>\n",
       "<td>-96.1011024</td>\n",
       "<td>10.6480237</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000010</td>\n",
       "<td>0.0416779</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0003258</td>\n",
       "<td>0.0078163</td>\n",
       "<td>0.0041678</td>\n",
       "<td>1.0</td>\n",
       "<td>-95.8322130</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.01                        0.0572326          35.2649    35.2649            0.275641         0.275641                    0.352649        0.352649                   3426.49   3426.49\n",
       "    2        0.02                        0.0316894          7.24657    21.2557            0.0566414        0.166141                    0.0724657       0.425114                   624.657   2025.57\n",
       "    3        0.03                        0.022431           5.36435    15.9586            0.0419294        0.124737                    0.0536435       0.478758                   436.435   1495.86\n",
       "    4        0.04                        0.01744            4.06023    12.984             0.031736         0.101487                    0.0406023       0.51936                    306.023   1198.4\n",
       "    5        0.05                        0.0142044          3.58967    11.1051            0.028058         0.0868012                   0.0358967       0.555257                   258.967   1010.51\n",
       "    6        0.1                         0.00710047         2.42269    6.76392            0.0189365        0.0528689                   0.121135        0.676392                   142.269   576.392\n",
       "    7        0.15                        0.00447993         1.62678    5.05154            0.0127154        0.0394844                   0.0813391       0.757731                   62.6781   405.154\n",
       "    8        0.2                         0.00310612         1.15085    4.07636            0.00899538       0.0318621                   0.0575424       0.815273                   15.0847   307.636\n",
       "    9        0.3                         0.00175762         0.740791   2.96451            0.00579025       0.0231715                   0.0740791       0.889352                   -25.9209  196.451\n",
       "    10       0.4                         0.00111393         0.446357   2.33497            0.00348886       0.0182508                   0.0446357       0.933988                   -55.3643  133.497\n",
       "    11       0.5                         0.000759194        0.244689   1.91691            0.00191257       0.0149832                   0.0244689       0.958457                   -75.5311  91.6913\n",
       "    12       0.6                         0.000536991        0.166711   1.62521            0.00130307       0.0127032                   0.0166711       0.975128                   -83.3289  62.5213\n",
       "    13       0.7                         0.000381702        0.0994891  1.40725            0.000777638      0.0109995                   0.00994891      0.985077                   -90.0511  40.7252\n",
       "    14       0.8                         0.000264442        0.0685668  1.23992            0.000535939      0.00969157                  0.00685668      0.991933                   -93.1433  23.9917\n",
       "    15       0.9                         0.000154471        0.038989   1.10648            0.00030475       0.00864859                  0.0038989       0.995832                   -96.1011  10.648\n",
       "    16       1                           9.66071e-07        0.0416779  1                  0.000325767      0.00781631                  0.00416779      1                          -95.8322  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>mean</b></td>\n",
       "<td><b>sd</b></td>\n",
       "<td><b>cv_1_valid</b></td>\n",
       "<td><b>cv_2_valid</b></td>\n",
       "<td><b>cv_3_valid</b></td>\n",
       "<td><b>cv_4_valid</b></td>\n",
       "<td><b>cv_5_valid</b></td>\n",
       "<td><b>cv_6_valid</b></td>\n",
       "<td><b>cv_7_valid</b></td>\n",
       "<td><b>cv_8_valid</b></td>\n",
       "<td><b>cv_9_valid</b></td>\n",
       "<td><b>cv_10_valid</b></td></tr>\n",
       "<tr><td>F0point5</td>\n",
       "<td>0.4844156</td>\n",
       "<td>0.0476009</td>\n",
       "<td>0.4878049</td>\n",
       "<td>0.4954084</td>\n",
       "<td>0.3679047</td>\n",
       "<td>0.4896285</td>\n",
       "<td>0.3688960</td>\n",
       "<td>0.4777345</td>\n",
       "<td>0.5564924</td>\n",
       "<td>0.4816797</td>\n",
       "<td>0.5890888</td>\n",
       "<td>0.5295178</td></tr>\n",
       "<tr><td>F1</td>\n",
       "<td>0.3752425</td>\n",
       "<td>0.0275108</td>\n",
       "<td>0.3767313</td>\n",
       "<td>0.3810409</td>\n",
       "<td>0.3354633</td>\n",
       "<td>0.3888889</td>\n",
       "<td>0.2766169</td>\n",
       "<td>0.3807063</td>\n",
       "<td>0.3905325</td>\n",
       "<td>0.3952703</td>\n",
       "<td>0.4134420</td>\n",
       "<td>0.4137324</td></tr>\n",
       "<tr><td>F2</td>\n",
       "<td>0.3078893</td>\n",
       "<td>0.0220217</td>\n",
       "<td>0.3068592</td>\n",
       "<td>0.3095742</td>\n",
       "<td>0.3082795</td>\n",
       "<td>0.3225294</td>\n",
       "<td>0.2212671</td>\n",
       "<td>0.3164376</td>\n",
       "<td>0.3008204</td>\n",
       "<td>0.3351475</td>\n",
       "<td>0.3184813</td>\n",
       "<td>0.3394973</td></tr>\n",
       "<tr><td>accuracy</td>\n",
       "<td>0.9928203</td>\n",
       "<td>0.0004910</td>\n",
       "<td>0.9928908</td>\n",
       "<td>0.9929824</td>\n",
       "<td>0.9912636</td>\n",
       "<td>0.993292</td>\n",
       "<td>0.9924004</td>\n",
       "<td>0.9924853</td>\n",
       "<td>0.9934913</td>\n",
       "<td>0.992468</td>\n",
       "<td>0.9939398</td>\n",
       "<td>0.9929899</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.8996372</td>\n",
       "<td>0.0125736</td>\n",
       "<td>0.9090250</td>\n",
       "<td>0.8937151</td>\n",
       "<td>0.9040449</td>\n",
       "<td>0.9132952</td>\n",
       "<td>0.8591597</td>\n",
       "<td>0.8792023</td>\n",
       "<td>0.9134046</td>\n",
       "<td>0.8925735</td>\n",
       "<td>0.9146807</td>\n",
       "<td>0.9172714</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.0071797</td>\n",
       "<td>0.0004910</td>\n",
       "<td>0.0071092</td>\n",
       "<td>0.0070176</td>\n",
       "<td>0.0087364</td>\n",
       "<td>0.0067080</td>\n",
       "<td>0.0075997</td>\n",
       "<td>0.0075146</td>\n",
       "<td>0.0065087</td>\n",
       "<td>0.0075320</td>\n",
       "<td>0.0060602</td>\n",
       "<td>0.0070101</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>683.3</td>\n",
       "<td>47.36143</td>\n",
       "<td>675.0</td>\n",
       "<td>666.0</td>\n",
       "<td>832.0</td>\n",
       "<td>638.0</td>\n",
       "<td>727.0</td>\n",
       "<td>719.0</td>\n",
       "<td>618.0</td>\n",
       "<td>716.0</td>\n",
       "<td>576.0</td>\n",
       "<td>666.0</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>35.88915</td>\n",
       "<td>2.8850212</td>\n",
       "<td>37.060974</td>\n",
       "<td>36.070896</td>\n",
       "<td>34.794827</td>\n",
       "<td>39.905178</td>\n",
       "<td>24.568892</td>\n",
       "<td>36.67187</td>\n",
       "<td>35.15935</td>\n",
       "<td>38.085804</td>\n",
       "<td>37.257744</td>\n",
       "<td>39.31594</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>0.0317487</td>\n",
       "<td>0.0010352</td>\n",
       "<td>0.0330156</td>\n",
       "<td>0.0309114</td>\n",
       "<td>0.0308897</td>\n",
       "<td>0.0296697</td>\n",
       "<td>0.0335409</td>\n",
       "<td>0.0343992</td>\n",
       "<td>0.0303389</td>\n",
       "<td>0.0321333</td>\n",
       "<td>0.0304934</td>\n",
       "<td>0.0320950</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.7245445</td>\n",
       "<td>0.0210102</td>\n",
       "<td>0.7269076</td>\n",
       "<td>0.7248322</td>\n",
       "<td>0.7075209</td>\n",
       "<td>0.7104137</td>\n",
       "<td>0.8047753</td>\n",
       "<td>0.7155727</td>\n",
       "<td>0.7391304</td>\n",
       "<td>0.6957087</td>\n",
       "<td>0.7238095</td>\n",
       "<td>0.6967742</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.4036947</td>\n",
       "<td>0.0344781</td>\n",
       "<td>0.4042227</td>\n",
       "<td>0.4099132</td>\n",
       "<td>0.3348451</td>\n",
       "<td>0.4110915</td>\n",
       "<td>0.3011353</td>\n",
       "<td>0.4013177</td>\n",
       "<td>0.4478234</td>\n",
       "<td>0.4108342</td>\n",
       "<td>0.4744047</td>\n",
       "<td>0.4413591</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.0060470</td>\n",
       "<td>0.0001391</td>\n",
       "<td>0.0061561</td>\n",
       "<td>0.0059473</td>\n",
       "<td>0.0060034</td>\n",
       "<td>0.0056429</td>\n",
       "<td>0.0063044</td>\n",
       "<td>0.0062502</td>\n",
       "<td>0.0060125</td>\n",
       "<td>0.0061011</td>\n",
       "<td>0.0058170</td>\n",
       "<td>0.0062349</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.6074655</td>\n",
       "<td>0.0846520</td>\n",
       "<td>0.6071429</td>\n",
       "<td>0.6193353</td>\n",
       "<td>0.3932584</td>\n",
       "<td>0.5918368</td>\n",
       "<td>0.4744027</td>\n",
       "<td>0.5755208</td>\n",
       "<td>0.7764706</td>\n",
       "<td>0.5638554</td>\n",
       "<td>0.8218623</td>\n",
       "<td>0.6509695</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.2197492</td>\n",
       "<td>0.0196847</td>\n",
       "<td>0.2113261</td>\n",
       "<td>0.2363945</td>\n",
       "<td>0.1976720</td>\n",
       "<td>0.2287</td>\n",
       "<td>0.1466084</td>\n",
       "<td>0.2240453</td>\n",
       "<td>0.2417881</td>\n",
       "<td>0.2396517</td>\n",
       "<td>0.2419190</td>\n",
       "<td>0.2293870</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.2754555</td>\n",
       "<td>0.0210102</td>\n",
       "<td>0.2730924</td>\n",
       "<td>0.2751678</td>\n",
       "<td>0.2924791</td>\n",
       "<td>0.2895863</td>\n",
       "<td>0.1952247</td>\n",
       "<td>0.2844273</td>\n",
       "<td>0.2608696</td>\n",
       "<td>0.3042913</td>\n",
       "<td>0.2761905</td>\n",
       "<td>0.3032258</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.9984682</td>\n",
       "<td>0.0005421</td>\n",
       "<td>0.9985987</td>\n",
       "<td>0.9986618</td>\n",
       "<td>0.996572</td>\n",
       "<td>0.9985171</td>\n",
       "<td>0.9983781</td>\n",
       "<td>0.9982824</td>\n",
       "<td>0.9993948</td>\n",
       "<td>0.9980804</td>\n",
       "<td>0.9995335</td>\n",
       "<td>0.9986629</td></tr></table></div>"
      ],
      "text/plain": [
       "                     mean        sd           cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid    cv_6_valid    cv_7_valid    cv_8_valid    cv_9_valid    cv_10_valid\n",
       "-------------------  ----------  -----------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  -------------\n",
       "F0point5             0.484416    0.0476009    0.487805      0.495408      0.367905      0.489629      0.368896      0.477735      0.556492      0.48168       0.589089      0.529518\n",
       "F1                   0.375242    0.0275108    0.376731      0.381041      0.335463      0.388889      0.276617      0.380706      0.390533      0.39527       0.413442      0.413732\n",
       "F2                   0.307889    0.0220217    0.306859      0.309574      0.308279      0.322529      0.221267      0.316438      0.30082       0.335148      0.318481      0.339497\n",
       "accuracy             0.99282     0.000491014  0.992891      0.992982      0.991264      0.993292      0.9924        0.992485      0.993491      0.992468      0.99394       0.99299\n",
       "auc                  0.899637    0.0125736    0.909025      0.893715      0.904045      0.913295      0.85916       0.879202      0.913405      0.892574      0.914681      0.917271\n",
       "err                  0.00717966  0.000491014  0.00710923    0.00701762    0.00873638    0.00670802    0.00759967    0.00751463    0.00650869    0.00753201    0.00606022    0.00701008\n",
       "err_count            683.3       47.3614      675           666           832           638           727           719           618           716           576           666\n",
       "lift_top_group       35.8892     2.88502      37.061        36.0709       34.7948       39.9052       24.5689       36.6719       35.1594       38.0858       37.2577       39.3159\n",
       "logloss              0.0317487   0.00103524   0.0330156     0.0309114     0.0308897     0.0296697     0.0335409     0.0343992     0.0303389     0.0321333     0.0304934     0.032095\n",
       "max_per_class_error  0.724545    0.0210102    0.726908      0.724832      0.707521      0.710414      0.804775      0.715573      0.73913       0.695709      0.72381       0.696774\n",
       "mcc                  0.403695    0.0344781    0.404223      0.409913      0.334845      0.411091      0.301135      0.401318      0.447823      0.410834      0.474405      0.441359\n",
       "mse                  0.00604698  0.000139094  0.00615611    0.00594728    0.00600341    0.0056429     0.00630441    0.00625022    0.00601245    0.00610111    0.00581698    0.0062349\n",
       "precision            0.607465    0.084652     0.607143      0.619335      0.393258      0.591837      0.474403      0.575521      0.776471      0.563855      0.821862      0.650969\n",
       "r2                   0.219749    0.0196847    0.211326      0.236395      0.197672      0.2287        0.146608      0.224045      0.241788      0.239652      0.241919      0.229387\n",
       "recall               0.275455    0.0210102    0.273092      0.275168      0.292479      0.289586      0.195225      0.284427      0.26087       0.304291      0.276191      0.303226\n",
       "specificity          0.998468    0.00054207   0.998599      0.998662      0.996572      0.998517      0.998378      0.998282      0.999395      0.99808       0.999533      0.998663"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>training_speed</b></td>\n",
       "<td><b>epochs</b></td>\n",
       "<td><b>iterations</b></td>\n",
       "<td><b>samples</b></td>\n",
       "<td><b>training_MSE</b></td>\n",
       "<td><b>training_r2</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_AUC</b></td>\n",
       "<td><b>training_lift</b></td>\n",
       "<td><b>training_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-05-09 16:15:03</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-05-09 16:15:14</td>\n",
       "<td>25 min 27.335 sec</td>\n",
       "<td>9051 rows/sec</td>\n",
       "<td>0.1053773</td>\n",
       "<td>1</td>\n",
       "<td>100277.0</td>\n",
       "<td>0.0067578</td>\n",
       "<td>0.1614811</td>\n",
       "<td>0.0473401</td>\n",
       "<td>0.8143866</td>\n",
       "<td>33.23</td>\n",
       "<td>0.0079246</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-05-09 16:15:26</td>\n",
       "<td>25 min 38.867 sec</td>\n",
       "<td>8912 rows/sec</td>\n",
       "<td>0.2104802</td>\n",
       "<td>2</td>\n",
       "<td>200293.0</td>\n",
       "<td>0.0063670</td>\n",
       "<td>0.2099686</td>\n",
       "<td>0.0366679</td>\n",
       "<td>0.9044945</td>\n",
       "<td>31.9992593</td>\n",
       "<td>0.0070218</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-05-09 16:15:37</td>\n",
       "<td>25 min 49.612 sec</td>\n",
       "<td>9061 rows/sec</td>\n",
       "<td>0.3156274</td>\n",
       "<td>3</td>\n",
       "<td>300351.0</td>\n",
       "<td>0.0067387</td>\n",
       "<td>0.1638512</td>\n",
       "<td>0.0385219</td>\n",
       "<td>0.8495227</td>\n",
       "<td>29.5377778</td>\n",
       "<td>0.0069215</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-05-09 16:15:47</td>\n",
       "<td>25 min 59.541 sec</td>\n",
       "<td>9309 rows/sec</td>\n",
       "<td>0.4205013</td>\n",
       "<td>4</td>\n",
       "<td>400149.0</td>\n",
       "<td>0.0066019</td>\n",
       "<td>0.1808191</td>\n",
       "<td>0.0383968</td>\n",
       "<td>0.8526216</td>\n",
       "<td>30.7685185</td>\n",
       "<td>0.0086267</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-05-09 16:15:56</td>\n",
       "<td>26 min  9.186 sec</td>\n",
       "<td>9516 rows/sec</td>\n",
       "<td>0.5254571</td>\n",
       "<td>5</td>\n",
       "<td>500025.0</td>\n",
       "<td>0.0063217</td>\n",
       "<td>0.2155846</td>\n",
       "<td>0.0347189</td>\n",
       "<td>0.8988430</td>\n",
       "<td>29.5377778</td>\n",
       "<td>0.0064199</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-05-09 16:16:06</td>\n",
       "<td>26 min 19.060 sec</td>\n",
       "<td>9628 rows/sec</td>\n",
       "<td>0.6306263</td>\n",
       "<td>6</td>\n",
       "<td>600104.0</td>\n",
       "<td>0.0073925</td>\n",
       "<td>0.0827186</td>\n",
       "<td>0.0360194</td>\n",
       "<td>0.8971687</td>\n",
       "<td>27.0762963</td>\n",
       "<td>0.0081252</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-05-09 16:16:16</td>\n",
       "<td>26 min 28.795 sec</td>\n",
       "<td>9728 rows/sec</td>\n",
       "<td>0.7357472</td>\n",
       "<td>7</td>\n",
       "<td>700137.0</td>\n",
       "<td>0.0065960</td>\n",
       "<td>0.1815539</td>\n",
       "<td>0.0387098</td>\n",
       "<td>0.8848629</td>\n",
       "<td>30.7685185</td>\n",
       "<td>0.0099308</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-05-09 16:16:26</td>\n",
       "<td>26 min 38.642 sec</td>\n",
       "<td>9790 rows/sec</td>\n",
       "<td>0.8407388</td>\n",
       "<td>8</td>\n",
       "<td>800047.0</td>\n",
       "<td>0.0069029</td>\n",
       "<td>0.1434771</td>\n",
       "<td>0.0426598</td>\n",
       "<td>0.8382670</td>\n",
       "<td>28.3070370</td>\n",
       "<td>0.0086267</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-05-09 16:16:35</td>\n",
       "<td>26 min 48.506 sec</td>\n",
       "<td>9834 rows/sec</td>\n",
       "<td>0.9455549</td>\n",
       "<td>9</td>\n",
       "<td>899790.0</td>\n",
       "<td>0.0066184</td>\n",
       "<td>0.1787701</td>\n",
       "<td>0.0427488</td>\n",
       "<td>0.8390604</td>\n",
       "<td>28.3070370</td>\n",
       "<td>0.0065202</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-05-09 16:16:46</td>\n",
       "<td>26 min 58.753 sec</td>\n",
       "<td>9839 rows/sec</td>\n",
       "<td>1.0511013</td>\n",
       "<td>10</td>\n",
       "<td>1000228.0</td>\n",
       "<td>0.0066946</td>\n",
       "<td>0.1693176</td>\n",
       "<td>0.0455291</td>\n",
       "<td>0.8598301</td>\n",
       "<td>28.3070370</td>\n",
       "<td>0.0077239</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-05-09 16:16:56</td>\n",
       "<td>27 min  8.575 sec</td>\n",
       "<td>9879 rows/sec</td>\n",
       "<td>1.1563829</td>\n",
       "<td>11</td>\n",
       "<td>1100414.0</td>\n",
       "<td>0.0064303</td>\n",
       "<td>0.2021114</td>\n",
       "<td>0.0379232</td>\n",
       "<td>0.8961511</td>\n",
       "<td>36.9222222</td>\n",
       "<td>0.0100311</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-05-09 16:17:05</td>\n",
       "<td>27 min 18.322 sec</td>\n",
       "<td>9917 rows/sec</td>\n",
       "<td>1.2615637</td>\n",
       "<td>12</td>\n",
       "<td>1200504.0</td>\n",
       "<td>0.0070011</td>\n",
       "<td>0.1312843</td>\n",
       "<td>0.0417369</td>\n",
       "<td>0.8870279</td>\n",
       "<td>22.1533333</td>\n",
       "<td>0.0068211</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-05-09 16:17:15</td>\n",
       "<td>27 min 28.079 sec</td>\n",
       "<td>9949 rows/sec</td>\n",
       "<td>1.3666929</td>\n",
       "<td>13</td>\n",
       "<td>1300545.0</td>\n",
       "<td>0.0066459</td>\n",
       "<td>0.1753586</td>\n",
       "<td>0.0336441</td>\n",
       "<td>0.9108397</td>\n",
       "<td>29.5377778</td>\n",
       "<td>0.0077239</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-05-09 16:17:25</td>\n",
       "<td>27 min 37.827 sec</td>\n",
       "<td>9982 rows/sec</td>\n",
       "<td>1.4716772</td>\n",
       "<td>14</td>\n",
       "<td>1400448.0</td>\n",
       "<td>0.0066637</td>\n",
       "<td>0.1731518</td>\n",
       "<td>0.0426920</td>\n",
       "<td>0.8923361</td>\n",
       "<td>33.23</td>\n",
       "<td>0.0072224</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-05-09 16:17:35</td>\n",
       "<td>27 min 47.615 sec</td>\n",
       "<td>10001 rows/sec</td>\n",
       "<td>1.5765174</td>\n",
       "<td>15</td>\n",
       "<td>1500214.0</td>\n",
       "<td>0.0066624</td>\n",
       "<td>0.1733152</td>\n",
       "<td>0.0368655</td>\n",
       "<td>0.9185570</td>\n",
       "<td>28.3070370</td>\n",
       "<td>0.0086267</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-05-09 16:17:44</td>\n",
       "<td>27 min 57.410 sec</td>\n",
       "<td>10017 rows/sec</td>\n",
       "<td>1.6812568</td>\n",
       "<td>16</td>\n",
       "<td>1599884.0</td>\n",
       "<td>0.0066330</td>\n",
       "<td>0.1769655</td>\n",
       "<td>0.0405168</td>\n",
       "<td>0.9237728</td>\n",
       "<td>31.9992593</td>\n",
       "<td>0.0072224</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration           training_speed    epochs    iterations    samples      training_MSE    training_r2    training_logloss    training_AUC    training_lift    training_classification_error\n",
       "--  -------------------  -----------------  ----------------  --------  ------------  -----------  --------------  -------------  ------------------  --------------  ---------------  -------------------------------\n",
       "    2016-05-09 16:15:03  0.000 sec                            0         0             0            nan             nan            nan                 nan             nan              nan\n",
       "    2016-05-09 16:15:14  25 min 27.335 sec  9051 rows/sec     0.105377  1             100277       0.00675777      0.161481       0.0473401           0.814387        33.23            0.00792457\n",
       "    2016-05-09 16:15:26  25 min 38.867 sec  8912 rows/sec     0.21048   2             200293       0.006367        0.209969       0.0366679           0.904495        31.9993          0.00702177\n",
       "    2016-05-09 16:15:37  25 min 49.612 sec  9061 rows/sec     0.315627  3             300351       0.00673866      0.163851       0.0385219           0.849523        29.5378          0.00692146\n",
       "    2016-05-09 16:15:47  25 min 59.541 sec  9309 rows/sec     0.420501  4             400149       0.00660192      0.180819       0.0383968           0.852622        30.7685          0.00862674\n",
       "    2016-05-09 16:15:56  26 min  9.186 sec  9516 rows/sec     0.525457  5             500025       0.00632174      0.215585       0.0347189           0.898843        29.5378          0.0064199\n",
       "    2016-05-09 16:16:06  26 min 19.060 sec  9628 rows/sec     0.630626  6             600104       0.00739253      0.0827186      0.0360194           0.897169        27.0763          0.00812519\n",
       "    2016-05-09 16:16:16  26 min 28.795 sec  9728 rows/sec     0.735747  7             700137       0.006596        0.181554       0.0387098           0.884863        30.7685          0.00993079\n",
       "    2016-05-09 16:16:26  26 min 38.642 sec  9790 rows/sec     0.840739  8             800047       0.00690286      0.143477       0.0426598           0.838267        28.307           0.00862674\n",
       "    2016-05-09 16:16:35  26 min 48.506 sec  9834 rows/sec     0.945555  9             899790       0.00661843      0.17877        0.0427488           0.83906         28.307           0.00652021\n",
       "    2016-05-09 16:16:46  26 min 58.753 sec  9839 rows/sec     1.0511    10            1.00023e+06  0.00669461      0.169318       0.0455291           0.85983         28.307           0.00772394\n",
       "    2016-05-09 16:16:56  27 min  8.575 sec  9879 rows/sec     1.15638   11            1.10041e+06  0.00643032      0.202111       0.0379232           0.896151        36.9222          0.0100311\n",
       "    2016-05-09 16:17:05  27 min 18.322 sec  9917 rows/sec     1.26156   12            1.2005e+06   0.00700113      0.131284       0.0417369           0.887028        22.1533          0.00682115\n",
       "    2016-05-09 16:17:15  27 min 28.079 sec  9949 rows/sec     1.36669   13            1.30054e+06  0.00664592      0.175359       0.0336441           0.91084         29.5378          0.00772394\n",
       "    2016-05-09 16:17:25  27 min 37.827 sec  9982 rows/sec     1.47168   14            1.40045e+06  0.00666371      0.173152       0.042692            0.892336        33.23            0.00722239\n",
       "    2016-05-09 16:17:35  27 min 47.615 sec  10001 rows/sec    1.57652   15            1.50021e+06  0.00666239      0.173315       0.0368655           0.918557        28.307           0.00862674\n",
       "    2016-05-09 16:17:44  27 min 57.410 sec  10017 rows/sec    1.68126   16            1.59988e+06  0.00663297      0.176965       0.0405168           0.923773        31.9993          0.00722239"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
